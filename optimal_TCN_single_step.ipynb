{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashrafalaghbari/oil-production-forecasting/blob/main/optimal_TCN_single_step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "x1LrkoSv4cc7",
        "outputId": "16feda93-77ad-43bc-889d-b09beca152d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tcn --no-dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8tyr5_aWpmN",
        "outputId": "0cdc51cf-6b2b-403e-9c7e-41f3de27b199"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XxzUA1Pg4iEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation, Dropout\n",
        "from keras.layers import LSTM, Conv1D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I6ZrWV9NpfPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1866bf-bf84-4a39-c4cd-0e7fba74231f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hu7vsRejtR_4"
      },
      "outputs": [],
      "source": [
        "# # check if GPU is utilized \n",
        "# device_name = tf.config.experimental.list_physical_devices()[-1][-1]\n",
        "# if device_name != 'GPU':\n",
        "#     raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lVMp6qZiT9gO"
      },
      "outputs": [],
      "source": [
        "# Select the best features\n",
        "def select_features(df, target, correlation_type, threshold):\n",
        "    if (threshold < -1 ) | (threshold > 1 ) :\n",
        "            raise SystemError('correlation threshold is out of bounds')\n",
        "    features = df.corr(correlation_type).loc[target].drop(target)\n",
        "    best_features = features.where(abs(features) > threshold).dropna()\n",
        "    df = pd.concat([df[target], df[best_features.index]], axis=1)\n",
        "    return df\n",
        "\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, columns, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('%s(t-%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "        # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# scale train and test data to new feature range[0, 1]\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        "\n",
        "\n",
        "# inverse differencing\n",
        "def inverse_difference(history, interval=1):\n",
        "\treturn history[-len(test_scaled)-interval:-interval]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sX-FCHP3Hy7E"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics\n",
        "# compute RMSPE\n",
        "def RMSPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
        "\tresult /= len(x)\n",
        "\tresult = sqrt(result)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute MAPE\n",
        "def MAPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += abs((x[i]-y[i])/x[i])\n",
        "\tresult /= len(x)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute wMAPE weighted absolute percentage error\n",
        "def wMAPE(actual, predicted): \n",
        "    result_nom = 0\n",
        "    result_deno = 0\n",
        "    for i in range(len(actual)):\n",
        "        result_nom +=  abs(actual[i] - predicted[i])\n",
        "        result_deno +=  abs(actual[i]) \n",
        "    result = result_nom/result_deno\n",
        "    return result *100\n",
        "\n",
        "def SMAPE(actual, predicted): #Symmetric (adjusted) MEAN ABSOLUTE PERCENTAGE ERROR (SMAPE)\n",
        "    result = 0\n",
        "    for i in range(len(actual)):\n",
        "        result += abs(actual[i] - predicted[i])/(abs(actual[i]) + abs(predicted[i]))\n",
        "    result = 2 * result/ len(actual) \n",
        "    return result * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "tRJsglCpLKHo"
      },
      "outputs": [],
      "source": [
        "#load dataset\n",
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv', \n",
        "                     parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "# select feature based on correlation\n",
        "series = select_features(series, \"BORE_OIL_VOL\", \"spearman\", -1)\n",
        "# select features manually\n",
        "series =series[[\"ON_STREAM_HRS\",'BORE_GAS_VOL', 'BORE_WAT_VOL',\n",
        "                'AVG_CHOKE_SIZE_P','F_4_BORE_WI_VOL','F_5_BORE_WI_VOL',\n",
        "                 \"BORE_OIL_VOL\"]] "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "nS4Iu77brxRE",
        "outputId": "a5f0a291-dbfc-45e8-a401-23e2a60968f3"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ON_STREAM_HRS  BORE_GAS_VOL  BORE_WAT_VOL  AVG_CHOKE_SIZE_P  \\\n",
              "DATEPRD                                                                   \n",
              "2010-01-01           24.0  1.462166e+07  15304.241356         50.150825   \n",
              "2010-01-02           24.0  1.469266e+07  16519.118273         50.694654   \n",
              "2010-01-03           24.0  1.400904e+07  14796.150455         47.665676   \n",
              "2010-01-04           24.0  1.341015e+07  13428.619835         44.706230   \n",
              "2010-01-05           24.0  1.361768e+07   9839.905499         45.743761   \n",
              "...                   ...           ...           ...               ...   \n",
              "2015-03-19           24.0  1.366424e+06  21779.601368        100.000000   \n",
              "2015-03-20           24.0  1.397308e+06  23586.538158        100.000000   \n",
              "2015-03-21           24.0  1.408435e+06  22172.777429        100.000000   \n",
              "2015-03-22           24.0  1.379366e+06  21863.570340        100.000000   \n",
              "2015-03-23           24.0  1.263109e+06  20106.134360         99.994093   \n",
              "\n",
              "            F_4_BORE_WI_VOL  F_5_BORE_WI_VOL  BORE_OIL_VOL  \n",
              "DATEPRD                                                     \n",
              "2010-01-01     44109.287732     49054.221066  18593.749401  \n",
              "2010-01-02     41936.969541     51515.296516  18701.242265  \n",
              "2010-01-03     41114.572918     51717.286427  17799.912406  \n",
              "2010-01-04     40267.292699     51948.640243  17002.616014  \n",
              "2010-01-05     40524.238503     52129.744099  17270.939334  \n",
              "...                     ...              ...           ...  \n",
              "2015-03-19     27765.068530     26704.126695   1662.711432  \n",
              "2015-03-20     26112.632371     27951.162219   1707.494884  \n",
              "2015-03-21     26281.191015     27980.731217   1725.420844  \n",
              "2015-03-22     26104.671114     27500.440270   1620.632599  \n",
              "2015-03-23     26485.606927     27009.713398   1443.511533  \n",
              "\n",
              "[1908 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe5699dd-d207-47c5-87e7-61ef55d589f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS</th>\n",
              "      <th>BORE_GAS_VOL</th>\n",
              "      <th>BORE_WAT_VOL</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>F_4_BORE_WI_VOL</th>\n",
              "      <th>F_5_BORE_WI_VOL</th>\n",
              "      <th>BORE_OIL_VOL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-01</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.462166e+07</td>\n",
              "      <td>15304.241356</td>\n",
              "      <td>50.150825</td>\n",
              "      <td>44109.287732</td>\n",
              "      <td>49054.221066</td>\n",
              "      <td>18593.749401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-02</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.469266e+07</td>\n",
              "      <td>16519.118273</td>\n",
              "      <td>50.694654</td>\n",
              "      <td>41936.969541</td>\n",
              "      <td>51515.296516</td>\n",
              "      <td>18701.242265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-03</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.400904e+07</td>\n",
              "      <td>14796.150455</td>\n",
              "      <td>47.665676</td>\n",
              "      <td>41114.572918</td>\n",
              "      <td>51717.286427</td>\n",
              "      <td>17799.912406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.341015e+07</td>\n",
              "      <td>13428.619835</td>\n",
              "      <td>44.706230</td>\n",
              "      <td>40267.292699</td>\n",
              "      <td>51948.640243</td>\n",
              "      <td>17002.616014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.361768e+07</td>\n",
              "      <td>9839.905499</td>\n",
              "      <td>45.743761</td>\n",
              "      <td>40524.238503</td>\n",
              "      <td>52129.744099</td>\n",
              "      <td>17270.939334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-19</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.366424e+06</td>\n",
              "      <td>21779.601368</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27765.068530</td>\n",
              "      <td>26704.126695</td>\n",
              "      <td>1662.711432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-20</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.397308e+06</td>\n",
              "      <td>23586.538158</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26112.632371</td>\n",
              "      <td>27951.162219</td>\n",
              "      <td>1707.494884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-21</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.408435e+06</td>\n",
              "      <td>22172.777429</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26281.191015</td>\n",
              "      <td>27980.731217</td>\n",
              "      <td>1725.420844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-22</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.379366e+06</td>\n",
              "      <td>21863.570340</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26104.671114</td>\n",
              "      <td>27500.440270</td>\n",
              "      <td>1620.632599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-23</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.263109e+06</td>\n",
              "      <td>20106.134360</td>\n",
              "      <td>99.994093</td>\n",
              "      <td>26485.606927</td>\n",
              "      <td>27009.713398</td>\n",
              "      <td>1443.511533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1908 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe5699dd-d207-47c5-87e7-61ef55d589f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe5699dd-d207-47c5-87e7-61ef55d589f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe5699dd-d207-47c5-87e7-61ef55d589f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gd4HfCJBzSDp"
      },
      "outputs": [],
      "source": [
        "# for i in range(1, steps_ahead+1):\n",
        "#     series[f\"AVG_CHOKE_SIZE_P{i}\"] = series['AVG_CHOKE_SIZE_P'].shift(-i)\n",
        "#     series[f\"ON_STREAM_HRS{i}\"] = series['ON_STREAM_HRS'].shift(-i)\n",
        "#     #series[f\"BORE_GAS_VOL{i}\"] = series['BORE_GAS_VOL'].shift(-i)\n",
        "# series.drop([\"AVG_CHOKE_SIZE_P\",\"ON_STREAM_HRS\"], axis=1, inplace=True)\n",
        "# series.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# column_to_move = series_supervised.pop(\"BORE_OIL_VOL(t-1)\")\n",
        "# # insert column with insert(location, column_name, column_value)\n",
        "# series_supervised.insert(steps_ahead*len(series.columns) -1, \"BORE_OIL_VOL(t-1)\", column_to_move)"
      ],
      "metadata": {
        "id": "gvbdXWyRlpXZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KpoQJ7P7lmyb"
      },
      "outputs": [],
      "source": [
        "# Create a new directory in My Drive\n",
        "directory = '/content/drive/My Drive/my_trained_models'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # convert series to stationary \n",
        "series_diff = series.copy()\n",
        "diff_order = 1\n",
        "series_diff['BORE_OIL_VOL'] = series_diff['BORE_OIL_VOL'].diff(diff_order)\n",
        "#feature engineering\n",
        "steps_ahead=2\n",
        "timesteps=4\n",
        "# # convert the stationary series to supervise learning\n",
        "series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in= timesteps, n_out= steps_ahead, dropnan=True)   \n",
        "\n",
        "# drop columns we don't want to predict\n",
        "pattern = re.compile(r\"(t-)|^BORE_OIL_VOL.*\")\n",
        "# Extract the column names that match the pattern\n",
        "matching_columns = [col for col in series_supervised.columns if re.search(pattern, col)]\n",
        "series_supervised = series_supervised[matching_columns]"
      ],
      "metadata": {
        "id": "6b5TKp5GhQE-"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series_supervised"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "S-NwjqHQhRbV",
        "outputId": "afe76470-d7d0-422a-8139-e73d4ada9a65"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ON_STREAM_HRS(t-4)  BORE_GAS_VOL(t-4)  BORE_WAT_VOL(t-4)  \\\n",
              "DATEPRD                                                                \n",
              "2010-01-06                24.0       1.469266e+07       16519.118273   \n",
              "2010-01-07                24.0       1.400904e+07       14796.150455   \n",
              "2010-01-08                24.0       1.341015e+07       13428.619835   \n",
              "2010-01-09                24.0       1.361768e+07        9839.905499   \n",
              "2010-01-10                24.0       1.364834e+07       10054.073550   \n",
              "...                        ...                ...                ...   \n",
              "2015-03-18                24.0       1.362575e+06       21875.080693   \n",
              "2015-03-19                24.0       1.337302e+06       21926.091057   \n",
              "2015-03-20                24.0       1.344981e+06       22268.759939   \n",
              "2015-03-21                24.0       1.348689e+06       21771.927799   \n",
              "2015-03-22                24.0       1.354500e+06       21725.383201   \n",
              "\n",
              "            AVG_CHOKE_SIZE_P(t-4)  F_4_BORE_WI_VOL(t-4)  F_5_BORE_WI_VOL(t-4)  \\\n",
              "DATEPRD                                                                         \n",
              "2010-01-06              50.694654          41936.969541          51515.296516   \n",
              "2010-01-07              47.665676          41114.572918          51717.286427   \n",
              "2010-01-08              44.706230          40267.292699          51948.640243   \n",
              "2010-01-09              45.743761          40524.238503          52129.744099   \n",
              "2010-01-10              46.053981          40733.215195          52212.108216   \n",
              "...                           ...                   ...                   ...   \n",
              "2015-03-18             100.000000          27231.502584          26937.428795   \n",
              "2015-03-19             100.000000          27756.502625          26967.735313   \n",
              "2015-03-20             100.000000          27622.708539          27618.897616   \n",
              "2015-03-21             100.000000          26885.294563          27819.994862   \n",
              "2015-03-22             100.000000          27174.003165          26957.732482   \n",
              "\n",
              "            BORE_OIL_VOL(t-4)  ON_STREAM_HRS(t-3)  BORE_GAS_VOL(t-3)  \\\n",
              "DATEPRD                                                                \n",
              "2010-01-06         107.492863                24.0       1.400904e+07   \n",
              "2010-01-07        -901.329859                24.0       1.341015e+07   \n",
              "2010-01-08        -797.296392                24.0       1.361768e+07   \n",
              "2010-01-09         268.323320                24.0       1.364834e+07   \n",
              "2010-01-10          60.822469                24.0       1.350971e+07   \n",
              "...                       ...                 ...                ...   \n",
              "2015-03-18           9.623410                24.0       1.337302e+06   \n",
              "2015-03-19         -14.026278                24.0       1.344981e+06   \n",
              "2015-03-20          16.605100                24.0       1.348689e+06   \n",
              "2015-03-21          18.806534                24.0       1.354500e+06   \n",
              "2015-03-22          10.315289                24.0       1.366424e+06   \n",
              "\n",
              "            BORE_WAT_VOL(t-3)  ...  BORE_OIL_VOL(t-2)  ON_STREAM_HRS(t-1)  \\\n",
              "DATEPRD                        ...                                          \n",
              "2010-01-06       14796.150455  ...        -797.296392            24.00000   \n",
              "2010-01-07       13428.619835  ...         268.323320            24.00000   \n",
              "2010-01-08        9839.905499  ...          60.822469            24.00000   \n",
              "2010-01-09       10054.073550  ...        -193.160084            24.00000   \n",
              "2010-01-10       12837.943721  ...         -10.944270            22.83333   \n",
              "...                       ...  ...                ...                 ...   \n",
              "2015-03-18       21926.091057  ...          16.605100            24.00000   \n",
              "2015-03-19       22268.759939  ...          18.806534            24.00000   \n",
              "2015-03-20       21771.927799  ...          10.315289            24.00000   \n",
              "2015-03-21       21725.383201  ...           3.270702            24.00000   \n",
              "2015-03-22       21779.601368  ...          44.783451            24.00000   \n",
              "\n",
              "            BORE_GAS_VOL(t-1)  BORE_WAT_VOL(t-1)  AVG_CHOKE_SIZE_P(t-1)  \\\n",
              "DATEPRD                                                                   \n",
              "2010-01-06       1.361768e+07        9839.905499              45.743761   \n",
              "2010-01-07       1.364834e+07       10054.073550              46.053981   \n",
              "2010-01-08       1.350971e+07       12837.943721              44.740102   \n",
              "2010-01-09       1.349732e+07       10488.510768              44.805229   \n",
              "2010-01-10       1.192758e+07       10120.619746              39.728795   \n",
              "...                       ...                ...                    ...   \n",
              "2015-03-18       1.348689e+06       21771.927799             100.000000   \n",
              "2015-03-19       1.354500e+06       21725.383201             100.000000   \n",
              "2015-03-20       1.366424e+06       21779.601368             100.000000   \n",
              "2015-03-21       1.397308e+06       23586.538158             100.000000   \n",
              "2015-03-22       1.408435e+06       22172.777429             100.000000   \n",
              "\n",
              "            F_4_BORE_WI_VOL(t-1)  F_5_BORE_WI_VOL(t-1)  BORE_OIL_VOL(t-1)  \\\n",
              "DATEPRD                                                                     \n",
              "2010-01-06          40524.238503          52129.744099         268.323320   \n",
              "2010-01-07          40733.215195          52212.108216          60.822469   \n",
              "2010-01-08          39969.857579          51109.971510        -193.160084   \n",
              "2010-01-09          41079.035678          50933.111950         -10.944270   \n",
              "2010-01-10          26561.870164          36311.076594       -2649.834308   \n",
              "...                          ...                   ...                ...   \n",
              "2015-03-18          26885.294563          27819.994862          18.806534   \n",
              "2015-03-19          27174.003165          26957.732482          10.315289   \n",
              "2015-03-20          27765.068530          26704.126695           3.270702   \n",
              "2015-03-21          26112.632371          27951.162219          44.783451   \n",
              "2015-03-22          26281.191015          27980.731217          17.925960   \n",
              "\n",
              "            BORE_OIL_VOL(t)  BORE_OIL_VOL(t+1)  \n",
              "DATEPRD                                         \n",
              "2010-01-06        60.822469        -193.160084  \n",
              "2010-01-07      -193.160084         -10.944270  \n",
              "2010-01-08       -10.944270       -2649.834308  \n",
              "2010-01-09     -2649.834308        2671.659950  \n",
              "2010-01-10      2671.659950         -76.232504  \n",
              "...                     ...                ...  \n",
              "2015-03-18        10.315289           3.270702  \n",
              "2015-03-19         3.270702          44.783451  \n",
              "2015-03-20        44.783451          17.925960  \n",
              "2015-03-21        17.925960        -104.788245  \n",
              "2015-03-22      -104.788245        -177.121066  \n",
              "\n",
              "[1902 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-570652c7-e2bd-435f-98da-85088ea75019\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS(t-4)</th>\n",
              "      <th>BORE_GAS_VOL(t-4)</th>\n",
              "      <th>BORE_WAT_VOL(t-4)</th>\n",
              "      <th>AVG_CHOKE_SIZE_P(t-4)</th>\n",
              "      <th>F_4_BORE_WI_VOL(t-4)</th>\n",
              "      <th>F_5_BORE_WI_VOL(t-4)</th>\n",
              "      <th>BORE_OIL_VOL(t-4)</th>\n",
              "      <th>ON_STREAM_HRS(t-3)</th>\n",
              "      <th>BORE_GAS_VOL(t-3)</th>\n",
              "      <th>BORE_WAT_VOL(t-3)</th>\n",
              "      <th>...</th>\n",
              "      <th>BORE_OIL_VOL(t-2)</th>\n",
              "      <th>ON_STREAM_HRS(t-1)</th>\n",
              "      <th>BORE_GAS_VOL(t-1)</th>\n",
              "      <th>BORE_WAT_VOL(t-1)</th>\n",
              "      <th>AVG_CHOKE_SIZE_P(t-1)</th>\n",
              "      <th>F_4_BORE_WI_VOL(t-1)</th>\n",
              "      <th>F_5_BORE_WI_VOL(t-1)</th>\n",
              "      <th>BORE_OIL_VOL(t-1)</th>\n",
              "      <th>BORE_OIL_VOL(t)</th>\n",
              "      <th>BORE_OIL_VOL(t+1)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.469266e+07</td>\n",
              "      <td>16519.118273</td>\n",
              "      <td>50.694654</td>\n",
              "      <td>41936.969541</td>\n",
              "      <td>51515.296516</td>\n",
              "      <td>107.492863</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.400904e+07</td>\n",
              "      <td>14796.150455</td>\n",
              "      <td>...</td>\n",
              "      <td>-797.296392</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.361768e+07</td>\n",
              "      <td>9839.905499</td>\n",
              "      <td>45.743761</td>\n",
              "      <td>40524.238503</td>\n",
              "      <td>52129.744099</td>\n",
              "      <td>268.323320</td>\n",
              "      <td>60.822469</td>\n",
              "      <td>-193.160084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.400904e+07</td>\n",
              "      <td>14796.150455</td>\n",
              "      <td>47.665676</td>\n",
              "      <td>41114.572918</td>\n",
              "      <td>51717.286427</td>\n",
              "      <td>-901.329859</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.341015e+07</td>\n",
              "      <td>13428.619835</td>\n",
              "      <td>...</td>\n",
              "      <td>268.323320</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.364834e+07</td>\n",
              "      <td>10054.073550</td>\n",
              "      <td>46.053981</td>\n",
              "      <td>40733.215195</td>\n",
              "      <td>52212.108216</td>\n",
              "      <td>60.822469</td>\n",
              "      <td>-193.160084</td>\n",
              "      <td>-10.944270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.341015e+07</td>\n",
              "      <td>13428.619835</td>\n",
              "      <td>44.706230</td>\n",
              "      <td>40267.292699</td>\n",
              "      <td>51948.640243</td>\n",
              "      <td>-797.296392</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.361768e+07</td>\n",
              "      <td>9839.905499</td>\n",
              "      <td>...</td>\n",
              "      <td>60.822469</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.350971e+07</td>\n",
              "      <td>12837.943721</td>\n",
              "      <td>44.740102</td>\n",
              "      <td>39969.857579</td>\n",
              "      <td>51109.971510</td>\n",
              "      <td>-193.160084</td>\n",
              "      <td>-10.944270</td>\n",
              "      <td>-2649.834308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-09</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.361768e+07</td>\n",
              "      <td>9839.905499</td>\n",
              "      <td>45.743761</td>\n",
              "      <td>40524.238503</td>\n",
              "      <td>52129.744099</td>\n",
              "      <td>268.323320</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.364834e+07</td>\n",
              "      <td>10054.073550</td>\n",
              "      <td>...</td>\n",
              "      <td>-193.160084</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.349732e+07</td>\n",
              "      <td>10488.510768</td>\n",
              "      <td>44.805229</td>\n",
              "      <td>41079.035678</td>\n",
              "      <td>50933.111950</td>\n",
              "      <td>-10.944270</td>\n",
              "      <td>-2649.834308</td>\n",
              "      <td>2671.659950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-10</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.364834e+07</td>\n",
              "      <td>10054.073550</td>\n",
              "      <td>46.053981</td>\n",
              "      <td>40733.215195</td>\n",
              "      <td>52212.108216</td>\n",
              "      <td>60.822469</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.350971e+07</td>\n",
              "      <td>12837.943721</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.944270</td>\n",
              "      <td>22.83333</td>\n",
              "      <td>1.192758e+07</td>\n",
              "      <td>10120.619746</td>\n",
              "      <td>39.728795</td>\n",
              "      <td>26561.870164</td>\n",
              "      <td>36311.076594</td>\n",
              "      <td>-2649.834308</td>\n",
              "      <td>2671.659950</td>\n",
              "      <td>-76.232504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-18</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.362575e+06</td>\n",
              "      <td>21875.080693</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27231.502584</td>\n",
              "      <td>26937.428795</td>\n",
              "      <td>9.623410</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.337302e+06</td>\n",
              "      <td>21926.091057</td>\n",
              "      <td>...</td>\n",
              "      <td>16.605100</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.348689e+06</td>\n",
              "      <td>21771.927799</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26885.294563</td>\n",
              "      <td>27819.994862</td>\n",
              "      <td>18.806534</td>\n",
              "      <td>10.315289</td>\n",
              "      <td>3.270702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-19</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.337302e+06</td>\n",
              "      <td>21926.091057</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27756.502625</td>\n",
              "      <td>26967.735313</td>\n",
              "      <td>-14.026278</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.344981e+06</td>\n",
              "      <td>22268.759939</td>\n",
              "      <td>...</td>\n",
              "      <td>18.806534</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.354500e+06</td>\n",
              "      <td>21725.383201</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27174.003165</td>\n",
              "      <td>26957.732482</td>\n",
              "      <td>10.315289</td>\n",
              "      <td>3.270702</td>\n",
              "      <td>44.783451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-20</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.344981e+06</td>\n",
              "      <td>22268.759939</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27622.708539</td>\n",
              "      <td>27618.897616</td>\n",
              "      <td>16.605100</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.348689e+06</td>\n",
              "      <td>21771.927799</td>\n",
              "      <td>...</td>\n",
              "      <td>10.315289</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.366424e+06</td>\n",
              "      <td>21779.601368</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27765.068530</td>\n",
              "      <td>26704.126695</td>\n",
              "      <td>3.270702</td>\n",
              "      <td>44.783451</td>\n",
              "      <td>17.925960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-21</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.348689e+06</td>\n",
              "      <td>21771.927799</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26885.294563</td>\n",
              "      <td>27819.994862</td>\n",
              "      <td>18.806534</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.354500e+06</td>\n",
              "      <td>21725.383201</td>\n",
              "      <td>...</td>\n",
              "      <td>3.270702</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.397308e+06</td>\n",
              "      <td>23586.538158</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26112.632371</td>\n",
              "      <td>27951.162219</td>\n",
              "      <td>44.783451</td>\n",
              "      <td>17.925960</td>\n",
              "      <td>-104.788245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-22</th>\n",
              "      <td>24.0</td>\n",
              "      <td>1.354500e+06</td>\n",
              "      <td>21725.383201</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27174.003165</td>\n",
              "      <td>26957.732482</td>\n",
              "      <td>10.315289</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.366424e+06</td>\n",
              "      <td>21779.601368</td>\n",
              "      <td>...</td>\n",
              "      <td>44.783451</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>1.408435e+06</td>\n",
              "      <td>22172.777429</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>26281.191015</td>\n",
              "      <td>27980.731217</td>\n",
              "      <td>17.925960</td>\n",
              "      <td>-104.788245</td>\n",
              "      <td>-177.121066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1902 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-570652c7-e2bd-435f-98da-85088ea75019')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-570652c7-e2bd-435f-98da-85088ea75019 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-570652c7-e2bd-435f-98da-85088ea75019');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "    # # split into train and test sets\n",
        "    series_supervised = series_supervised.values\n",
        "    train_size = int(series_supervised.shape[0] * 0.8)\n",
        "    test_size = series_supervised.shape[0] - train_size\n",
        "    train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "    print(\"train.shape:\",train.shape, \"test.shape:\",test.shape)\n",
        "\n",
        "    # scale  the data to a feature range(0,1)\n",
        "    scaler, train_scaled, test_scaled = scale(train, test)\n",
        "    print('train_scaled.shape:',train_scaled.shape, \"test_scaled.shape:\",test_scaled.shape)\n",
        "\n",
        "    # reshape input to be 3D [samples, timesteps, features]\n",
        "    n_features = len(series.columns)\n",
        "    train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "    train_X = train_X.reshape(train_X.shape[0], timesteps, n_features)\n",
        "    test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "    test_X = test_X.reshape(test_X.shape[0], timesteps, n_features )\n",
        "    print(\"train_X.shape:\",train_X.shape, \"train_y.shape:\",train_y.shape,\n",
        "            \"test_X.shape:\", test_X.shape,\"test_y.shape:\",test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsv-ScobJY3w",
        "outputId": "38755c3b-f802-40b6-b627-8faa49256b4c"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (1521, 30) test.shape: (381, 30)\n",
            "train_scaled.shape: (1521, 30) test_scaled.shape: (381, 30)\n",
            "train_X.shape: (1521, 4, 7) train_y.shape: (1521, 2) test_X.shape: (381, 4, 7) test_y.shape: (381, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hyper_param(n_iteration,n_epochs, layers_seq, neurons_seq, batch_seq, timesteps_seq):\n",
        "  hyper_param = []\n",
        "  sequences = set()  \n",
        "  while len(hyper_param) < n_iteration:\n",
        "    current_params = []\n",
        "    current_params.append(np.random.choice(n_epochs)) # number of epochs\n",
        "    current_params.append(np.random.choice(layers_seq)) # num_hidden_layers\n",
        "    current_params.append(np.random.choice(neurons_seq)) # 'num_neurons'\n",
        "    current_params.append(np.random.choice(batch_seq)) # batch_size\n",
        "    current_params.append(np.random.choice(timesteps_seq)) # previous timesteps\n",
        "    if tuple(current_params) not in sequences:\n",
        "      sequences.add(tuple(current_params))\n",
        "      hyper_param.append(current_params)\n",
        "  return hyper_param\n",
        "\n",
        "n_epochs = [700]\n",
        "layers_seq = [1, 2]\n",
        "neurons_seq = [4, 8, 16, 32, 64]\n",
        "batch_seq = [2, 8, 12]\n",
        "timesteps_seq = [10, 20, 30, 40]\n",
        "n_iteration = 120\n",
        "\n",
        "hyper_param = get_hyper_param(n_iteration, n_epochs, layers_seq, neurons_seq, batch_seq, timesteps_seq)\n",
        "len(hyper_param)\n",
        "\n",
        "# def check_duplicate_nested_lists(nested_lists):\n",
        "#     nested_lists = [tuple(lst) for lst in nested_lists]\n",
        "#     return len(nested_lists) != len(set(nested_lists))\n",
        "\n",
        "# print(check_duplicate_nested_lists(hyper_param)) # True"
      ],
      "metadata": {
        "id": "nTpxsR6lTq_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972e4226-61b9-40b6-9b14-b261dea8c372"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparamter tuning\n",
        "def fit_lstm(steps_ahead = 2):\n",
        "    \n",
        "    # For reproducibility \n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    np.random.seed(42)\n",
        "    np.random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                            inter_op_parallelism_threads=1)\n",
        "    from keras import backend as K\n",
        "    tf.random.set_seed(1234)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                                config=session_conf)\n",
        "    K.set_session(sess)\n",
        "  \n",
        "    min_val_loss = 999\n",
        "    for  n_epochs, num_hidden_layers, num_neurons, batch_size, timesteps in hyper_param:\n",
        "        print('n_epochs', n_epochs, 'num_hidden_layers', num_hidden_layers, 'num_neurons',\n",
        "              num_neurons, \"batch_size\", batch_size, 'timesteps', timesteps)\n",
        "\n",
        "        #feature engineering\n",
        "        # # convert the stationary series to supervise learning\n",
        "        series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in= timesteps, n_out= steps_ahead, dropnan=True)   \n",
        "\n",
        "        # drop columns we don't want to predict\n",
        "        pattern = re.compile(r\"(t-)|^BORE_OIL_VOL.*\")\n",
        "        # Extract the column names that match the pattern\n",
        "        matching_columns = [col for col in series_supervised.columns if re.search(pattern, col)]\n",
        "        series_supervised = series_supervised[matching_columns]\n",
        "\n",
        "        # # split into train and test sets\n",
        "        series_supervised = series_supervised.values\n",
        "        train_size = int(series_supervised.shape[0] * 0.8)\n",
        "        test_size = series_supervised.shape[0] - train_size\n",
        "        train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "        print(\"train.shape:\",train.shape, \"test.shape:\",test.shape)\n",
        "\n",
        "        # scale  the data to a feature range(0,1)\n",
        "        scaler, train_scaled, test_scaled = scale(train, test)\n",
        "        print('train_scaled.shape:',train_scaled.shape, \"test_scaled.shape:\",test_scaled.shape)\n",
        "\n",
        "        # reshape input to be 3D [samples, timesteps, features]\n",
        "        n_features = len(series.columns)\n",
        "        train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "        train_X = train_X.reshape(train_X.shape[0], timesteps, n_features)\n",
        "        test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "        test_X = test_X.reshape(test_X.shape[0], timesteps, n_features )\n",
        "        print(\"train_X.shape:\",train_X.shape, \"train_y.shape:\",train_y.shape,\n",
        "              \"test_X.shape:\", test_X.shape,\"test_y.shape:\",test_y.shape)\n",
        "        \n",
        "        # build the LSTM model\n",
        "        model = Sequential()\n",
        "\n",
        "        if num_hidden_layers != 1:\n",
        "  \n",
        "            for num in range(num_hidden_layers-1):\n",
        "                model.add(LSTM(num_neurons, input_shape=(timesteps, n_features), return_sequences=True))\n",
        "            model.add(LSTM(num_neurons))\n",
        "\n",
        "        else:\n",
        "            model.add(LSTM(num_neurons, input_shape=(timesteps, n_features)))\n",
        "        model.add(Dense(steps_ahead)) # output layer\n",
        "        model.compile(loss='mean_squared_error',\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "    \n",
        "        \n",
        "        #prevent overfitting\n",
        "        early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "        # save the best weights\n",
        "        mcp_save = ModelCheckpoint(os.path.join(directory, f'{hyper_param[0]}_weights.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "        # fit model\n",
        "        lstm_model = model.fit(train_X, train_y, epochs=n_epochs,\n",
        "                               callbacks=[early_stopping, mcp_save],\n",
        "                               batch_size=batch_size,\n",
        "                            validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "        \n",
        "        # Save the model  in HDF5 foramt with a filename that includes the hyperparamters\n",
        "        model.save(os.path.join(directory, f'{hyper_param[0]}_model.h5'))\n",
        "        # Load the best weights\n",
        "        model.load_weights(os.path.join(directory, f'{hyper_param[0]}_weights.hdf5'))\n",
        "        current_val_loss = model.evaluate(test_X, test_y, verbose=0) #lstm_model.history['val_loss'][-1]\n",
        "        if current_val_loss < min_val_loss:\n",
        "            min_val_loss = current_val_loss\n",
        "            best_params = [n_epochs,  num_hidden_layers, num_neurons, batch_size, timesteps]\n",
        "\n",
        "        \n",
        "    print('final best params',\"n_epochs:\",n_epochs,\"num_hidden_layers:\",\n",
        "          num_hidden_layers,\"batch_size:\",batch_size,\"timesteps:\",timesteps) \n",
        "    return {\"best_params\": str(best_params) , \"MSE\": np.round(min_val_loss, 5)}#, lstm_model"
      ],
      "metadata": {
        "id": "WWzSZIJ36xtn"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the model and repeat the evaluation to reduce the certainty asscoicated with the random initialization of model weights\n",
        "# def run_model(n_repeats = 1):\n",
        "#     scores = [fit_lstm_random() for _ in range(n_repeats)]\n",
        "#     result = pd.DataFrame(scores)\n",
        "#     result = result.groupby(\"best_params\").mean()\n",
        "#     return result"
      ],
      "metadata": {
        "id": "Zpnlrc0t52h5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_param = [[700, 1,12,8, 10  ], [700, 1,12,8, 20  ], [700, 1,12,8, 30  ]]"
      ],
      "metadata": {
        "id": "SaQYj4aMTB45"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, model = fit_lstm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-QpKzZlx53Qd",
        "outputId": "26949b72-ce2e-4bab-b961-648baad26d5a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_epochs 700 num_hidden_layers 1 num_neurons 12 batch_size 8 timesteps 10\n",
            "train.shape: (1516, 72) test.shape: (380, 72)\n",
            "train_scaled.shape: (1516, 72) test_scaled.shape: (380, 72)\n",
            "train_X.shape: (1516, 10, 7) train_y.shape: (1516, 2) test_X.shape: (380, 10, 7) test_y.shape: (380, 2)\n",
            "Epoch 1/700\n",
            "190/190 - 52s - loss: 0.4556 - val_loss: 0.2290 - 52s/epoch - 275ms/step\n",
            "Epoch 2/700\n",
            "190/190 - 1s - loss: 0.1404 - val_loss: 0.0422 - 854ms/epoch - 4ms/step\n",
            "Epoch 3/700\n",
            "190/190 - 1s - loss: 0.0333 - val_loss: 0.0072 - 783ms/epoch - 4ms/step\n",
            "Epoch 4/700\n",
            "190/190 - 1s - loss: 0.0174 - val_loss: 0.0063 - 801ms/epoch - 4ms/step\n",
            "Epoch 5/700\n",
            "190/190 - 1s - loss: 0.0158 - val_loss: 0.0061 - 769ms/epoch - 4ms/step\n",
            "Epoch 6/700\n",
            "190/190 - 1s - loss: 0.0146 - val_loss: 0.0057 - 795ms/epoch - 4ms/step\n",
            "Epoch 7/700\n",
            "190/190 - 1s - loss: 0.0134 - val_loss: 0.0052 - 637ms/epoch - 3ms/step\n",
            "Epoch 8/700\n",
            "190/190 - 1s - loss: 0.0124 - val_loss: 0.0048 - 766ms/epoch - 4ms/step\n",
            "Epoch 9/700\n",
            "190/190 - 1s - loss: 0.0114 - val_loss: 0.0043 - 939ms/epoch - 5ms/step\n",
            "Epoch 10/700\n",
            "190/190 - 1s - loss: 0.0106 - val_loss: 0.0039 - 809ms/epoch - 4ms/step\n",
            "Epoch 11/700\n",
            "190/190 - 1s - loss: 0.0098 - val_loss: 0.0036 - 817ms/epoch - 4ms/step\n",
            "Epoch 12/700\n",
            "190/190 - 1s - loss: 0.0091 - val_loss: 0.0032 - 750ms/epoch - 4ms/step\n",
            "Epoch 13/700\n",
            "190/190 - 1s - loss: 0.0086 - val_loss: 0.0030 - 800ms/epoch - 4ms/step\n",
            "Epoch 14/700\n",
            "190/190 - 1s - loss: 0.0081 - val_loss: 0.0027 - 773ms/epoch - 4ms/step\n",
            "Epoch 15/700\n",
            "190/190 - 1s - loss: 0.0077 - val_loss: 0.0025 - 810ms/epoch - 4ms/step\n",
            "Epoch 16/700\n",
            "190/190 - 1s - loss: 0.0073 - val_loss: 0.0023 - 795ms/epoch - 4ms/step\n",
            "Epoch 17/700\n",
            "190/190 - 1s - loss: 0.0070 - val_loss: 0.0021 - 737ms/epoch - 4ms/step\n",
            "Epoch 18/700\n",
            "190/190 - 1s - loss: 0.0067 - val_loss: 0.0020 - 879ms/epoch - 5ms/step\n",
            "Epoch 19/700\n",
            "190/190 - 1s - loss: 0.0065 - val_loss: 0.0018 - 632ms/epoch - 3ms/step\n",
            "Epoch 20/700\n",
            "190/190 - 1s - loss: 0.0063 - val_loss: 0.0017 - 717ms/epoch - 4ms/step\n",
            "Epoch 21/700\n",
            "190/190 - 1s - loss: 0.0062 - val_loss: 0.0016 - 818ms/epoch - 4ms/step\n",
            "Epoch 22/700\n",
            "190/190 - 1s - loss: 0.0060 - val_loss: 0.0016 - 755ms/epoch - 4ms/step\n",
            "Epoch 23/700\n",
            "190/190 - 1s - loss: 0.0059 - val_loss: 0.0015 - 790ms/epoch - 4ms/step\n",
            "Epoch 24/700\n",
            "190/190 - 1s - loss: 0.0058 - val_loss: 0.0014 - 785ms/epoch - 4ms/step\n",
            "Epoch 25/700\n",
            "190/190 - 1s - loss: 0.0056 - val_loss: 0.0014 - 766ms/epoch - 4ms/step\n",
            "Epoch 26/700\n",
            "190/190 - 1s - loss: 0.0055 - val_loss: 0.0013 - 837ms/epoch - 4ms/step\n",
            "Epoch 27/700\n",
            "190/190 - 1s - loss: 0.0054 - val_loss: 0.0012 - 917ms/epoch - 5ms/step\n",
            "Epoch 28/700\n",
            "190/190 - 1s - loss: 0.0054 - val_loss: 0.0012 - 1s/epoch - 6ms/step\n",
            "Epoch 29/700\n",
            "190/190 - 1s - loss: 0.0053 - val_loss: 0.0012 - 1s/epoch - 6ms/step\n",
            "Epoch 30/700\n",
            "190/190 - 1s - loss: 0.0052 - val_loss: 0.0011 - 718ms/epoch - 4ms/step\n",
            "Epoch 31/700\n",
            "190/190 - 1s - loss: 0.0051 - val_loss: 0.0011 - 699ms/epoch - 4ms/step\n",
            "Epoch 32/700\n",
            "190/190 - 1s - loss: 0.0051 - val_loss: 0.0010 - 886ms/epoch - 5ms/step\n",
            "Epoch 33/700\n",
            "190/190 - 1s - loss: 0.0050 - val_loss: 9.8568e-04 - 738ms/epoch - 4ms/step\n",
            "Epoch 34/700\n",
            "190/190 - 1s - loss: 0.0050 - val_loss: 9.4862e-04 - 926ms/epoch - 5ms/step\n",
            "Epoch 35/700\n",
            "190/190 - 1s - loss: 0.0049 - val_loss: 9.1324e-04 - 888ms/epoch - 5ms/step\n",
            "Epoch 36/700\n",
            "190/190 - 1s - loss: 0.0049 - val_loss: 8.7951e-04 - 944ms/epoch - 5ms/step\n",
            "Epoch 37/700\n",
            "190/190 - 1s - loss: 0.0048 - val_loss: 8.4741e-04 - 686ms/epoch - 4ms/step\n",
            "Epoch 38/700\n",
            "190/190 - 1s - loss: 0.0048 - val_loss: 8.1689e-04 - 874ms/epoch - 5ms/step\n",
            "Epoch 39/700\n",
            "190/190 - 1s - loss: 0.0047 - val_loss: 7.8794e-04 - 747ms/epoch - 4ms/step\n",
            "Epoch 40/700\n",
            "190/190 - 1s - loss: 0.0047 - val_loss: 7.6052e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 41/700\n",
            "190/190 - 1s - loss: 0.0047 - val_loss: 7.3458e-04 - 823ms/epoch - 4ms/step\n",
            "Epoch 42/700\n",
            "190/190 - 1s - loss: 0.0046 - val_loss: 7.1010e-04 - 697ms/epoch - 4ms/step\n",
            "Epoch 43/700\n",
            "190/190 - 1s - loss: 0.0046 - val_loss: 6.8702e-04 - 804ms/epoch - 4ms/step\n",
            "Epoch 44/700\n",
            "190/190 - 1s - loss: 0.0046 - val_loss: 6.6529e-04 - 784ms/epoch - 4ms/step\n",
            "Epoch 45/700\n",
            "190/190 - 1s - loss: 0.0046 - val_loss: 6.4487e-04 - 782ms/epoch - 4ms/step\n",
            "Epoch 46/700\n",
            "190/190 - 1s - loss: 0.0045 - val_loss: 6.2568e-04 - 817ms/epoch - 4ms/step\n",
            "Epoch 47/700\n",
            "190/190 - 1s - loss: 0.0045 - val_loss: 6.0769e-04 - 786ms/epoch - 4ms/step\n",
            "Epoch 48/700\n",
            "190/190 - 1s - loss: 0.0045 - val_loss: 5.9083e-04 - 704ms/epoch - 4ms/step\n",
            "Epoch 49/700\n",
            "190/190 - 1s - loss: 0.0045 - val_loss: 5.7504e-04 - 901ms/epoch - 5ms/step\n",
            "Epoch 50/700\n",
            "190/190 - 1s - loss: 0.0045 - val_loss: 5.6027e-04 - 800ms/epoch - 4ms/step\n",
            "Epoch 51/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 5.4647e-04 - 871ms/epoch - 5ms/step\n",
            "Epoch 52/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 5.3358e-04 - 784ms/epoch - 4ms/step\n",
            "Epoch 53/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 5.2155e-04 - 849ms/epoch - 4ms/step\n",
            "Epoch 54/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 5.1033e-04 - 810ms/epoch - 4ms/step\n",
            "Epoch 55/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 4.9987e-04 - 831ms/epoch - 4ms/step\n",
            "Epoch 56/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 4.9012e-04 - 935ms/epoch - 5ms/step\n",
            "Epoch 57/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 4.8105e-04 - 866ms/epoch - 5ms/step\n",
            "Epoch 58/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 4.7261e-04 - 734ms/epoch - 4ms/step\n",
            "Epoch 59/700\n",
            "190/190 - 1s - loss: 0.0044 - val_loss: 4.6476e-04 - 684ms/epoch - 4ms/step\n",
            "Epoch 60/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.5746e-04 - 902ms/epoch - 5ms/step\n",
            "Epoch 61/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.5067e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 62/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.4435e-04 - 712ms/epoch - 4ms/step\n",
            "Epoch 63/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.3849e-04 - 835ms/epoch - 4ms/step\n",
            "Epoch 64/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.3303e-04 - 813ms/epoch - 4ms/step\n",
            "Epoch 65/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.2796e-04 - 828ms/epoch - 4ms/step\n",
            "Epoch 66/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.2324e-04 - 748ms/epoch - 4ms/step\n",
            "Epoch 67/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.1885e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 68/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.1477e-04 - 809ms/epoch - 4ms/step\n",
            "Epoch 69/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.1097e-04 - 846ms/epoch - 4ms/step\n",
            "Epoch 70/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.0743e-04 - 769ms/epoch - 4ms/step\n",
            "Epoch 71/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.0413e-04 - 796ms/epoch - 4ms/step\n",
            "Epoch 72/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 4.0106e-04 - 844ms/epoch - 4ms/step\n",
            "Epoch 73/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.9818e-04 - 866ms/epoch - 5ms/step\n",
            "Epoch 74/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.9550e-04 - 860ms/epoch - 5ms/step\n",
            "Epoch 75/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.9299e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 76/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.9064e-04 - 742ms/epoch - 4ms/step\n",
            "Epoch 77/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.8844e-04 - 829ms/epoch - 4ms/step\n",
            "Epoch 78/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.8637e-04 - 846ms/epoch - 4ms/step\n",
            "Epoch 79/700\n",
            "190/190 - 1s - loss: 0.0043 - val_loss: 3.8443e-04 - 792ms/epoch - 4ms/step\n",
            "Epoch 80/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.8261e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 81/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.8089e-04 - 737ms/epoch - 4ms/step\n",
            "Epoch 82/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7928e-04 - 679ms/epoch - 4ms/step\n",
            "Epoch 83/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7775e-04 - 764ms/epoch - 4ms/step\n",
            "Epoch 84/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7631e-04 - 733ms/epoch - 4ms/step\n",
            "Epoch 85/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7494e-04 - 648ms/epoch - 3ms/step\n",
            "Epoch 86/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7365e-04 - 731ms/epoch - 4ms/step\n",
            "Epoch 87/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7243e-04 - 682ms/epoch - 4ms/step\n",
            "Epoch 88/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7127e-04 - 824ms/epoch - 4ms/step\n",
            "Epoch 89/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.7017e-04 - 797ms/epoch - 4ms/step\n",
            "Epoch 90/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6912e-04 - 821ms/epoch - 4ms/step\n",
            "Epoch 91/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6813e-04 - 848ms/epoch - 4ms/step\n",
            "Epoch 92/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6718e-04 - 817ms/epoch - 4ms/step\n",
            "Epoch 93/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6627e-04 - 834ms/epoch - 4ms/step\n",
            "Epoch 94/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6541e-04 - 809ms/epoch - 4ms/step\n",
            "Epoch 95/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6459e-04 - 821ms/epoch - 4ms/step\n",
            "Epoch 96/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6380e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 97/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6305e-04 - 774ms/epoch - 4ms/step\n",
            "Epoch 98/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6234e-04 - 710ms/epoch - 4ms/step\n",
            "Epoch 99/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6165e-04 - 732ms/epoch - 4ms/step\n",
            "Epoch 100/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6099e-04 - 663ms/epoch - 3ms/step\n",
            "Epoch 101/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.6037e-04 - 821ms/epoch - 4ms/step\n",
            "Epoch 102/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5976e-04 - 767ms/epoch - 4ms/step\n",
            "Epoch 103/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5919e-04 - 721ms/epoch - 4ms/step\n",
            "Epoch 104/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5864e-04 - 889ms/epoch - 5ms/step\n",
            "Epoch 105/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5811e-04 - 919ms/epoch - 5ms/step\n",
            "Epoch 106/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5761e-04 - 815ms/epoch - 4ms/step\n",
            "Epoch 107/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5713e-04 - 698ms/epoch - 4ms/step\n",
            "Epoch 108/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5666e-04 - 671ms/epoch - 4ms/step\n",
            "Epoch 109/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5622e-04 - 742ms/epoch - 4ms/step\n",
            "Epoch 110/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5580e-04 - 717ms/epoch - 4ms/step\n",
            "Epoch 111/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5539e-04 - 764ms/epoch - 4ms/step\n",
            "Epoch 112/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5501e-04 - 874ms/epoch - 5ms/step\n",
            "Epoch 113/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5464e-04 - 878ms/epoch - 5ms/step\n",
            "Epoch 114/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5429e-04 - 821ms/epoch - 4ms/step\n",
            "Epoch 115/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5395e-04 - 765ms/epoch - 4ms/step\n",
            "Epoch 116/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5363e-04 - 822ms/epoch - 4ms/step\n",
            "Epoch 117/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5332e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 118/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5303e-04 - 822ms/epoch - 4ms/step\n",
            "Epoch 119/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5276e-04 - 815ms/epoch - 4ms/step\n",
            "Epoch 120/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5250e-04 - 795ms/epoch - 4ms/step\n",
            "Epoch 121/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5225e-04 - 746ms/epoch - 4ms/step\n",
            "Epoch 122/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5201e-04 - 756ms/epoch - 4ms/step\n",
            "Epoch 123/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5179e-04 - 877ms/epoch - 5ms/step\n",
            "Epoch 124/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5158e-04 - 712ms/epoch - 4ms/step\n",
            "Epoch 125/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5138e-04 - 804ms/epoch - 4ms/step\n",
            "Epoch 126/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5119e-04 - 716ms/epoch - 4ms/step\n",
            "Epoch 127/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5101e-04 - 862ms/epoch - 5ms/step\n",
            "Epoch 128/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5085e-04 - 879ms/epoch - 5ms/step\n",
            "Epoch 129/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5070e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 130/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5055e-04 - 863ms/epoch - 5ms/step\n",
            "Epoch 131/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5042e-04 - 724ms/epoch - 4ms/step\n",
            "Epoch 132/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5030e-04 - 694ms/epoch - 4ms/step\n",
            "Epoch 133/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5019e-04 - 792ms/epoch - 4ms/step\n",
            "Epoch 134/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.5008e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 135/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4999e-04 - 747ms/epoch - 4ms/step\n",
            "Epoch 136/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4990e-04 - 722ms/epoch - 4ms/step\n",
            "Epoch 137/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4983e-04 - 766ms/epoch - 4ms/step\n",
            "Epoch 138/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4976e-04 - 824ms/epoch - 4ms/step\n",
            "Epoch 139/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4970e-04 - 740ms/epoch - 4ms/step\n",
            "Epoch 140/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4965e-04 - 814ms/epoch - 4ms/step\n",
            "Epoch 141/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4961e-04 - 702ms/epoch - 4ms/step\n",
            "Epoch 142/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4958e-04 - 742ms/epoch - 4ms/step\n",
            "Epoch 143/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4955e-04 - 743ms/epoch - 4ms/step\n",
            "Epoch 144/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4953e-04 - 811ms/epoch - 4ms/step\n",
            "Epoch 145/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4952e-04 - 766ms/epoch - 4ms/step\n",
            "Epoch 146/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4952e-04 - 755ms/epoch - 4ms/step\n",
            "Epoch 147/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4952e-04 - 682ms/epoch - 4ms/step\n",
            "Epoch 148/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4953e-04 - 806ms/epoch - 4ms/step\n",
            "Epoch 149/700\n",
            "190/190 - 1s - loss: 0.0042 - val_loss: 3.4954e-04 - 709ms/epoch - 4ms/step\n",
            "Epoch 150/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4957e-04 - 639ms/epoch - 3ms/step\n",
            "Epoch 151/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4960e-04 - 705ms/epoch - 4ms/step\n",
            "Epoch 152/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4963e-04 - 772ms/epoch - 4ms/step\n",
            "Epoch 153/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4968e-04 - 745ms/epoch - 4ms/step\n",
            "Epoch 154/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4972e-04 - 721ms/epoch - 4ms/step\n",
            "Epoch 155/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4978e-04 - 613ms/epoch - 3ms/step\n",
            "Epoch 156/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4984e-04 - 742ms/epoch - 4ms/step\n",
            "Epoch 157/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4990e-04 - 678ms/epoch - 4ms/step\n",
            "Epoch 158/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.4997e-04 - 687ms/epoch - 4ms/step\n",
            "Epoch 159/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5005e-04 - 638ms/epoch - 3ms/step\n",
            "Epoch 160/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5013e-04 - 653ms/epoch - 3ms/step\n",
            "Epoch 161/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5022e-04 - 755ms/epoch - 4ms/step\n",
            "Epoch 162/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5031e-04 - 614ms/epoch - 3ms/step\n",
            "Epoch 163/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5040e-04 - 692ms/epoch - 4ms/step\n",
            "Epoch 164/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5050e-04 - 773ms/epoch - 4ms/step\n",
            "Epoch 165/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5061e-04 - 811ms/epoch - 4ms/step\n",
            "Epoch 166/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5072e-04 - 659ms/epoch - 3ms/step\n",
            "Epoch 167/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5083e-04 - 723ms/epoch - 4ms/step\n",
            "Epoch 168/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5095e-04 - 686ms/epoch - 4ms/step\n",
            "Epoch 169/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5108e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 170/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5120e-04 - 725ms/epoch - 4ms/step\n",
            "Epoch 171/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5133e-04 - 734ms/epoch - 4ms/step\n",
            "Epoch 172/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5147e-04 - 803ms/epoch - 4ms/step\n",
            "Epoch 173/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5161e-04 - 726ms/epoch - 4ms/step\n",
            "Epoch 174/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5175e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 175/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5190e-04 - 733ms/epoch - 4ms/step\n",
            "Epoch 176/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5205e-04 - 778ms/epoch - 4ms/step\n",
            "Epoch 177/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5221e-04 - 694ms/epoch - 4ms/step\n",
            "Epoch 178/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5236e-04 - 663ms/epoch - 3ms/step\n",
            "Epoch 179/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5252e-04 - 686ms/epoch - 4ms/step\n",
            "Epoch 180/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5269e-04 - 692ms/epoch - 4ms/step\n",
            "Epoch 181/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5286e-04 - 668ms/epoch - 4ms/step\n",
            "Epoch 182/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5303e-04 - 740ms/epoch - 4ms/step\n",
            "Epoch 183/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5320e-04 - 791ms/epoch - 4ms/step\n",
            "Epoch 184/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5338e-04 - 690ms/epoch - 4ms/step\n",
            "Epoch 185/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5356e-04 - 719ms/epoch - 4ms/step\n",
            "Epoch 186/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5375e-04 - 715ms/epoch - 4ms/step\n",
            "Epoch 187/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5393e-04 - 746ms/epoch - 4ms/step\n",
            "Epoch 188/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5412e-04 - 743ms/epoch - 4ms/step\n",
            "Epoch 189/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5431e-04 - 865ms/epoch - 5ms/step\n",
            "Epoch 190/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5451e-04 - 806ms/epoch - 4ms/step\n",
            "Epoch 191/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5471e-04 - 902ms/epoch - 5ms/step\n",
            "Epoch 192/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5491e-04 - 978ms/epoch - 5ms/step\n",
            "Epoch 193/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5511e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 194/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5531e-04 - 984ms/epoch - 5ms/step\n",
            "Epoch 195/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5552e-04 - 823ms/epoch - 4ms/step\n",
            "Epoch 196/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5573e-04 - 753ms/epoch - 4ms/step\n",
            "Epoch 197/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5595e-04 - 729ms/epoch - 4ms/step\n",
            "Epoch 198/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5616e-04 - 839ms/epoch - 4ms/step\n",
            "Epoch 199/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5638e-04 - 684ms/epoch - 4ms/step\n",
            "Epoch 200/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5660e-04 - 767ms/epoch - 4ms/step\n",
            "Epoch 201/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5682e-04 - 727ms/epoch - 4ms/step\n",
            "Epoch 202/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5705e-04 - 804ms/epoch - 4ms/step\n",
            "Epoch 203/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5727e-04 - 778ms/epoch - 4ms/step\n",
            "Epoch 204/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5750e-04 - 825ms/epoch - 4ms/step\n",
            "Epoch 205/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5774e-04 - 851ms/epoch - 4ms/step\n",
            "Epoch 206/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5797e-04 - 928ms/epoch - 5ms/step\n",
            "Epoch 207/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5820e-04 - 720ms/epoch - 4ms/step\n",
            "Epoch 208/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5844e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 209/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5868e-04 - 814ms/epoch - 4ms/step\n",
            "Epoch 210/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5892e-04 - 740ms/epoch - 4ms/step\n",
            "Epoch 211/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5916e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 212/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5941e-04 - 803ms/epoch - 4ms/step\n",
            "Epoch 213/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5966e-04 - 774ms/epoch - 4ms/step\n",
            "Epoch 214/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.5991e-04 - 789ms/epoch - 4ms/step\n",
            "Epoch 215/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6016e-04 - 937ms/epoch - 5ms/step\n",
            "Epoch 216/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6041e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 217/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6066e-04 - 784ms/epoch - 4ms/step\n",
            "Epoch 218/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6092e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 219/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6118e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 220/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6144e-04 - 692ms/epoch - 4ms/step\n",
            "Epoch 221/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6170e-04 - 793ms/epoch - 4ms/step\n",
            "Epoch 222/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6196e-04 - 662ms/epoch - 3ms/step\n",
            "Epoch 223/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6223e-04 - 710ms/epoch - 4ms/step\n",
            "Epoch 224/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6249e-04 - 685ms/epoch - 4ms/step\n",
            "Epoch 225/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6276e-04 - 826ms/epoch - 4ms/step\n",
            "Epoch 226/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6303e-04 - 866ms/epoch - 5ms/step\n",
            "Epoch 227/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6330e-04 - 814ms/epoch - 4ms/step\n",
            "Epoch 228/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6357e-04 - 727ms/epoch - 4ms/step\n",
            "Epoch 229/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6385e-04 - 822ms/epoch - 4ms/step\n",
            "Epoch 230/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6412e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 231/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6440e-04 - 795ms/epoch - 4ms/step\n",
            "Epoch 232/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6468e-04 - 735ms/epoch - 4ms/step\n",
            "Epoch 233/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6496e-04 - 775ms/epoch - 4ms/step\n",
            "Epoch 234/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6524e-04 - 768ms/epoch - 4ms/step\n",
            "Epoch 235/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6552e-04 - 730ms/epoch - 4ms/step\n",
            "Epoch 236/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6581e-04 - 830ms/epoch - 4ms/step\n",
            "Epoch 237/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6609e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 238/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6638e-04 - 736ms/epoch - 4ms/step\n",
            "Epoch 239/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6667e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 240/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6696e-04 - 841ms/epoch - 4ms/step\n",
            "Epoch 241/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6725e-04 - 966ms/epoch - 5ms/step\n",
            "Epoch 242/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6754e-04 - 823ms/epoch - 4ms/step\n",
            "Epoch 243/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6784e-04 - 885ms/epoch - 5ms/step\n",
            "Epoch 244/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6813e-04 - 975ms/epoch - 5ms/step\n",
            "Epoch 245/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6843e-04 - 854ms/epoch - 4ms/step\n",
            "Epoch 246/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6873e-04 - 854ms/epoch - 4ms/step\n",
            "Epoch 247/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6903e-04 - 769ms/epoch - 4ms/step\n",
            "Epoch 248/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6933e-04 - 717ms/epoch - 4ms/step\n",
            "Epoch 249/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6963e-04 - 779ms/epoch - 4ms/step\n",
            "Epoch 250/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.6993e-04 - 807ms/epoch - 4ms/step\n",
            "Epoch 251/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7024e-04 - 713ms/epoch - 4ms/step\n",
            "Epoch 252/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7054e-04 - 771ms/epoch - 4ms/step\n",
            "Epoch 253/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7085e-04 - 779ms/epoch - 4ms/step\n",
            "Epoch 254/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7116e-04 - 737ms/epoch - 4ms/step\n",
            "Epoch 255/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7147e-04 - 689ms/epoch - 4ms/step\n",
            "Epoch 256/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7178e-04 - 853ms/epoch - 4ms/step\n",
            "Epoch 257/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7209e-04 - 893ms/epoch - 5ms/step\n",
            "Epoch 258/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7240e-04 - 813ms/epoch - 4ms/step\n",
            "Epoch 259/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7272e-04 - 865ms/epoch - 5ms/step\n",
            "Epoch 260/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7303e-04 - 889ms/epoch - 5ms/step\n",
            "Epoch 261/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7335e-04 - 793ms/epoch - 4ms/step\n",
            "Epoch 262/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7367e-04 - 663ms/epoch - 3ms/step\n",
            "Epoch 263/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7399e-04 - 793ms/epoch - 4ms/step\n",
            "Epoch 264/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7431e-04 - 850ms/epoch - 4ms/step\n",
            "Epoch 265/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7463e-04 - 835ms/epoch - 4ms/step\n",
            "Epoch 266/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7495e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 267/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7527e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 268/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7560e-04 - 816ms/epoch - 4ms/step\n",
            "Epoch 269/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7592e-04 - 791ms/epoch - 4ms/step\n",
            "Epoch 270/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7625e-04 - 957ms/epoch - 5ms/step\n",
            "Epoch 271/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7657e-04 - 891ms/epoch - 5ms/step\n",
            "Epoch 272/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7690e-04 - 767ms/epoch - 4ms/step\n",
            "Epoch 273/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7723e-04 - 805ms/epoch - 4ms/step\n",
            "Epoch 274/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7756e-04 - 783ms/epoch - 4ms/step\n",
            "Epoch 275/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7789e-04 - 818ms/epoch - 4ms/step\n",
            "Epoch 276/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7823e-04 - 783ms/epoch - 4ms/step\n",
            "Epoch 277/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7856e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 278/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7890e-04 - 896ms/epoch - 5ms/step\n",
            "Epoch 279/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7923e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 280/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7957e-04 - 827ms/epoch - 4ms/step\n",
            "Epoch 281/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.7991e-04 - 837ms/epoch - 4ms/step\n",
            "Epoch 282/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8024e-04 - 844ms/epoch - 4ms/step\n",
            "Epoch 283/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8058e-04 - 695ms/epoch - 4ms/step\n",
            "Epoch 284/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8092e-04 - 781ms/epoch - 4ms/step\n",
            "Epoch 285/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8126e-04 - 812ms/epoch - 4ms/step\n",
            "Epoch 286/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8161e-04 - 759ms/epoch - 4ms/step\n",
            "Epoch 287/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8195e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 288/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8229e-04 - 696ms/epoch - 4ms/step\n",
            "Epoch 289/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8264e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 290/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8299e-04 - 742ms/epoch - 4ms/step\n",
            "Epoch 291/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8333e-04 - 744ms/epoch - 4ms/step\n",
            "Epoch 292/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8368e-04 - 768ms/epoch - 4ms/step\n",
            "Epoch 293/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8403e-04 - 657ms/epoch - 3ms/step\n",
            "Epoch 294/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8438e-04 - 639ms/epoch - 3ms/step\n",
            "Epoch 295/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8473e-04 - 772ms/epoch - 4ms/step\n",
            "Epoch 296/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8508e-04 - 655ms/epoch - 3ms/step\n",
            "Epoch 297/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8543e-04 - 662ms/epoch - 3ms/step\n",
            "Epoch 298/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8578e-04 - 732ms/epoch - 4ms/step\n",
            "Epoch 299/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8614e-04 - 716ms/epoch - 4ms/step\n",
            "Epoch 300/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8649e-04 - 719ms/epoch - 4ms/step\n",
            "Epoch 301/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8685e-04 - 878ms/epoch - 5ms/step\n",
            "Epoch 302/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8720e-04 - 860ms/epoch - 5ms/step\n",
            "Epoch 303/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8756e-04 - 680ms/epoch - 4ms/step\n",
            "Epoch 304/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8792e-04 - 804ms/epoch - 4ms/step\n",
            "Epoch 305/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8828e-04 - 725ms/epoch - 4ms/step\n",
            "Epoch 306/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8863e-04 - 747ms/epoch - 4ms/step\n",
            "Epoch 307/700\n",
            "190/190 - 1s - loss: 0.0041 - val_loss: 3.8899e-04 - 748ms/epoch - 4ms/step\n",
            "Epoch 308/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.8935e-04 - 758ms/epoch - 4ms/step\n",
            "Epoch 309/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.8972e-04 - 855ms/epoch - 5ms/step\n",
            "Epoch 310/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9008e-04 - 864ms/epoch - 5ms/step\n",
            "Epoch 311/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9044e-04 - 726ms/epoch - 4ms/step\n",
            "Epoch 312/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9080e-04 - 805ms/epoch - 4ms/step\n",
            "Epoch 313/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9117e-04 - 861ms/epoch - 5ms/step\n",
            "Epoch 314/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9153e-04 - 728ms/epoch - 4ms/step\n",
            "Epoch 315/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9189e-04 - 669ms/epoch - 4ms/step\n",
            "Epoch 316/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9226e-04 - 686ms/epoch - 4ms/step\n",
            "Epoch 317/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9263e-04 - 800ms/epoch - 4ms/step\n",
            "Epoch 318/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9299e-04 - 765ms/epoch - 4ms/step\n",
            "Epoch 319/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9336e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 320/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9373e-04 - 828ms/epoch - 4ms/step\n",
            "Epoch 321/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9410e-04 - 697ms/epoch - 4ms/step\n",
            "Epoch 322/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9447e-04 - 839ms/epoch - 4ms/step\n",
            "Epoch 323/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9484e-04 - 883ms/epoch - 5ms/step\n",
            "Epoch 324/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9521e-04 - 791ms/epoch - 4ms/step\n",
            "Epoch 325/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9558e-04 - 882ms/epoch - 5ms/step\n",
            "Epoch 326/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9595e-04 - 746ms/epoch - 4ms/step\n",
            "Epoch 327/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9632e-04 - 766ms/epoch - 4ms/step\n",
            "Epoch 328/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9669e-04 - 778ms/epoch - 4ms/step\n",
            "Epoch 329/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9706e-04 - 720ms/epoch - 4ms/step\n",
            "Epoch 330/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9744e-04 - 800ms/epoch - 4ms/step\n",
            "Epoch 331/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9781e-04 - 738ms/epoch - 4ms/step\n",
            "Epoch 332/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9819e-04 - 834ms/epoch - 4ms/step\n",
            "Epoch 333/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9856e-04 - 707ms/epoch - 4ms/step\n",
            "Epoch 334/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9894e-04 - 755ms/epoch - 4ms/step\n",
            "Epoch 335/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9931e-04 - 797ms/epoch - 4ms/step\n",
            "Epoch 336/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 3.9969e-04 - 794ms/epoch - 4ms/step\n",
            "Epoch 337/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0006e-04 - 834ms/epoch - 4ms/step\n",
            "Epoch 338/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0044e-04 - 787ms/epoch - 4ms/step\n",
            "Epoch 339/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0082e-04 - 724ms/epoch - 4ms/step\n",
            "Epoch 340/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0119e-04 - 728ms/epoch - 4ms/step\n",
            "Epoch 341/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0157e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 342/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0195e-04 - 832ms/epoch - 4ms/step\n",
            "Epoch 343/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0233e-04 - 846ms/epoch - 4ms/step\n",
            "Epoch 344/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0271e-04 - 795ms/epoch - 4ms/step\n",
            "Epoch 345/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0308e-04 - 720ms/epoch - 4ms/step\n",
            "Epoch 346/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0346e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 347/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0384e-04 - 662ms/epoch - 3ms/step\n",
            "Epoch 348/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0422e-04 - 566ms/epoch - 3ms/step\n",
            "Epoch 349/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0460e-04 - 663ms/epoch - 3ms/step\n",
            "Epoch 350/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0498e-04 - 679ms/epoch - 4ms/step\n",
            "Epoch 351/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0536e-04 - 734ms/epoch - 4ms/step\n",
            "Epoch 352/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0575e-04 - 740ms/epoch - 4ms/step\n",
            "Epoch 353/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0613e-04 - 890ms/epoch - 5ms/step\n",
            "Epoch 354/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0651e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 355/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0689e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 356/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0727e-04 - 875ms/epoch - 5ms/step\n",
            "Epoch 357/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0765e-04 - 780ms/epoch - 4ms/step\n",
            "Epoch 358/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0803e-04 - 753ms/epoch - 4ms/step\n",
            "Epoch 359/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0842e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 360/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0880e-04 - 737ms/epoch - 4ms/step\n",
            "Epoch 361/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0918e-04 - 585ms/epoch - 3ms/step\n",
            "Epoch 362/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0956e-04 - 665ms/epoch - 4ms/step\n",
            "Epoch 363/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.0995e-04 - 826ms/epoch - 4ms/step\n",
            "Epoch 364/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1033e-04 - 596ms/epoch - 3ms/step\n",
            "Epoch 365/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1071e-04 - 749ms/epoch - 4ms/step\n",
            "Epoch 366/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1109e-04 - 723ms/epoch - 4ms/step\n",
            "Epoch 367/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1148e-04 - 697ms/epoch - 4ms/step\n",
            "Epoch 368/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1186e-04 - 698ms/epoch - 4ms/step\n",
            "Epoch 369/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1224e-04 - 690ms/epoch - 4ms/step\n",
            "Epoch 370/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1263e-04 - 811ms/epoch - 4ms/step\n",
            "Epoch 371/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1301e-04 - 852ms/epoch - 4ms/step\n",
            "Epoch 372/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1339e-04 - 648ms/epoch - 3ms/step\n",
            "Epoch 373/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1378e-04 - 778ms/epoch - 4ms/step\n",
            "Epoch 374/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1416e-04 - 900ms/epoch - 5ms/step\n",
            "Epoch 375/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1454e-04 - 922ms/epoch - 5ms/step\n",
            "Epoch 376/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1493e-04 - 768ms/epoch - 4ms/step\n",
            "Epoch 377/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1531e-04 - 814ms/epoch - 4ms/step\n",
            "Epoch 378/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1569e-04 - 776ms/epoch - 4ms/step\n",
            "Epoch 379/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1607e-04 - 731ms/epoch - 4ms/step\n",
            "Epoch 380/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1646e-04 - 797ms/epoch - 4ms/step\n",
            "Epoch 381/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1684e-04 - 734ms/epoch - 4ms/step\n",
            "Epoch 382/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1722e-04 - 784ms/epoch - 4ms/step\n",
            "Epoch 383/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1761e-04 - 768ms/epoch - 4ms/step\n",
            "Epoch 384/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1799e-04 - 682ms/epoch - 4ms/step\n",
            "Epoch 385/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1837e-04 - 594ms/epoch - 3ms/step\n",
            "Epoch 386/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1875e-04 - 786ms/epoch - 4ms/step\n",
            "Epoch 387/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1914e-04 - 862ms/epoch - 5ms/step\n",
            "Epoch 388/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1952e-04 - 782ms/epoch - 4ms/step\n",
            "Epoch 389/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.1990e-04 - 628ms/epoch - 3ms/step\n",
            "Epoch 390/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2028e-04 - 905ms/epoch - 5ms/step\n",
            "Epoch 391/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2066e-04 - 819ms/epoch - 4ms/step\n",
            "Epoch 392/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2104e-04 - 780ms/epoch - 4ms/step\n",
            "Epoch 393/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2142e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 394/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2181e-04 - 931ms/epoch - 5ms/step\n",
            "Epoch 395/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2219e-04 - 949ms/epoch - 5ms/step\n",
            "Epoch 396/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2257e-04 - 816ms/epoch - 4ms/step\n",
            "Epoch 397/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2295e-04 - 818ms/epoch - 4ms/step\n",
            "Epoch 398/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2333e-04 - 798ms/epoch - 4ms/step\n",
            "Epoch 399/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2371e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 400/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2409e-04 - 877ms/epoch - 5ms/step\n",
            "Epoch 401/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2447e-04 - 753ms/epoch - 4ms/step\n",
            "Epoch 402/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2485e-04 - 817ms/epoch - 4ms/step\n",
            "Epoch 403/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2523e-04 - 846ms/epoch - 4ms/step\n",
            "Epoch 404/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2560e-04 - 770ms/epoch - 4ms/step\n",
            "Epoch 405/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2598e-04 - 839ms/epoch - 4ms/step\n",
            "Epoch 406/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2636e-04 - 901ms/epoch - 5ms/step\n",
            "Epoch 407/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2674e-04 - 691ms/epoch - 4ms/step\n",
            "Epoch 408/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2712e-04 - 817ms/epoch - 4ms/step\n",
            "Epoch 409/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2749e-04 - 833ms/epoch - 4ms/step\n",
            "Epoch 410/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2787e-04 - 765ms/epoch - 4ms/step\n",
            "Epoch 411/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2825e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 412/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2862e-04 - 778ms/epoch - 4ms/step\n",
            "Epoch 413/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2900e-04 - 772ms/epoch - 4ms/step\n",
            "Epoch 414/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2937e-04 - 707ms/epoch - 4ms/step\n",
            "Epoch 415/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.2975e-04 - 747ms/epoch - 4ms/step\n",
            "Epoch 416/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3012e-04 - 723ms/epoch - 4ms/step\n",
            "Epoch 417/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3050e-04 - 806ms/epoch - 4ms/step\n",
            "Epoch 418/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3087e-04 - 771ms/epoch - 4ms/step\n",
            "Epoch 419/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3125e-04 - 758ms/epoch - 4ms/step\n",
            "Epoch 420/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3162e-04 - 665ms/epoch - 3ms/step\n",
            "Epoch 421/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3199e-04 - 781ms/epoch - 4ms/step\n",
            "Epoch 422/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3236e-04 - 701ms/epoch - 4ms/step\n",
            "Epoch 423/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3273e-04 - 648ms/epoch - 3ms/step\n",
            "Epoch 424/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3311e-04 - 632ms/epoch - 3ms/step\n",
            "Epoch 425/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3348e-04 - 636ms/epoch - 3ms/step\n",
            "Epoch 426/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3385e-04 - 696ms/epoch - 4ms/step\n",
            "Epoch 427/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3422e-04 - 758ms/epoch - 4ms/step\n",
            "Epoch 428/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3459e-04 - 769ms/epoch - 4ms/step\n",
            "Epoch 429/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3496e-04 - 680ms/epoch - 4ms/step\n",
            "Epoch 430/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3533e-04 - 774ms/epoch - 4ms/step\n",
            "Epoch 431/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3569e-04 - 669ms/epoch - 4ms/step\n",
            "Epoch 432/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3606e-04 - 701ms/epoch - 4ms/step\n",
            "Epoch 433/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3643e-04 - 763ms/epoch - 4ms/step\n",
            "Epoch 434/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3679e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 435/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3716e-04 - 784ms/epoch - 4ms/step\n",
            "Epoch 436/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3753e-04 - 681ms/epoch - 4ms/step\n",
            "Epoch 437/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3789e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 438/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3826e-04 - 639ms/epoch - 3ms/step\n",
            "Epoch 439/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3862e-04 - 717ms/epoch - 4ms/step\n",
            "Epoch 440/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3898e-04 - 692ms/epoch - 4ms/step\n",
            "Epoch 441/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3935e-04 - 669ms/epoch - 4ms/step\n",
            "Epoch 442/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.3971e-04 - 625ms/epoch - 3ms/step\n",
            "Epoch 443/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4007e-04 - 644ms/epoch - 3ms/step\n",
            "Epoch 444/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4043e-04 - 704ms/epoch - 4ms/step\n",
            "Epoch 445/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4079e-04 - 729ms/epoch - 4ms/step\n",
            "Epoch 446/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4115e-04 - 905ms/epoch - 5ms/step\n",
            "Epoch 447/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4151e-04 - 706ms/epoch - 4ms/step\n",
            "Epoch 448/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4187e-04 - 797ms/epoch - 4ms/step\n",
            "Epoch 449/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4223e-04 - 766ms/epoch - 4ms/step\n",
            "Epoch 450/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4259e-04 - 843ms/epoch - 4ms/step\n",
            "Epoch 451/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4295e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 452/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4330e-04 - 754ms/epoch - 4ms/step\n",
            "Epoch 453/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4366e-04 - 802ms/epoch - 4ms/step\n",
            "Epoch 454/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4402e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 455/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4437e-04 - 705ms/epoch - 4ms/step\n",
            "Epoch 456/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4473e-04 - 713ms/epoch - 4ms/step\n",
            "Epoch 457/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4508e-04 - 729ms/epoch - 4ms/step\n",
            "Epoch 458/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4543e-04 - 679ms/epoch - 4ms/step\n",
            "Epoch 459/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4579e-04 - 635ms/epoch - 3ms/step\n",
            "Epoch 460/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4614e-04 - 821ms/epoch - 4ms/step\n",
            "Epoch 461/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4649e-04 - 713ms/epoch - 4ms/step\n",
            "Epoch 462/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4684e-04 - 708ms/epoch - 4ms/step\n",
            "Epoch 463/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4719e-04 - 801ms/epoch - 4ms/step\n",
            "Epoch 464/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4754e-04 - 652ms/epoch - 3ms/step\n",
            "Epoch 465/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4789e-04 - 745ms/epoch - 4ms/step\n",
            "Epoch 466/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4824e-04 - 697ms/epoch - 4ms/step\n",
            "Epoch 467/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4858e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 468/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4893e-04 - 736ms/epoch - 4ms/step\n",
            "Epoch 469/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4928e-04 - 775ms/epoch - 4ms/step\n",
            "Epoch 470/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4962e-04 - 674ms/epoch - 4ms/step\n",
            "Epoch 471/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.4997e-04 - 758ms/epoch - 4ms/step\n",
            "Epoch 472/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.5031e-04 - 800ms/epoch - 4ms/step\n",
            "Epoch 473/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.5066e-04 - 724ms/epoch - 4ms/step\n",
            "Epoch 474/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.5100e-04 - 732ms/epoch - 4ms/step\n",
            "Epoch 475/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.5134e-04 - 701ms/epoch - 4ms/step\n",
            "Epoch 476/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.5168e-04 - 880ms/epoch - 5ms/step\n",
            "Epoch 477/700\n",
            "190/190 - 1s - loss: 0.0040 - val_loss: 4.5202e-04 - 944ms/epoch - 5ms/step\n",
            "Epoch 478/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5236e-04 - 798ms/epoch - 4ms/step\n",
            "Epoch 479/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5270e-04 - 664ms/epoch - 3ms/step\n",
            "Epoch 480/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5304e-04 - 672ms/epoch - 4ms/step\n",
            "Epoch 481/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5338e-04 - 695ms/epoch - 4ms/step\n",
            "Epoch 482/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5372e-04 - 653ms/epoch - 3ms/step\n",
            "Epoch 483/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5405e-04 - 647ms/epoch - 3ms/step\n",
            "Epoch 484/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5439e-04 - 693ms/epoch - 4ms/step\n",
            "Epoch 485/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5472e-04 - 756ms/epoch - 4ms/step\n",
            "Epoch 486/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5506e-04 - 755ms/epoch - 4ms/step\n",
            "Epoch 487/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5539e-04 - 623ms/epoch - 3ms/step\n",
            "Epoch 488/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5573e-04 - 637ms/epoch - 3ms/step\n",
            "Epoch 489/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5606e-04 - 714ms/epoch - 4ms/step\n",
            "Epoch 490/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5639e-04 - 817ms/epoch - 4ms/step\n",
            "Epoch 491/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5672e-04 - 812ms/epoch - 4ms/step\n",
            "Epoch 492/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5705e-04 - 696ms/epoch - 4ms/step\n",
            "Epoch 493/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5738e-04 - 873ms/epoch - 5ms/step\n",
            "Epoch 494/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5771e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 495/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5804e-04 - 820ms/epoch - 4ms/step\n",
            "Epoch 496/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5837e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 497/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5869e-04 - 892ms/epoch - 5ms/step\n",
            "Epoch 498/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5902e-04 - 795ms/epoch - 4ms/step\n",
            "Epoch 499/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5934e-04 - 815ms/epoch - 4ms/step\n",
            "Epoch 500/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5967e-04 - 883ms/epoch - 5ms/step\n",
            "Epoch 501/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.5999e-04 - 789ms/epoch - 4ms/step\n",
            "Epoch 502/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6031e-04 - 895ms/epoch - 5ms/step\n",
            "Epoch 503/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6064e-04 - 849ms/epoch - 4ms/step\n",
            "Epoch 504/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6096e-04 - 882ms/epoch - 5ms/step\n",
            "Epoch 505/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6128e-04 - 679ms/epoch - 4ms/step\n",
            "Epoch 506/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6160e-04 - 804ms/epoch - 4ms/step\n",
            "Epoch 507/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6192e-04 - 833ms/epoch - 4ms/step\n",
            "Epoch 508/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6224e-04 - 756ms/epoch - 4ms/step\n",
            "Epoch 509/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6255e-04 - 827ms/epoch - 4ms/step\n",
            "Epoch 510/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6287e-04 - 876ms/epoch - 5ms/step\n",
            "Epoch 511/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6319e-04 - 875ms/epoch - 5ms/step\n",
            "Epoch 512/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6350e-04 - 793ms/epoch - 4ms/step\n",
            "Epoch 513/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6382e-04 - 839ms/epoch - 4ms/step\n",
            "Epoch 514/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6413e-04 - 754ms/epoch - 4ms/step\n",
            "Epoch 515/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6444e-04 - 963ms/epoch - 5ms/step\n",
            "Epoch 516/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6476e-04 - 955ms/epoch - 5ms/step\n",
            "Epoch 517/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6507e-04 - 804ms/epoch - 4ms/step\n",
            "Epoch 518/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6538e-04 - 859ms/epoch - 5ms/step\n",
            "Epoch 519/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6569e-04 - 970ms/epoch - 5ms/step\n",
            "Epoch 520/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6600e-04 - 830ms/epoch - 4ms/step\n",
            "Epoch 521/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6631e-04 - 887ms/epoch - 5ms/step\n",
            "Epoch 522/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6662e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 523/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6692e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 524/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6723e-04 - 868ms/epoch - 5ms/step\n",
            "Epoch 525/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6753e-04 - 916ms/epoch - 5ms/step\n",
            "Epoch 526/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6784e-04 - 933ms/epoch - 5ms/step\n",
            "Epoch 527/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6814e-04 - 880ms/epoch - 5ms/step\n",
            "Epoch 528/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6845e-04 - 922ms/epoch - 5ms/step\n",
            "Epoch 529/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6875e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 530/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6905e-04 - 890ms/epoch - 5ms/step\n",
            "Epoch 531/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6935e-04 - 976ms/epoch - 5ms/step\n",
            "Epoch 532/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6965e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 533/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.6995e-04 - 868ms/epoch - 5ms/step\n",
            "Epoch 534/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7025e-04 - 767ms/epoch - 4ms/step\n",
            "Epoch 535/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7055e-04 - 745ms/epoch - 4ms/step\n",
            "Epoch 536/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7084e-04 - 724ms/epoch - 4ms/step\n",
            "Epoch 537/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7114e-04 - 752ms/epoch - 4ms/step\n",
            "Epoch 538/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7144e-04 - 908ms/epoch - 5ms/step\n",
            "Epoch 539/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7173e-04 - 758ms/epoch - 4ms/step\n",
            "Epoch 540/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7202e-04 - 755ms/epoch - 4ms/step\n",
            "Epoch 541/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7232e-04 - 691ms/epoch - 4ms/step\n",
            "Epoch 542/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7261e-04 - 675ms/epoch - 4ms/step\n",
            "Epoch 543/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7290e-04 - 753ms/epoch - 4ms/step\n",
            "Epoch 544/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7319e-04 - 749ms/epoch - 4ms/step\n",
            "Epoch 545/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7348e-04 - 798ms/epoch - 4ms/step\n",
            "Epoch 546/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7377e-04 - 912ms/epoch - 5ms/step\n",
            "Epoch 547/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7406e-04 - 881ms/epoch - 5ms/step\n",
            "Epoch 548/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7435e-04 - 839ms/epoch - 4ms/step\n",
            "Epoch 549/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7464e-04 - 755ms/epoch - 4ms/step\n",
            "Epoch 550/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7492e-04 - 855ms/epoch - 5ms/step\n",
            "Epoch 551/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7521e-04 - 740ms/epoch - 4ms/step\n",
            "Epoch 552/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7549e-04 - 836ms/epoch - 4ms/step\n",
            "Epoch 553/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7578e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 554/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7606e-04 - 797ms/epoch - 4ms/step\n",
            "Epoch 555/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7634e-04 - 798ms/epoch - 4ms/step\n",
            "Epoch 556/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7662e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 557/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7690e-04 - 701ms/epoch - 4ms/step\n",
            "Epoch 558/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7718e-04 - 916ms/epoch - 5ms/step\n",
            "Epoch 559/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7746e-04 - 656ms/epoch - 3ms/step\n",
            "Epoch 560/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7774e-04 - 735ms/epoch - 4ms/step\n",
            "Epoch 561/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7802e-04 - 713ms/epoch - 4ms/step\n",
            "Epoch 562/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7830e-04 - 705ms/epoch - 4ms/step\n",
            "Epoch 563/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7857e-04 - 842ms/epoch - 4ms/step\n",
            "Epoch 564/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7885e-04 - 750ms/epoch - 4ms/step\n",
            "Epoch 565/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7912e-04 - 736ms/epoch - 4ms/step\n",
            "Epoch 566/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7940e-04 - 666ms/epoch - 4ms/step\n",
            "Epoch 567/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7967e-04 - 678ms/epoch - 4ms/step\n",
            "Epoch 568/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.7994e-04 - 827ms/epoch - 4ms/step\n",
            "Epoch 569/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8021e-04 - 889ms/epoch - 5ms/step\n",
            "Epoch 570/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8048e-04 - 643ms/epoch - 3ms/step\n",
            "Epoch 571/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8075e-04 - 763ms/epoch - 4ms/step\n",
            "Epoch 572/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8102e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 573/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8129e-04 - 672ms/epoch - 4ms/step\n",
            "Epoch 574/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8156e-04 - 778ms/epoch - 4ms/step\n",
            "Epoch 575/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8182e-04 - 667ms/epoch - 4ms/step\n",
            "Epoch 576/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8209e-04 - 781ms/epoch - 4ms/step\n",
            "Epoch 577/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8235e-04 - 727ms/epoch - 4ms/step\n",
            "Epoch 578/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8262e-04 - 682ms/epoch - 4ms/step\n",
            "Epoch 579/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8288e-04 - 670ms/epoch - 4ms/step\n",
            "Epoch 580/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8314e-04 - 816ms/epoch - 4ms/step\n",
            "Epoch 581/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8341e-04 - 625ms/epoch - 3ms/step\n",
            "Epoch 582/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8367e-04 - 702ms/epoch - 4ms/step\n",
            "Epoch 583/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8393e-04 - 766ms/epoch - 4ms/step\n",
            "Epoch 584/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8419e-04 - 771ms/epoch - 4ms/step\n",
            "Epoch 585/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8445e-04 - 709ms/epoch - 4ms/step\n",
            "Epoch 586/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8471e-04 - 659ms/epoch - 3ms/step\n",
            "Epoch 587/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8496e-04 - 969ms/epoch - 5ms/step\n",
            "Epoch 588/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8522e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 589/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8547e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 590/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8573e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 591/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8598e-04 - 962ms/epoch - 5ms/step\n",
            "Epoch 592/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8624e-04 - 862ms/epoch - 5ms/step\n",
            "Epoch 593/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8649e-04 - 932ms/epoch - 5ms/step\n",
            "Epoch 594/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8674e-04 - 861ms/epoch - 5ms/step\n",
            "Epoch 595/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8699e-04 - 893ms/epoch - 5ms/step\n",
            "Epoch 596/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8724e-04 - 813ms/epoch - 4ms/step\n",
            "Epoch 597/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8749e-04 - 832ms/epoch - 4ms/step\n",
            "Epoch 598/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8774e-04 - 809ms/epoch - 4ms/step\n",
            "Epoch 599/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8799e-04 - 825ms/epoch - 4ms/step\n",
            "Epoch 600/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8824e-04 - 733ms/epoch - 4ms/step\n",
            "Epoch 601/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8849e-04 - 883ms/epoch - 5ms/step\n",
            "Epoch 602/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8873e-04 - 860ms/epoch - 5ms/step\n",
            "Epoch 603/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8898e-04 - 774ms/epoch - 4ms/step\n",
            "Epoch 604/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8922e-04 - 787ms/epoch - 4ms/step\n",
            "Epoch 605/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8947e-04 - 737ms/epoch - 4ms/step\n",
            "Epoch 606/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8971e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 607/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.8995e-04 - 823ms/epoch - 4ms/step\n",
            "Epoch 608/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9019e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 609/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9043e-04 - 978ms/epoch - 5ms/step\n",
            "Epoch 610/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9067e-04 - 891ms/epoch - 5ms/step\n",
            "Epoch 611/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9091e-04 - 638ms/epoch - 3ms/step\n",
            "Epoch 612/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9115e-04 - 832ms/epoch - 4ms/step\n",
            "Epoch 613/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9139e-04 - 876ms/epoch - 5ms/step\n",
            "Epoch 614/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9163e-04 - 775ms/epoch - 4ms/step\n",
            "Epoch 615/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9187e-04 - 931ms/epoch - 5ms/step\n",
            "Epoch 616/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9210e-04 - 887ms/epoch - 5ms/step\n",
            "Epoch 617/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9234e-04 - 809ms/epoch - 4ms/step\n",
            "Epoch 618/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9257e-04 - 803ms/epoch - 4ms/step\n",
            "Epoch 619/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9281e-04 - 775ms/epoch - 4ms/step\n",
            "Epoch 620/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9304e-04 - 946ms/epoch - 5ms/step\n",
            "Epoch 621/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9327e-04 - 842ms/epoch - 4ms/step\n",
            "Epoch 622/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9351e-04 - 844ms/epoch - 4ms/step\n",
            "Epoch 623/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9374e-04 - 871ms/epoch - 5ms/step\n",
            "Epoch 624/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9397e-04 - 833ms/epoch - 4ms/step\n",
            "Epoch 625/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9420e-04 - 831ms/epoch - 4ms/step\n",
            "Epoch 626/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9443e-04 - 886ms/epoch - 5ms/step\n",
            "Epoch 627/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9466e-04 - 827ms/epoch - 4ms/step\n",
            "Epoch 628/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9489e-04 - 763ms/epoch - 4ms/step\n",
            "Epoch 629/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9511e-04 - 821ms/epoch - 4ms/step\n",
            "Epoch 630/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9534e-04 - 861ms/epoch - 5ms/step\n",
            "Epoch 631/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9556e-04 - 771ms/epoch - 4ms/step\n",
            "Epoch 632/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9579e-04 - 901ms/epoch - 5ms/step\n",
            "Epoch 633/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9602e-04 - 763ms/epoch - 4ms/step\n",
            "Epoch 634/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9624e-04 - 766ms/epoch - 4ms/step\n",
            "Epoch 635/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9646e-04 - 879ms/epoch - 5ms/step\n",
            "Epoch 636/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9669e-04 - 917ms/epoch - 5ms/step\n",
            "Epoch 637/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9691e-04 - 827ms/epoch - 4ms/step\n",
            "Epoch 638/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9713e-04 - 873ms/epoch - 5ms/step\n",
            "Epoch 639/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9735e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 640/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9757e-04 - 894ms/epoch - 5ms/step\n",
            "Epoch 641/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9779e-04 - 860ms/epoch - 5ms/step\n",
            "Epoch 642/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9801e-04 - 745ms/epoch - 4ms/step\n",
            "Epoch 643/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9823e-04 - 819ms/epoch - 4ms/step\n",
            "Epoch 644/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9845e-04 - 759ms/epoch - 4ms/step\n",
            "Epoch 645/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9867e-04 - 888ms/epoch - 5ms/step\n",
            "Epoch 646/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9889e-04 - 752ms/epoch - 4ms/step\n",
            "Epoch 647/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9911e-04 - 776ms/epoch - 4ms/step\n",
            "Epoch 648/700\n",
            "190/190 - 1s - loss: 0.0039 - val_loss: 4.9932e-04 - 847ms/epoch - 4ms/step\n",
            "Epoch 649/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 4.9954e-04 - 777ms/epoch - 4ms/step\n",
            "Epoch 650/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 4.9975e-04 - 672ms/epoch - 4ms/step\n",
            "Epoch 651/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 4.9997e-04 - 686ms/epoch - 4ms/step\n",
            "Epoch 652/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0018e-04 - 664ms/epoch - 3ms/step\n",
            "Epoch 653/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0040e-04 - 632ms/epoch - 3ms/step\n",
            "Epoch 654/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0061e-04 - 673ms/epoch - 4ms/step\n",
            "Epoch 655/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0082e-04 - 743ms/epoch - 4ms/step\n",
            "Epoch 656/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0103e-04 - 712ms/epoch - 4ms/step\n",
            "Epoch 657/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0124e-04 - 697ms/epoch - 4ms/step\n",
            "Epoch 658/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0146e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 659/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0167e-04 - 651ms/epoch - 3ms/step\n",
            "Epoch 660/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0188e-04 - 688ms/epoch - 4ms/step\n",
            "Epoch 661/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0209e-04 - 681ms/epoch - 4ms/step\n",
            "Epoch 662/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0230e-04 - 683ms/epoch - 4ms/step\n",
            "Epoch 663/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0251e-04 - 604ms/epoch - 3ms/step\n",
            "Epoch 664/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0271e-04 - 698ms/epoch - 4ms/step\n",
            "Epoch 665/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0292e-04 - 819ms/epoch - 4ms/step\n",
            "Epoch 666/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0313e-04 - 720ms/epoch - 4ms/step\n",
            "Epoch 667/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0334e-04 - 740ms/epoch - 4ms/step\n",
            "Epoch 668/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0354e-04 - 774ms/epoch - 4ms/step\n",
            "Epoch 669/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0375e-04 - 827ms/epoch - 4ms/step\n",
            "Epoch 670/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0396e-04 - 902ms/epoch - 5ms/step\n",
            "Epoch 671/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0416e-04 - 795ms/epoch - 4ms/step\n",
            "Epoch 672/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0437e-04 - 736ms/epoch - 4ms/step\n",
            "Epoch 673/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0457e-04 - 736ms/epoch - 4ms/step\n",
            "Epoch 674/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0478e-04 - 687ms/epoch - 4ms/step\n",
            "Epoch 675/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0498e-04 - 693ms/epoch - 4ms/step\n",
            "Epoch 676/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0518e-04 - 651ms/epoch - 3ms/step\n",
            "Epoch 677/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0539e-04 - 714ms/epoch - 4ms/step\n",
            "Epoch 678/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0559e-04 - 704ms/epoch - 4ms/step\n",
            "Epoch 679/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0579e-04 - 941ms/epoch - 5ms/step\n",
            "Epoch 680/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0599e-04 - 917ms/epoch - 5ms/step\n",
            "Epoch 681/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0619e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 682/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0640e-04 - 785ms/epoch - 4ms/step\n",
            "Epoch 683/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0660e-04 - 652ms/epoch - 3ms/step\n",
            "Epoch 684/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0680e-04 - 881ms/epoch - 5ms/step\n",
            "Epoch 685/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0700e-04 - 749ms/epoch - 4ms/step\n",
            "Epoch 686/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0720e-04 - 742ms/epoch - 4ms/step\n",
            "Epoch 687/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0740e-04 - 775ms/epoch - 4ms/step\n",
            "Epoch 688/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0760e-04 - 749ms/epoch - 4ms/step\n",
            "Epoch 689/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0780e-04 - 656ms/epoch - 3ms/step\n",
            "Epoch 690/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0800e-04 - 794ms/epoch - 4ms/step\n",
            "Epoch 691/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0820e-04 - 812ms/epoch - 4ms/step\n",
            "Epoch 692/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0839e-04 - 754ms/epoch - 4ms/step\n",
            "Epoch 693/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0859e-04 - 732ms/epoch - 4ms/step\n",
            "Epoch 694/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0879e-04 - 760ms/epoch - 4ms/step\n",
            "Epoch 695/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0899e-04 - 798ms/epoch - 4ms/step\n",
            "Epoch 696/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0919e-04 - 763ms/epoch - 4ms/step\n",
            "Epoch 697/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0938e-04 - 897ms/epoch - 5ms/step\n",
            "Epoch 698/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0958e-04 - 696ms/epoch - 4ms/step\n",
            "Epoch 699/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0978e-04 - 864ms/epoch - 5ms/step\n",
            "Epoch 700/700\n",
            "190/190 - 1s - loss: 0.0038 - val_loss: 5.0997e-04 - 815ms/epoch - 4ms/step\n",
            "n_epochs 700 num_hidden_layers 1 num_neurons 12 batch_size 8 timesteps 20\n",
            "train.shape: (1508, 142) test.shape: (378, 142)\n",
            "train_scaled.shape: (1508, 142) test_scaled.shape: (378, 142)\n",
            "train_X.shape: (1508, 20, 7) train_y.shape: (1508, 2) test_X.shape: (378, 20, 7) test_y.shape: (378, 2)\n",
            "Epoch 1/700\n",
            "189/189 - 4s - loss: 0.3723 - val_loss: 0.2677 - 4s/epoch - 20ms/step\n",
            "Epoch 2/700\n",
            "189/189 - 1s - loss: 0.1509 - val_loss: 0.0939 - 1s/epoch - 6ms/step\n",
            "Epoch 3/700\n",
            "189/189 - 1s - loss: 0.0460 - val_loss: 0.0203 - 1s/epoch - 7ms/step\n",
            "Epoch 4/700\n",
            "189/189 - 1s - loss: 0.0183 - val_loss: 0.0070 - 1s/epoch - 7ms/step\n",
            "Epoch 5/700\n",
            "189/189 - 1s - loss: 0.0146 - val_loss: 0.0049 - 1s/epoch - 7ms/step\n",
            "Epoch 6/700\n",
            "189/189 - 1s - loss: 0.0126 - val_loss: 0.0040 - 1s/epoch - 7ms/step\n",
            "Epoch 7/700\n",
            "189/189 - 1s - loss: 0.0109 - val_loss: 0.0035 - 1s/epoch - 7ms/step\n",
            "Epoch 8/700\n",
            "189/189 - 2s - loss: 0.0096 - val_loss: 0.0030 - 2s/epoch - 8ms/step\n",
            "Epoch 9/700\n",
            "189/189 - 1s - loss: 0.0085 - val_loss: 0.0027 - 1s/epoch - 8ms/step\n",
            "Epoch 10/700\n",
            "189/189 - 1s - loss: 0.0076 - val_loss: 0.0024 - 1s/epoch - 7ms/step\n",
            "Epoch 11/700\n",
            "189/189 - 1s - loss: 0.0069 - val_loss: 0.0022 - 1s/epoch - 7ms/step\n",
            "Epoch 12/700\n",
            "189/189 - 1s - loss: 0.0064 - val_loss: 0.0020 - 1s/epoch - 6ms/step\n",
            "Epoch 13/700\n",
            "189/189 - 1s - loss: 0.0060 - val_loss: 0.0019 - 1s/epoch - 6ms/step\n",
            "Epoch 14/700\n",
            "189/189 - 1s - loss: 0.0057 - val_loss: 0.0017 - 1s/epoch - 6ms/step\n",
            "Epoch 15/700\n",
            "189/189 - 1s - loss: 0.0055 - val_loss: 0.0016 - 1s/epoch - 6ms/step\n",
            "Epoch 16/700\n",
            "189/189 - 1s - loss: 0.0053 - val_loss: 0.0015 - 1s/epoch - 7ms/step\n",
            "Epoch 17/700\n",
            "189/189 - 1s - loss: 0.0052 - val_loss: 0.0014 - 1s/epoch - 7ms/step\n",
            "Epoch 18/700\n",
            "189/189 - 1s - loss: 0.0051 - val_loss: 0.0013 - 1s/epoch - 6ms/step\n",
            "Epoch 19/700\n",
            "189/189 - 1s - loss: 0.0050 - val_loss: 0.0012 - 1s/epoch - 7ms/step\n",
            "Epoch 20/700\n",
            "189/189 - 1s - loss: 0.0050 - val_loss: 0.0011 - 1s/epoch - 6ms/step\n",
            "Epoch 21/700\n",
            "189/189 - 1s - loss: 0.0049 - val_loss: 0.0011 - 1s/epoch - 7ms/step\n",
            "Epoch 22/700\n",
            "189/189 - 1s - loss: 0.0049 - val_loss: 9.9188e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 23/700\n",
            "189/189 - 1s - loss: 0.0048 - val_loss: 9.2374e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 24/700\n",
            "189/189 - 1s - loss: 0.0048 - val_loss: 8.6115e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 25/700\n",
            "189/189 - 1s - loss: 0.0047 - val_loss: 8.0391e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 26/700\n",
            "189/189 - 1s - loss: 0.0047 - val_loss: 7.5176e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 27/700\n",
            "189/189 - 1s - loss: 0.0047 - val_loss: 7.0438e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 28/700\n",
            "189/189 - 1s - loss: 0.0046 - val_loss: 6.6145e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 29/700\n",
            "189/189 - 1s - loss: 0.0046 - val_loss: 6.2264e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 30/700\n",
            "189/189 - 1s - loss: 0.0046 - val_loss: 5.8759e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 31/700\n",
            "189/189 - 1s - loss: 0.0046 - val_loss: 5.5599e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 32/700\n",
            "189/189 - 1s - loss: 0.0045 - val_loss: 5.2753e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 33/700\n",
            "189/189 - 1s - loss: 0.0045 - val_loss: 5.0192e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 34/700\n",
            "189/189 - 1s - loss: 0.0045 - val_loss: 4.7889e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 35/700\n",
            "189/189 - 1s - loss: 0.0045 - val_loss: 4.5820e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 36/700\n",
            "189/189 - 1s - loss: 0.0045 - val_loss: 4.3963e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 37/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 4.2297e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 38/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 4.0803e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 39/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.9466e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 40/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.8270e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 41/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.7201e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 42/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.6246e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 43/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.5394e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 44/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.4636e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 45/700\n",
            "189/189 - 1s - loss: 0.0044 - val_loss: 3.3961e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 46/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.3361e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 47/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.2829e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 48/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.2357e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 49/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.1940e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 50/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.1571e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 51/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.1246e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 52/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.0960e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 53/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.0709e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 54/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.0490e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 55/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.0299e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 56/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 3.0132e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 57/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9989e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 58/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9865e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 59/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9760e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 60/700\n",
            "189/189 - 2s - loss: 0.0043 - val_loss: 2.9671e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 61/700\n",
            "189/189 - 2s - loss: 0.0043 - val_loss: 2.9597e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 62/700\n",
            "189/189 - 2s - loss: 0.0043 - val_loss: 2.9536e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 63/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9486e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 64/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9447e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 65/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9418e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 66/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9397e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 67/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9384e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 68/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9378e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 69/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9378e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 70/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9383e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 71/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9394e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 72/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9409e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 73/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9429e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 74/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9452e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 75/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9478e-04 - 988ms/epoch - 5ms/step\n",
            "Epoch 76/700\n",
            "189/189 - 1s - loss: 0.0043 - val_loss: 2.9507e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 77/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9539e-04 - 942ms/epoch - 5ms/step\n",
            "Epoch 78/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9573e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 79/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9610e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 80/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 2.9648e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 81/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 2.9689e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 82/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9730e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 83/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9773e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 84/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9818e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 85/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9863e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 86/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9909e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 87/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 2.9957e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 88/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0005e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 89/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0053e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 90/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0102e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 91/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0152e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 92/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0202e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 93/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0253e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 94/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0303e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 95/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0354e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 96/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0405e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 97/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0456e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 98/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0507e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 99/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0559e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 100/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0610e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 101/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0661e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 102/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0712e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 103/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0763e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 104/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0814e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 105/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0865e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 106/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0915e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 107/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.0966e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 108/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.1016e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 109/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1066e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 110/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1116e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 111/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1166e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 112/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1215e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 113/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1264e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 114/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1313e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 115/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1361e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 116/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1409e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 117/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1457e-04 - 999ms/epoch - 5ms/step\n",
            "Epoch 118/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1505e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 119/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1552e-04 - 953ms/epoch - 5ms/step\n",
            "Epoch 120/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1599e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 121/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1646e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 122/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1692e-04 - 942ms/epoch - 5ms/step\n",
            "Epoch 123/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1738e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 124/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.1784e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 125/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1829e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 126/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1874e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 127/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.1919e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 128/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.1963e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 129/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2007e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 130/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2051e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 131/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2094e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 132/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2137e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 133/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2180e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 134/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2222e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 135/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2264e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 136/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2306e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 137/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2347e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 138/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2388e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 139/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2429e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 140/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2470e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 141/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2510e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 142/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2550e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 143/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2589e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 144/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2629e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 145/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2668e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 146/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2706e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 147/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2745e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 148/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2783e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 149/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2821e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 150/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2858e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 151/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2895e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 152/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.2932e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 153/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.2969e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 154/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3005e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 155/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3042e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 156/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3077e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 157/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3113e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 158/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3149e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 159/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3184e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 160/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3219e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 161/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3253e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 162/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3288e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 163/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3322e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 164/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3356e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 165/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3390e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 166/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3424e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 167/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3457e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 168/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3490e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 169/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3523e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 170/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3556e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 171/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3589e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 172/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3621e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 173/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3653e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 174/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3685e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 175/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3717e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 176/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3749e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 177/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3780e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 178/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3812e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 179/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3843e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 180/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3874e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 181/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3905e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 182/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3936e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 183/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3967e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 184/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.3997e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 185/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4027e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 186/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4058e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 187/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4088e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 188/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4118e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 189/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4148e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 190/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4178e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 191/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4208e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 192/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4237e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 193/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4267e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 194/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4296e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 195/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4326e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 196/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4355e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 197/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4384e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 198/700\n",
            "189/189 - 3s - loss: 0.0042 - val_loss: 3.4413e-04 - 3s/epoch - 16ms/step\n",
            "Epoch 199/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4443e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 200/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4472e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 201/700\n",
            "189/189 - 2s - loss: 0.0042 - val_loss: 3.4501e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 202/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4530e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 203/700\n",
            "189/189 - 1s - loss: 0.0042 - val_loss: 3.4559e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 204/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4587e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 205/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4616e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 206/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.4645e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 207/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4674e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 208/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.4703e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 209/700\n",
            "189/189 - 3s - loss: 0.0041 - val_loss: 3.4731e-04 - 3s/epoch - 14ms/step\n",
            "Epoch 210/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.4760e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 211/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.4789e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 212/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.4818e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 213/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4846e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 214/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4875e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 215/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4904e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 216/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4933e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 217/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4961e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 218/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.4990e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 219/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5019e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 220/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5048e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 221/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5077e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 222/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5106e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 223/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5135e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 224/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5164e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 225/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5193e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 226/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5222e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 227/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5251e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 228/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5280e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 229/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5310e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 230/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5339e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 231/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5369e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 232/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5398e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 233/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5428e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 234/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5458e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 235/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5487e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 236/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5517e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 237/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5547e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 238/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5577e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 239/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5608e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 240/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5638e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 241/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5668e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 242/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5699e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 243/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5730e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 244/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5760e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 245/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5791e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 246/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5822e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 247/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5854e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 248/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5885e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 249/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5916e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 250/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5948e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 251/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.5979e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 252/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6011e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 253/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6043e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 254/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6075e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 255/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6108e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 256/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6140e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 257/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6173e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 258/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6205e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 259/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6238e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 260/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6271e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 261/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6304e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 262/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6337e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 263/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6371e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 264/700\n",
            "189/189 - 3s - loss: 0.0041 - val_loss: 3.6405e-04 - 3s/epoch - 16ms/step\n",
            "Epoch 265/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6438e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 266/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6472e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 267/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6506e-04 - 2s/epoch - 13ms/step\n",
            "Epoch 268/700\n",
            "189/189 - 3s - loss: 0.0041 - val_loss: 3.6541e-04 - 3s/epoch - 14ms/step\n",
            "Epoch 269/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6575e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 270/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6610e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 271/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6644e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 272/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6679e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 273/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6714e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 274/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6750e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 275/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6785e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 276/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6821e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 277/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.6856e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 278/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6892e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 279/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6928e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 280/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.6964e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 281/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7001e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 282/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7037e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 283/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7074e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 284/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7110e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 285/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7147e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 286/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7184e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 287/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7221e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 288/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7259e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 289/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7296e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 290/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7334e-04 - 2s/epoch - 13ms/step\n",
            "Epoch 291/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7372e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 292/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7410e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 293/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7448e-04 - 2s/epoch - 13ms/step\n",
            "Epoch 294/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7486e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 295/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7524e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 296/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.7562e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 297/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7601e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 298/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7640e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 299/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7678e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 300/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7717e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 301/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7756e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 302/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7795e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 303/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7834e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 304/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7874e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 305/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7913e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 306/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7952e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 307/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.7992e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 308/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8031e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 309/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8071e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 310/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8111e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 311/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8151e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 312/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8191e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 313/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8230e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 314/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8271e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 315/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8311e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 316/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8351e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 317/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8391e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 318/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8431e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 319/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8471e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 320/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8511e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 321/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8552e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 322/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8592e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 323/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8632e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 324/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8672e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 325/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8713e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 326/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8753e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 327/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8793e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 328/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 3.8834e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 329/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8874e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 330/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8914e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 331/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8955e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 332/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.8995e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 333/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9035e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 334/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9075e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 335/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9115e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 336/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9155e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 337/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9195e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 338/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9236e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 339/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9275e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 340/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9315e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 341/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9355e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 342/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9395e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 343/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9435e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 344/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9474e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 345/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9514e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 346/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9553e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 347/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9593e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 348/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9632e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 349/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9671e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 350/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9710e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 351/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9749e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 352/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9788e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 353/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9827e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 354/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9866e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 355/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9904e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 356/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9943e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 357/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 3.9981e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 358/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0019e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 359/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0057e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 360/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0095e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 361/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0133e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 362/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0171e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 363/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0209e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 364/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0246e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 365/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0283e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 366/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 4.0320e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 367/700\n",
            "189/189 - 2s - loss: 0.0041 - val_loss: 4.0357e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 368/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0394e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 369/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0431e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 370/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0467e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 371/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0504e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 372/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0540e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 373/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0576e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 374/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0612e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 375/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0648e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 376/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0684e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 377/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0719e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 378/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0754e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 379/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0789e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 380/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0824e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 381/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0859e-04 - 959ms/epoch - 5ms/step\n",
            "Epoch 382/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0893e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 383/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0928e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 384/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0962e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 385/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.0996e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 386/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1030e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 387/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1063e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 388/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1097e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 389/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1130e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 390/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1163e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 391/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1196e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 392/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1229e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 393/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1261e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 394/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1294e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 395/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1326e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 396/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1358e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 397/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1389e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 398/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1421e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 399/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1452e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 400/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1483e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 401/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1514e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 402/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1545e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 403/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1575e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 404/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1606e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 405/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1636e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 406/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1666e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 407/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1695e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 408/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1725e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 409/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1754e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 410/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1783e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 411/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1812e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 412/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1841e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 413/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1869e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 414/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1897e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 415/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1925e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 416/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1953e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 417/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.1981e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 418/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2008e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 419/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2035e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 420/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2062e-04 - 984ms/epoch - 5ms/step\n",
            "Epoch 421/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2089e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 422/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2115e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 423/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2142e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 424/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2168e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 425/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2193e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 426/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2219e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 427/700\n",
            "189/189 - 1s - loss: 0.0041 - val_loss: 4.2244e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 428/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2270e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 429/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2295e-04 - 935ms/epoch - 5ms/step\n",
            "Epoch 430/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2319e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 431/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2344e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 432/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2368e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 433/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2392e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 434/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2416e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 435/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2440e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 436/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2463e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 437/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2486e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 438/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2509e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 439/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2532e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 440/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2554e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 441/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2577e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 442/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2599e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 443/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2620e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 444/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2642e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 445/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2663e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 446/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2685e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 447/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2706e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 448/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2726e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 449/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2747e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 450/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2767e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 451/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2787e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 452/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2807e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 453/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2826e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 454/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2846e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 455/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2865e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 456/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2883e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 457/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2902e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 458/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2921e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 459/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2939e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 460/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2957e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 461/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2974e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 462/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2992e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 463/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3009e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 464/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3026e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 465/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3043e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 466/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3059e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 467/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3076e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 468/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3092e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 469/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3108e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 470/700\n",
            "189/189 - 2s - loss: 0.0040 - val_loss: 4.3123e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 471/700\n",
            "189/189 - 2s - loss: 0.0040 - val_loss: 4.3139e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 472/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3154e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 473/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3169e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 474/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3183e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 475/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3198e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 476/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3212e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 477/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3226e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 478/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3240e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 479/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3253e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 480/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3267e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 481/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3280e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 482/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3293e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 483/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3305e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 484/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3317e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 485/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3329e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 486/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3341e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 487/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3353e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 488/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3364e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 489/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3376e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 490/700\n",
            "189/189 - 2s - loss: 0.0040 - val_loss: 4.3386e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 491/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3397e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 492/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3408e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 493/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3418e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 494/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3428e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 495/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3438e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 496/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3447e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 497/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3456e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 498/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3465e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 499/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3474e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 500/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3483e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 501/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3491e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 502/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3499e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 503/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3507e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 504/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3515e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 505/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3522e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 506/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3529e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 507/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3536e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 508/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3543e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 509/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3549e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 510/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3555e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 511/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3561e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 512/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3567e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 513/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3573e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 514/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3578e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 515/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3583e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 516/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3588e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 517/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3592e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 518/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3596e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 519/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3600e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 520/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3604e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 521/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3608e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 522/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3611e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 523/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3614e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 524/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3617e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 525/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3619e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 526/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3621e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 527/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3624e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 528/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3625e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 529/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3627e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 530/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3628e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 531/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3629e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 532/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3630e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 533/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3631e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 534/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3631e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 535/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3631e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 536/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3631e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 537/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3631e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 538/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3630e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 539/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3629e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 540/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3628e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 541/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3626e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 542/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3625e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 543/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3623e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 544/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3621e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 545/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3618e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 546/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3616e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 547/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3613e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 548/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3610e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 549/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3606e-04 - 990ms/epoch - 5ms/step\n",
            "Epoch 550/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3603e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 551/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3599e-04 - 967ms/epoch - 5ms/step\n",
            "Epoch 552/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3594e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 553/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3590e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 554/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3585e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 555/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3580e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 556/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3575e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 557/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3570e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 558/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3564e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 559/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3558e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 560/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3552e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 561/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3546e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 562/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3539e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 563/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3532e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 564/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3525e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 565/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3518e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 566/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3510e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 567/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3502e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 568/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3494e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 569/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3485e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 570/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3477e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 571/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3468e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 572/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3459e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 573/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3449e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 574/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3440e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 575/700\n",
            "189/189 - 2s - loss: 0.0040 - val_loss: 4.3430e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 576/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3420e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 577/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3409e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 578/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3399e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 579/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3388e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 580/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3377e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 581/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3366e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 582/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3354e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 583/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3343e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 584/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3331e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 585/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3319e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 586/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3306e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 587/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3294e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 588/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3281e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 589/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3268e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 590/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3255e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 591/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3241e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 592/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3228e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 593/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3214e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 594/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3200e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 595/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3186e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 596/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3171e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 597/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3157e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 598/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3142e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 599/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3127e-04 - 987ms/epoch - 5ms/step\n",
            "Epoch 600/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3112e-04 - 954ms/epoch - 5ms/step\n",
            "Epoch 601/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3096e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 602/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3081e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 603/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3065e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 604/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3050e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 605/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3034e-04 - 856ms/epoch - 5ms/step\n",
            "Epoch 606/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3018e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 607/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.3001e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 608/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2985e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 609/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2969e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 610/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2952e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 611/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2935e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 612/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2919e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 613/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2902e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 614/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2884e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 615/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2867e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 616/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2850e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 617/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2833e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 618/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2815e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 619/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2798e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 620/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2780e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 621/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2763e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 622/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2745e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 623/700\n",
            "189/189 - 1s - loss: 0.0040 - val_loss: 4.2727e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 624/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2710e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 625/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2692e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 626/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2674e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 627/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2656e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 628/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2639e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 629/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2621e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 630/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2603e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 631/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2585e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 632/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2567e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 633/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2550e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 634/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2532e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 635/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2514e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 636/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2496e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 637/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2479e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 638/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2461e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 639/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2444e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 640/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2426e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 641/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2409e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 642/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2392e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 643/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2375e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 644/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2358e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 645/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2341e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 646/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2324e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 647/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2307e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 648/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2290e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 649/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2274e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 650/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2257e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 651/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2241e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 652/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2225e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 653/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2209e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 654/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2193e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 655/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2178e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 656/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2162e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 657/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2147e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 658/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2132e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 659/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2116e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 660/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2102e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 661/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2087e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 662/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2072e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 663/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2058e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 664/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2044e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 665/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2030e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 666/700\n",
            "189/189 - 2s - loss: 0.0039 - val_loss: 4.2016e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 667/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.2003e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 668/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1989e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 669/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1976e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 670/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1963e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 671/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1950e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 672/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1938e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 673/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1926e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 674/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1913e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 675/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1901e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 676/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1890e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 677/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1878e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 678/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1867e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 679/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1856e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 680/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1845e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 681/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1834e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 682/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1823e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 683/700\n",
            "189/189 - 2s - loss: 0.0039 - val_loss: 4.1813e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 684/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1803e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 685/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1793e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 686/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1783e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 687/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1774e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 688/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1764e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 689/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1755e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 690/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1746e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 691/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1737e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 692/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1729e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 693/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1720e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 694/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1712e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 695/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1704e-04 - 1s/epoch - 6ms/step\n",
            "Epoch 696/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1696e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 697/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1689e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 698/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1681e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 699/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1674e-04 - 1s/epoch - 5ms/step\n",
            "Epoch 700/700\n",
            "189/189 - 1s - loss: 0.0039 - val_loss: 4.1667e-04 - 1s/epoch - 6ms/step\n",
            "n_epochs 700 num_hidden_layers 1 num_neurons 12 batch_size 8 timesteps 30\n",
            "train.shape: (1500, 212) test.shape: (376, 212)\n",
            "train_scaled.shape: (1500, 212) test_scaled.shape: (376, 212)\n",
            "train_X.shape: (1500, 30, 7) train_y.shape: (1500, 2) test_X.shape: (376, 30, 7) test_y.shape: (376, 2)\n",
            "Epoch 1/700\n",
            "188/188 - 4s - loss: 0.1727 - val_loss: 0.0739 - 4s/epoch - 22ms/step\n",
            "Epoch 2/700\n",
            "188/188 - 2s - loss: 0.0276 - val_loss: 0.0093 - 2s/epoch - 9ms/step\n",
            "Epoch 3/700\n",
            "188/188 - 2s - loss: 0.0107 - val_loss: 0.0039 - 2s/epoch - 8ms/step\n",
            "Epoch 4/700\n",
            "188/188 - 1s - loss: 0.0093 - val_loss: 0.0032 - 1s/epoch - 8ms/step\n",
            "Epoch 5/700\n",
            "188/188 - 2s - loss: 0.0084 - val_loss: 0.0028 - 2s/epoch - 8ms/step\n",
            "Epoch 6/700\n",
            "188/188 - 2s - loss: 0.0076 - val_loss: 0.0026 - 2s/epoch - 8ms/step\n",
            "Epoch 7/700\n",
            "188/188 - 2s - loss: 0.0071 - val_loss: 0.0024 - 2s/epoch - 9ms/step\n",
            "Epoch 8/700\n",
            "188/188 - 1s - loss: 0.0067 - val_loss: 0.0022 - 1s/epoch - 8ms/step\n",
            "Epoch 9/700\n",
            "188/188 - 1s - loss: 0.0064 - val_loss: 0.0021 - 1s/epoch - 8ms/step\n",
            "Epoch 10/700\n",
            "188/188 - 1s - loss: 0.0062 - val_loss: 0.0020 - 1s/epoch - 7ms/step\n",
            "Epoch 11/700\n",
            "188/188 - 1s - loss: 0.0060 - val_loss: 0.0019 - 1s/epoch - 7ms/step\n",
            "Epoch 12/700\n",
            "188/188 - 2s - loss: 0.0059 - val_loss: 0.0019 - 2s/epoch - 8ms/step\n",
            "Epoch 13/700\n",
            "188/188 - 2s - loss: 0.0057 - val_loss: 0.0018 - 2s/epoch - 8ms/step\n",
            "Epoch 14/700\n",
            "188/188 - 2s - loss: 0.0056 - val_loss: 0.0017 - 2s/epoch - 9ms/step\n",
            "Epoch 15/700\n",
            "188/188 - 2s - loss: 0.0055 - val_loss: 0.0017 - 2s/epoch - 8ms/step\n",
            "Epoch 16/700\n",
            "188/188 - 2s - loss: 0.0054 - val_loss: 0.0016 - 2s/epoch - 8ms/step\n",
            "Epoch 17/700\n",
            "188/188 - 1s - loss: 0.0054 - val_loss: 0.0016 - 1s/epoch - 8ms/step\n",
            "Epoch 18/700\n",
            "188/188 - 2s - loss: 0.0053 - val_loss: 0.0015 - 2s/epoch - 9ms/step\n",
            "Epoch 19/700\n",
            "188/188 - 2s - loss: 0.0052 - val_loss: 0.0015 - 2s/epoch - 10ms/step\n",
            "Epoch 20/700\n",
            "188/188 - 1s - loss: 0.0051 - val_loss: 0.0015 - 1s/epoch - 8ms/step\n",
            "Epoch 21/700\n",
            "188/188 - 2s - loss: 0.0051 - val_loss: 0.0014 - 2s/epoch - 9ms/step\n",
            "Epoch 22/700\n",
            "188/188 - 2s - loss: 0.0050 - val_loss: 0.0014 - 2s/epoch - 8ms/step\n",
            "Epoch 23/700\n",
            "188/188 - 2s - loss: 0.0050 - val_loss: 0.0014 - 2s/epoch - 9ms/step\n",
            "Epoch 24/700\n",
            "188/188 - 2s - loss: 0.0049 - val_loss: 0.0013 - 2s/epoch - 8ms/step\n",
            "Epoch 25/700\n",
            "188/188 - 2s - loss: 0.0049 - val_loss: 0.0013 - 2s/epoch - 9ms/step\n",
            "Epoch 26/700\n",
            "188/188 - 2s - loss: 0.0049 - val_loss: 0.0013 - 2s/epoch - 9ms/step\n",
            "Epoch 27/700\n",
            "188/188 - 2s - loss: 0.0048 - val_loss: 0.0012 - 2s/epoch - 9ms/step\n",
            "Epoch 28/700\n",
            "188/188 - 2s - loss: 0.0048 - val_loss: 0.0012 - 2s/epoch - 9ms/step\n",
            "Epoch 29/700\n",
            "188/188 - 2s - loss: 0.0048 - val_loss: 0.0012 - 2s/epoch - 9ms/step\n",
            "Epoch 30/700\n",
            "188/188 - 2s - loss: 0.0047 - val_loss: 0.0012 - 2s/epoch - 9ms/step\n",
            "Epoch 31/700\n",
            "188/188 - 2s - loss: 0.0047 - val_loss: 0.0011 - 2s/epoch - 10ms/step\n",
            "Epoch 32/700\n",
            "188/188 - 2s - loss: 0.0047 - val_loss: 0.0011 - 2s/epoch - 9ms/step\n",
            "Epoch 33/700\n",
            "188/188 - 2s - loss: 0.0047 - val_loss: 0.0011 - 2s/epoch - 9ms/step\n",
            "Epoch 34/700\n",
            "188/188 - 2s - loss: 0.0046 - val_loss: 0.0011 - 2s/epoch - 8ms/step\n",
            "Epoch 35/700\n",
            "188/188 - 2s - loss: 0.0046 - val_loss: 0.0011 - 2s/epoch - 9ms/step\n",
            "Epoch 36/700\n",
            "188/188 - 2s - loss: 0.0046 - val_loss: 0.0010 - 2s/epoch - 8ms/step\n",
            "Epoch 37/700\n",
            "188/188 - 1s - loss: 0.0046 - val_loss: 0.0010 - 1s/epoch - 8ms/step\n",
            "Epoch 38/700\n",
            "188/188 - 1s - loss: 0.0046 - val_loss: 0.0010 - 1s/epoch - 7ms/step\n",
            "Epoch 39/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.9723e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 40/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.8144e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 41/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.6620e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 42/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.5149e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 43/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.3728e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 44/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.2354e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 45/700\n",
            "188/188 - 1s - loss: 0.0045 - val_loss: 9.1026e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 46/700\n",
            "188/188 - 2s - loss: 0.0045 - val_loss: 8.9741e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 47/700\n",
            "188/188 - 1s - loss: 0.0044 - val_loss: 8.8498e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 48/700\n",
            "188/188 - 1s - loss: 0.0044 - val_loss: 8.7294e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 49/700\n",
            "188/188 - 1s - loss: 0.0044 - val_loss: 8.6128e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 50/700\n",
            "188/188 - 1s - loss: 0.0044 - val_loss: 8.4998e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 51/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 8.3903e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 52/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 8.2842e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 53/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 8.1812e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 54/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 8.0813e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 55/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.9844e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 56/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.8904e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 57/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.7991e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 58/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.7105e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 59/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.6245e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 60/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.5409e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 61/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.4598e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 62/700\n",
            "188/188 - 2s - loss: 0.0044 - val_loss: 7.3811e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 63/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 7.3046e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 64/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 7.2303e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 65/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 7.1582e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 66/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 7.0881e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 67/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 7.0201e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 68/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.9540e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 69/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.8898e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 70/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.8274e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 71/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.7669e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 72/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.7080e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 73/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.6509e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 74/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.5954e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 75/700\n",
            "188/188 - 1s - loss: 0.0043 - val_loss: 6.5414e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 76/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.4891e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 77/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.4382e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 78/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.3888e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 79/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.3407e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 80/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.2941e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 81/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.2488e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 82/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.2048e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 83/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.1620e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 84/700\n",
            "188/188 - 1s - loss: 0.0043 - val_loss: 6.1204e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 85/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.0801e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 86/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.0409e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 87/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 6.0028e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 88/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.9658e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 89/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.9299e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 90/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.8949e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 91/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.8610e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 92/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.8280e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 93/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.7960e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 94/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.7649e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 95/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.7347e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 96/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.7054e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 97/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.6769e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 98/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.6492e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 99/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.6223e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 100/700\n",
            "188/188 - 1s - loss: 0.0043 - val_loss: 5.5961e-04 - 1s/epoch - 7ms/step\n",
            "Epoch 101/700\n",
            "188/188 - 1s - loss: 0.0043 - val_loss: 5.5708e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 102/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.5461e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 103/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.5222e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 104/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.4989e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 105/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.4764e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 106/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.4544e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 107/700\n",
            "188/188 - 2s - loss: 0.0043 - val_loss: 5.4331e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 108/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.4125e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 109/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 5.3924e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 110/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.3729e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 111/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.3540e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 112/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.3356e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 113/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.3178e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 114/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.3004e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 115/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.2836e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 116/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.2673e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 117/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.2515e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 118/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.2361e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 119/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.2212e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 120/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.2067e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 121/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1927e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 122/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1791e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 123/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1659e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 124/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1531e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 125/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1407e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 126/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1287e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 127/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 5.1170e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 128/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.1057e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 129/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0947e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 130/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0841e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 131/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0739e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 132/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0639e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 133/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0543e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 134/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0449e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 135/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0359e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 136/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 5.0271e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 137/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0187e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 138/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0105e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 139/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 5.0026e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 140/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9949e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 141/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9875e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 142/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9804e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 143/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9735e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 144/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9668e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 145/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9604e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 146/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 4.9542e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 147/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9482e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 148/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9425e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 149/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9369e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 150/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9315e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 151/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9264e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 152/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9214e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 153/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9167e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 154/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9121e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 155/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9077e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 156/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9035e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 157/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8995e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 158/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8956e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 159/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8919e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 160/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8883e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 161/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8849e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 162/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8817e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 163/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8786e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 164/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8756e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 165/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8728e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 166/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8702e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 167/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8676e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 168/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8653e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 169/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8630e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 170/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8609e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 171/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8589e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 172/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8570e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 173/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8552e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 174/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8535e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 175/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8520e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 176/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8505e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 177/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8492e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 178/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8480e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 179/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8469e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 180/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8459e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 181/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 4.8449e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 182/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8441e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 183/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8434e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 184/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8427e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 185/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8422e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 186/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8417e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 187/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8413e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 188/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8410e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 189/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8408e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 190/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8407e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 191/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8406e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 192/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8407e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 193/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8407e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 194/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8409e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 195/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8411e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 196/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 4.8414e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 197/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8418e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 198/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8423e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 199/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8428e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 200/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8433e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 201/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 4.8439e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 202/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8446e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 203/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8454e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 204/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8462e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 205/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8470e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 206/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8479e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 207/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8489e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 208/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8499e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 209/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8510e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 210/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8521e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 211/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8532e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 212/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8544e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 213/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8557e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 214/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8570e-04 - 2s/epoch - 11ms/step\n",
            "Epoch 215/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8583e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 216/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8597e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 217/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8611e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 218/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8626e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 219/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8641e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 220/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8656e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 221/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 4.8672e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 222/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8688e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 223/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8704e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 224/700\n",
            "188/188 - 1s - loss: 0.0042 - val_loss: 4.8721e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 225/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8738e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 226/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8756e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 227/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8773e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 228/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8791e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 229/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8810e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 230/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8828e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 231/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8847e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 232/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8866e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 233/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8886e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 234/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8905e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 235/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8925e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 236/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8945e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 237/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8966e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 238/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.8986e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 239/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9007e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 240/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9028e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 241/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9049e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 242/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9070e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 243/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9091e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 244/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9113e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 245/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9135e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 246/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9157e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 247/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9179e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 248/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9201e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 249/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9224e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 250/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9246e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 251/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9269e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 252/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9291e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 253/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9314e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 254/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9337e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 255/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9360e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 256/700\n",
            "188/188 - 2s - loss: 0.0042 - val_loss: 4.9383e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 257/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9407e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 258/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9430e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 259/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9453e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 260/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9477e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 261/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9500e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 262/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9524e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 263/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9547e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 264/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9571e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 265/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9595e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 266/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9619e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 267/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9642e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 268/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9666e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 269/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9690e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 270/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9714e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 271/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9738e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 272/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9762e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 273/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9786e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 274/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9809e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 275/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9833e-04 - 2s/epoch - 8ms/step\n",
            "Epoch 276/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9857e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 277/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9881e-04 - 2s/epoch - 12ms/step\n",
            "Epoch 278/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9905e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 279/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9929e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 280/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 4.9953e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 281/700\n",
            "188/188 - 1s - loss: 0.0041 - val_loss: 4.9977e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 282/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0000e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 283/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0024e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 284/700\n",
            "188/188 - 1s - loss: 0.0041 - val_loss: 5.0048e-04 - 1s/epoch - 8ms/step\n",
            "Epoch 285/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0071e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 286/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0095e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 287/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0118e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 288/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0142e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 289/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0165e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 290/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0189e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 291/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0212e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 292/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0235e-04 - 2s/epoch - 9ms/step\n",
            "Epoch 293/700\n",
            "188/188 - 2s - loss: 0.0041 - val_loss: 5.0258e-04 - 2s/epoch - 10ms/step\n",
            "Epoch 294/700\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-f6a718099432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-134-173c6505c421>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(steps_ahead)\u001b[0m\n\u001b[1;32m     74\u001b[0m                             monitor='val_loss', mode='min') \n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         lstm_model = model.fit(train_X, train_y, epochs=n_epochs,\n\u001b[0m\u001b[1;32m     77\u001b[0m                                \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_save\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EvEswvoTXy5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                            config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons=30# 22\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons, activation=\"tanh\",\n",
        "               input_shape=(timesteps, n_features)))\n",
        "\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "#reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 700\n",
        "loss_tracking = list()\n",
        "\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=8, validation_data=(test_X, test_y),\n",
        "                     verbose=2,\n",
        "                     shuffle=False)\n",
        "    # to find for which epoch each loss belongs\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "    # Save the model every 10 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "        #model.save(f'model_{epoch}Eps.h5')\n",
        "        model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU \n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                            config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons=30# 22\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons, activation=\"tanh\",\n",
        "               input_shape=(timesteps, n_features)))\n",
        "\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "#reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-3, mode='min')\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 700\n",
        "loss_tracking = list()\n",
        "\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_scaled[:,:-2], train_scaled[:,-2:], callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=8, validation_data=(test_scaled[:,:-2], test_scaled[:,-2:]),\n",
        "                     verbose=2,\n",
        "                     shuffle=False)\n",
        "    # to find for which epoch each loss belongs\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "    # Save the model every 10 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "        #model.save(f'model_{epoch}Eps.h5')\n",
        "        model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))\n"
      ],
      "metadata": {
        "id": "89topE2MGmXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "6fd73ad8-3e98-4e77-9e7c-2ebad7b4bd1c"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-243-e9bd7954c27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}/{n_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Train the model for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     history = model.fit(train_scaled[:,:-2], train_scaled[:,-2:], callbacks=[early_stopping, mcp_save],\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_18\" is incompatible with the layer: expected shape=(None, 4, 7), found shape=(None, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXCP3rhtt_nL",
        "outputId": "9c26021f-3a92-48ee-cea7-8542f807b098"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1521, 4, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACz8nZKitNyv",
        "outputId": "153b71c8-eb93-4dfe-afd6-99b1db491aab"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 4, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNb0SQjRuIL9",
        "outputId": "6c7c71fb-0159-407b-fe55-8762e2d613dd"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1521, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLc6p334uMBh",
        "outputId": "e5333748-375d-4095-9eb3-7a9221b85cde"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                            config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons= 30\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters = 46, kernel_size=1, dilation_rate=1, padding='same',\n",
        "                 input_shape=(timesteps, n_features)))\n",
        "model.add(Conv1D(filters = 25, kernel_size=1, dilation_rate=1, padding='same'))\n",
        "model.add(Conv1D(filters = 10, kernel_size=1, dilation_rate=1, padding='same'))\n",
        "#model.add(Conv1D(filters = 46, kernel_size=10, dilation_rate=1, padding='causal'))\n",
        "model.add(Conv1D(filters = 46, kernel_size=2, dilation_rate=1, padding='causal'))\n",
        "\n",
        "\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 700\n",
        "loss_tracking = list()\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=2, validation_data=(test_X, test_y),\n",
        "                     verbose=2,\n",
        "                     shuffle=False)\n",
        "    # to find for which epoch each loss belongs\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "    # Save the model every 10 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "        #model.save(f'model_{epoch}Eps.h5')\n",
        "        model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ],
      "metadata": {
        "id": "lZ7I0rvzsWSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhTpbudiq0FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  best tcn architecture is the one used in the papaer"
      ],
      "metadata": {
        "id": "Vi-k3p80zLmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YyrxlI_zh4_P"
      },
      "outputs": [],
      "source": [
        "# load the trained saved model\n",
        "model_saved = tf.keras.models.load_model('/content/drive/MyDrive/my_trained_models/[50, 1, 8, 2, 20]_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tInM8k2Aa_V1"
      },
      "outputs": [],
      "source": [
        "# Load the best weights\n",
        "model_saved.load_weights('/content/drive/MyDrive/my_trained_models/[50, 1, 8, 2, 20]_weights.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "615tFlHjehTK"
      },
      "outputs": [],
      "source": [
        "# Load the best weights\n",
        "model.load_weights(os.path.join(directory, 'mdl_wts.hdf5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qycqaUhnK5QM",
        "outputId": "9e9a5475-bd4a-4b68-a88a-e4b0adee2ca6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003296691575087607"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "model.evaluate(test_X, test_y, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUQ9MQO4e0uQ",
        "outputId": "b99be15b-9cc0-49d2-bcfe-101dea4207ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:82\n",
            "Validation loss: 6.0132886574137956e-05\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_X, test_y, verbose=0)\n",
        "best_epoch = loss_tracking.index(score) + 1\n",
        "# validation loss and corresponding epoch for the saved model\n",
        "print(f'Epoch:{best_epoch}\\nValidation loss: {score}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfmgjN3OhMYp"
      },
      "outputs": [],
      "source": [
        "# # continue if training is interrupted \n",
        "# model.compile(loss='mean_squared_error',\n",
        "#               optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n",
        "# early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "#                                 restore_best_weights=True, mode='min')\n",
        "# # save the best weights if training is interrupted\n",
        "# mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "#                             save_best_only=True,\n",
        "#                             monitor='val_loss', mode='min') \n",
        "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# # Set the initial and total number of epochs\n",
        "# initial_epoch = 1\n",
        "# n_epochs = 2000\n",
        "\n",
        "# # Run the training loop\n",
        "# for epoch in range(initial_epoch , n_epochs+1):\n",
        "#     print(f'Epoch {epoch}/{n_epochs}')\n",
        "#     # Train the model for one epoch\n",
        "#     history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save, reduce_lr_loss],\n",
        "#                     epochs=1, batch_size=2, validation_data=(test_X, test_y),\n",
        "#                      verbose=2,\n",
        "#                      shuffle=False)\n",
        "#     # to find for which epoch each loss belongs\n",
        "#     validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "#     loss_tracking.append(validation_loss)\n",
        "#     # Save the model every 10 epochs\n",
        "#     if epoch % 50 == 0:\n",
        "#         # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "#         #model.save(f'model_{epoch}Eps.h5')\n",
        "#         model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Om2PkqgiVjri",
        "outputId": "fbc63826-635b-4156-df77-b765c7a709a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(5))\n",
        "#plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(loss_tracking, label='test')\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHohbk8uYRIh"
      },
      "source": [
        "**MinMax Scaler equation**\n",
        "$$x' = \\frac{(x - min)}{(max - min)} \\times (new\\ max\\ value - new\\ min\\  value) + new\\ min\\ value$$<br/>\n",
        "\n",
        "\n",
        "$$x = \\frac{(max - min)\\times (new\\ min\\ value + x') + (new\\ max\\ value - new\\ min\\ value)\\times min}{new\\ max\\ value - new\\ min\\ value}$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$x$ is the inverse scaled value\n",
        "$x'$ is the scaled value\n",
        "$min$ is the minimum value of the original data\n",
        "$max$ is the maximum value of the original data.<br/>\n",
        "$new\\ max\\ value$ and $new\\ min\\ value$ is the new range that we want to scale the data to. For example: $(1,0)\\ or\\ (1,-1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ3IIvIhvHaz",
        "outputId": "9090f235-f06b-49f3-b567-2cc77130c52c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# make a prediction \n",
        "# select the number of obersvtions for prediction\n",
        "n_obs = len(test)\n",
        "yhat = model.predict(test_X[-n_obs:], verbose=1)\n",
        "\n",
        "\n",
        "# invert scaling \n",
        "scaled_y = pd.DataFrame(test_y)\n",
        "scaled_yhat = pd.DataFrame(yhat) ## ravel () converting into 1D array\n",
        "#obtain the min and max from the training set\n",
        "unscaled_train = pd.DataFrame(series_supervised[:len(train)])\n",
        "#new feature range\n",
        "new_max_value = 1 \n",
        "new_min_value= 0\n",
        "feature_range = new_max_value - new_min_value\n",
        "\n",
        "def transform_column(column):\n",
        "    min_value = min(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    max_value = max(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    return ((max_value - min_value) * (new_min_value + column) + (feature_range  * min_value)) / feature_range \n",
        "    \n",
        "# invert scaling for actual\n",
        "inv_scale_y = scaled_y.apply(transform_column, axis=0)\n",
        "inv_scale_y = inv_scale_y.values\n",
        "# invert scaling for forecast\n",
        "inv_scale_yhat = scaled_yhat.apply(transform_column, axis=0)\n",
        "inv_scale_yhat = inv_scale_yhat.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(inv_scale_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UqsUebr1EW6w",
        "outputId": "d98f9a48-964a-4778-8e70-82899d241865"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0           1\n",
              "0   -112.776304  -27.234880\n",
              "1    -27.234880   23.335197\n",
              "2     23.335197 -377.514432\n",
              "3   -377.514432  -30.505581\n",
              "4    -30.505581  -21.322458\n",
              "..          ...         ...\n",
              "376   10.315289    3.270702\n",
              "377    3.270702   44.783451\n",
              "378   44.783451   17.925960\n",
              "379   17.925960 -104.788245\n",
              "380 -104.788245 -177.121066\n",
              "\n",
              "[381 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cf3f0af-863b-445f-b48d-7c8b6ec91840\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-112.776304</td>\n",
              "      <td>-27.234880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-27.234880</td>\n",
              "      <td>23.335197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.335197</td>\n",
              "      <td>-377.514432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-377.514432</td>\n",
              "      <td>-30.505581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-30.505581</td>\n",
              "      <td>-21.322458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>10.315289</td>\n",
              "      <td>3.270702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>3.270702</td>\n",
              "      <td>44.783451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>44.783451</td>\n",
              "      <td>17.925960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>17.925960</td>\n",
              "      <td>-104.788245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>-104.788245</td>\n",
              "      <td>-177.121066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>381 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cf3f0af-863b-445f-b48d-7c8b6ec91840')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cf3f0af-863b-445f-b48d-7c8b6ec91840 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cf3f0af-863b-445f-b48d-7c8b6ec91840');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "TqftbPYxvEE5"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for actual \n",
        "df = pd.DataFrame(series.iloc[-len(test)-steps_ahead:,-1])\n",
        "n_vars = df.shape[1]\n",
        "columns = df.columns\n",
        "cols, names = list(), list()\n",
        "for i in range(0, steps_ahead):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "        names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "    else:\n",
        "        names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "# put it all together\n",
        "agg = pd.concat(cols, axis=1)\n",
        "agg.columns = names\n",
        "agg.dropna(inplace=True)\n",
        "agg = agg.iloc[:-1]\n",
        "#drop all the variables that we don't want to predict\n",
        "#agg.drop(columns=vars_to_drop, inplace=True)\n",
        "agg = agg.to_numpy()\n",
        "inv_y = np.add(inv_scale_y,agg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWAqc4iTkxvn"
      },
      "source": [
        "* To invert the differencing of time series for multistep prediction:<br/>\n",
        "The equation is given by $$\n",
        "\\hat x_{t+h|t}=x_t+(\\widehat{\\Delta x_{t+1}}+\\dots+\\widehat{\\Delta x_{t+h}}).\n",
        "$$ <br/>\n",
        "where: <br/>\n",
        "$\\hat x_{t+h|t}$ is the predicted value of the time series x at time $t$+h, given the value of the time series at time $t$.<br/>\n",
        "$x_t$ is the value of the time series $x$ at time t.<br/>\n",
        "${\\Delta x_{t+1}}$ is the difference between the value of the time series $x$ at time $t+1$ and the value of the time series at time t.<br/>\n",
        "${\\Delta x_{t+2}}$ is the difference between the value of the time series $x$ at time $t+2$ and the value of the time series at time $t+1$.<br/>\n",
        "${\\Delta x_{t+h}}$ is the difference between the value of the time series $x$ at time $t+h$ and the value of the time series at time $t+h-1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "DSJErK0WDkX4"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for forecast\n",
        "# to invert the diffrenced predicted values,the the predicted differenced value is added\n",
        "# to previous predicted diffenced values and last available observation in test set(Xt) as explained above\n",
        "originalSeries_supervised = series_to_supervised(series, series.columns, n_in=timesteps, n_out=steps_ahead, dropnan=True)\n",
        "current_timestep = 1\n",
        "originalSeries_xt = originalSeries_supervised[['BORE_OIL_VOL(t)','BORE_OIL_VOL(t+1)']]\n",
        "# A predicted value at any given step ahead is a result of the previous cumulative differnced predicted values and current time step\n",
        "col = []\n",
        "inv_yhat_cum = np.cumsum(inv_scale_yhat, axis=1)\n",
        "\n",
        "for i in range(n_obs):\n",
        "    #.ravel() flattens the series into a one-dimensional array\n",
        "    inverted_diff_yhat = originalSeries_xt[-n_obs:].values[i] + inv_yhat_cum[i]\n",
        "    col.append(inverted_diff_yhat)\n",
        "col = pd.DataFrame(col)\n",
        "inv_yhat = col.values # convert df to NumpyArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51SnY7n5e0nx",
        "outputId": "425c2666-877c-40be-e76b-8da4869f1ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Average scores for the vector output 2 steps ahead:\n",
            "\n",
            "Test RMSE: 517.58664\n",
            "Test MAE: 304.76658\n",
            "Test r2: 0.45559\n",
            "Test wMAPE: 13.34431 \n",
            "Test SMAPE: 16.53452 \n"
          ]
        }
      ],
      "source": [
        "# Performance evaluation\n",
        "rmse_test, RMSPE_test, MAE_test, MAPE_test, r2_test, wMAPE_test, SMAPE_test  = [], [], [], [], [], [], []\n",
        "# calculate the score for each day\n",
        "\n",
        "for i in range(test_y.shape[1]):\n",
        "    result_rmse = sqrt(mean_squared_error(inv_y[:,i], inv_yhat[:,i]))\n",
        "    result_RMSPE = RMSPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAE = mean_absolute_error(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAPE = MAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_r2 = r2_score(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_wMAPE = wMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_SMAPE = SMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "\n",
        "    rmse_test.append(result_rmse)\n",
        "    RMSPE_test.append(result_RMSPE)\n",
        "    MAE_test.append(result_MAE)\n",
        "    MAPE_test.append(result_MAPE)\n",
        "    r2_test.append(result_r2)\n",
        "    wMAPE_test.append(result_wMAPE)\n",
        "    SMAPE_test.append(result_SMAPE)\n",
        "    \n",
        "## calculate overall score\n",
        "print(\"The Average scores for the vector output {} steps ahead:\\n\".format(steps_ahead))\n",
        "print('Test RMSE: %.5f' % np.mean(rmse_test))\n",
        "#print('Test RMSPE: %.5f' % np.mean(RMSPE_test)) because of that the denominator (actual) has some zero values\n",
        "print('Test MAE: %.5f' % np.mean(MAE_test))\n",
        "#print('Test MAPE: %.5f' % np.mean(MAPE_test)) #because of that the denominator (actual) has some zero values\n",
        "print('Test r2: %.5f' % np.mean(r2_test))\n",
        "print('Test wMAPE: %.5f ' % np.mean(wMAPE_test))\n",
        "print('Test SMAPE: %.5f ' % np.mean(SMAPE_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "H4KkEyXsJvDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "870b7b56-869a-4336-cab9-05d16b5c5a06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1224x1080 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the scores for each time step of the multi-step forecast\n",
        "scores = pd.DataFrame({\"rmse_test\":rmse_test, \"MAE_test\":MAE_test, \"R-squared_test\":r2_test, \"wMAPE_test\":wMAPE_test, \"SMAPE_test\":SMAPE_test})\n",
        "\n",
        "# Reset the index, keeping the old index as a column\n",
        "scores = scores.reset_index(drop=False)\n",
        "\n",
        "# Set the 'index' column as the new index\n",
        "scores.index = scores['index'] + 1\n",
        "\n",
        "# Drop the old 'index' column\n",
        "scores = scores.drop(columns='index')\n",
        "\n",
        "data = scores.columns\n",
        "\n",
        "# Creating figure with two rows and one column\n",
        "fig, axs = plt.subplots(nrows=len(data), figsize=(17, 15))\n",
        "\n",
        "axs = axs.ravel()\n",
        "\n",
        "for id, column in enumerate(data):\n",
        "    # Set the x-axis limits\n",
        "    #axs[id].set_xlim(xmin=1, xmax= steps_ahead)\n",
        "    #print the name of the test on plot\n",
        "    axs[id].plot(scores[column])\n",
        "    # Add a title to the x-axis\n",
        "    axs[id].set_xlabel('Steps ahead',fontsize=10, labelpad=0.1)\n",
        "    axs[id].grid(True)\n",
        "    # Remove the horizontal grid lines\n",
        "    axs[id].grid(which='both', axis='y')\n",
        "    axs[id].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "    axs[id].legend([column], loc='upper left', fontsize=15, handlelength=0, handletextpad=0, frameon=False)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "doFyZoCCZ-ht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "7e9c5fc3-c49f-4bb3-c64c-ab373a761259"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the last forecasted values on test set\n",
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "# Set the major locator for the x-axis\n",
        "x = list(range(1, len(inv_yhat[-1])+1))\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "ax.plot(x, inv_yhat[-1], label = \"predicted\")\n",
        "ax.plot(x, inv_y[-1], label = \"actual\")\n",
        "ax.set_ylabel('Oil Rate', fontsize=15)\n",
        "ax.set_xlabel('Steps Ahead (Days)',fontsize=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PcMnvDfCdcQlg3ikKWSjWFO9GT6HGhdO",
      "authorship_tag": "ABX9TyOCn/IFTA+iiXXTIQTpJQLK",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}