{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashrafalaghbari/oil-production-forecasting/blob/main/optimal_TCN_single_step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "x1LrkoSv4cc7",
        "outputId": "a81b4a26-0719-47db-f14c-f718ce246a14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tcn --no-dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8tyr5_aWpmN",
        "outputId": "ef6ea6c1-b000-4ffb-d72d-e6808fc51cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XxzUA1Pg4iEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import re\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation, Dropout\n",
        "from keras.layers import LSTM, Conv1D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import math "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6ZrWV9NpfPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417e3aae-4c6d-4e04-e5b8-80c4b1cfb0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu7vsRejtR_4"
      },
      "outputs": [],
      "source": [
        "# # check if GPU is utilized \n",
        "# device_name = tf.config.experimental.list_physical_devices()[-1][-1]\n",
        "# if device_name != 'GPU':\n",
        "#     raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVMp6qZiT9gO"
      },
      "outputs": [],
      "source": [
        "# Select the best features\n",
        "def select_features(df, target, correlation_type, threshold):\n",
        "    if (threshold < -1 ) | (threshold > 1 ) :\n",
        "            raise SystemError('correlation threshold is out of bounds')\n",
        "    features = df.corr(correlation_type).loc[target].drop(target)\n",
        "    best_features = features.where(abs(features) > threshold).dropna()\n",
        "    df = pd.concat([df[target], df[best_features.index]], axis=1)\n",
        "    return df\n",
        "\n",
        "# convert series to supervised learning using a sliding  window approach\n",
        "def series_to_supervised(data, columns, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('%s(t-%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "        # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# scale train and test data to new feature range[0, 1]\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        "\n",
        "\n",
        "# inverse differencing\n",
        "def inverse_difference(history, interval=1):\n",
        "\treturn history[-len(test_scaled)-interval:-interval]\n",
        "\n",
        "#Evaluation metrics\n",
        "# compute RMSPE\n",
        "def RMSPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
        "\tresult /= len(x)\n",
        "\tresult = sqrt(result)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute MAPE\n",
        "def MAPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += abs((x[i]-y[i])/x[i])\n",
        "\tresult /= len(x)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute wMAPE weighted absolute percentage error\n",
        "def wMAPE(actual, predicted): \n",
        "    result_nom = 0\n",
        "    result_deno = 0\n",
        "    for i in range(len(actual)):\n",
        "        result_nom +=  abs(actual[i] - predicted[i])\n",
        "        result_deno +=  abs(actual[i]) \n",
        "    result = result_nom/result_deno\n",
        "    return result *100\n",
        "\n",
        "def SMAPE(actual, predicted): #Symmetric (adjusted) MEAN ABSOLUTE PERCENTAGE ERROR (SMAPE)\n",
        "    result = 0\n",
        "    for i in range(len(actual)):\n",
        "        result += abs(actual[i] - predicted[i])/(abs(actual[i]) + abs(predicted[i]))\n",
        "    result = 2 * result/ len(actual) \n",
        "    return result * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tRJsglCpLKHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd3105b-f878-4354-ff6c-03e7fc202e5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1905, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#load dataset\n",
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv', \n",
        "                     parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "days = pd.Series(range(len(series), 0, -1), index=series.index)\n",
        "series.insert(0, 'days', days)\n",
        "series['days1'] = series['days'].shift(-1)\n",
        "series[\"AVG_CHOKE_SIZE_P1\"] = series['AVG_CHOKE_SIZE_P'].shift(-1)\n",
        "series[\"ON_STREAM_HRS1\"] = series['ON_STREAM_HRS'].shift(-1)\n",
        "series['days2'] = series['days'].shift(-2)\n",
        "series[\"AVG_CHOKE_SIZE_P2\"] = series['AVG_CHOKE_SIZE_P'].shift(-2)\n",
        "series[\"ON_STREAM_HRS2\"] = series['ON_STREAM_HRS'].shift(-2)\n",
        "\n",
        "series['days3'] = series['days'].shift(-3)\n",
        "series[\"AVG_CHOKE_SIZE_P3\"] = series['AVG_CHOKE_SIZE_P'].shift(-3)\n",
        "series[\"ON_STREAM_HRS3\"] = series['ON_STREAM_HRS'].shift(-3)\n",
        "\n",
        "\n",
        "series['interaction_effect_onNext_oil1'] = series[\"AVG_CHOKE_SIZE_P1\"] * series[\"days1\"] * series[\"ON_STREAM_HRS1\"]\n",
        "series['interaction_effect_onNext_oil2'] = series[\"AVG_CHOKE_SIZE_P2\"] * series[\"days2\"] * series[\"ON_STREAM_HRS2\"]\n",
        "series['interaction_effect_onNext_oil3'] = series[\"AVG_CHOKE_SIZE_P3\"] * series[\"days3\"] * series[\"ON_STREAM_HRS3\"]\n",
        "series.dropna(inplace=True)\n",
        "\n",
        "\n",
        "# # # # select feature based on correlation\n",
        "# # series = select_features(series, \"BORE_OIL_VOL\", \"spearman\", 0.2)\n",
        "# # select features manually\n",
        "series =series[['interaction_effect_onNext_oil1', 'interaction_effect_onNext_oil2', 'interaction_effect_onNext_oil3',\n",
        "                \"BORE_OIL_VOL\",\n",
        "                \"ON_STREAM_HRS1\",\"ON_STREAM_HRS2\",\"ON_STREAM_HRS3\", \"AVG_CHOKE_SIZE_P1\", \"AVG_CHOKE_SIZE_P2\", \"AVG_CHOKE_SIZE_P3\"\n",
        "                ]] \n",
        "series.shape             "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv', \n",
        "                     parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "series.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx73tOhW0kM-",
        "outputId": "049e2efd-c97f-42c3-bd36-b623e4d163ac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ON_STREAM_HRS', 'AVG_DOWNHOLE_PRESSURE', 'AVG_DOWNHOLE_TEMPERATURE',\n",
              "       'AVG_CHOKE_SIZE_P', 'AVG_WHP_P', 'AVG_WHT_P', 'DP_CHOKE_SIZE',\n",
              "       'BORE_OIL_VOL', 'BORE_GAS_VOL', 'BORE_WAT_VOL', 'F_4_ON_STREAM_HRS',\n",
              "       'F_4_BORE_WI_VOL', 'F_5_ON_STREAM_HRS', 'F_5_BORE_WI_VOL'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv', \n",
        "                     parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "days = pd.Series(range(len(series), 0, -1), index=series.index)\n",
        "series.insert(0, 'days', days)\n",
        "series['days1'] = series['days'].shift(-1)\n",
        "series[\"AVG_CHOKE_SIZE_P1\"] = series['AVG_CHOKE_SIZE_P'].shift(-1)\n",
        "series[\"ON_STREAM_HRS1\"] = series['ON_STREAM_HRS'].shift(-1)\n",
        "series['days2'] = series['days'].shift(-2)\n",
        "series[\"AVG_CHOKE_SIZE_P2\"] = series['AVG_CHOKE_SIZE_P'].shift(-2)\n",
        "series[\"ON_STREAM_HRS2\"] = series['ON_STREAM_HRS'].shift(-2)\n",
        "\n",
        "series['days3'] = series['days'].shift(-3)\n",
        "series[\"AVG_CHOKE_SIZE_P3\"] = series['AVG_CHOKE_SIZE_P'].shift(-3)\n",
        "series[\"ON_STREAM_HRS3\"] = series['ON_STREAM_HRS'].shift(-3)\n",
        "\n",
        "\n",
        "series['interaction_effect_onNext_oil1'] = series[\"AVG_CHOKE_SIZE_P1\"] *  series[\"ON_STREAM_HRS1\"]\n",
        "series['interaction_effect_onNext_oil2'] = series[\"AVG_CHOKE_SIZE_P2\"] *  series[\"ON_STREAM_HRS2\"]\n",
        "series['interaction_effect_onNext_oil3'] = series[\"AVG_CHOKE_SIZE_P3\"] *  series[\"ON_STREAM_HRS3\"]\n",
        "series.dropna(inplace=True)\n",
        "\n",
        "\n",
        "# # # # select feature based on correlation\n",
        "# # series = select_features(series, \"BORE_OIL_VOL\", \"spearman\", 0.2)\n",
        "# # select features manually\n",
        "series =series[['interaction_effect_onNext_oil1', 'interaction_effect_onNext_oil2', 'interaction_effect_onNext_oil3',\n",
        "                 \"days\",\n",
        "                \"ON_STREAM_HRS1\",\"ON_STREAM_HRS2\",\"ON_STREAM_HRS3\", \"AVG_CHOKE_SIZE_P1\", \"AVG_CHOKE_SIZE_P2\", \"AVG_CHOKE_SIZE_P3\",\n",
        "\n",
        "                'AVG_DOWNHOLE_PRESSURE', 'AVG_DOWNHOLE_TEMPERATURE',\n",
        "        'AVG_WHP_P', 'AVG_WHT_P',\n",
        "        'BORE_GAS_VOL', 'BORE_WAT_VOL', \n",
        "       #'F_4_BORE_WI_VOL',  'F_5_BORE_WI_VOL',\n",
        "       \"BORE_OIL_VOL\"\n",
        "\n",
        "                ]] \n",
        "series.shape             "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LejOYrFB0Z3u",
        "outputId": "9d78b64f-32d2-4e53-a166-ea78e75319dc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1905, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = [\"ON_STREAM_HRS1\",\"ON_STREAM_HRS2\",\"ON_STREAM_HRS3\", \"AVG_CHOKE_SIZE_P1\", \"AVG_CHOKE_SIZE_P2\", \"AVG_CHOKE_SIZE_P3\"]\n",
        "for i in col:\n",
        "    if i not in [\"AVG_CHOKE_SIZE_P1\", \"AVG_CHOKE_SIZE_P2\", \"AVG_CHOKE_SIZE_P3\"]:\n",
        "        series[f\"{i}cut\"] = pd.cut(series[i], bins= [0,5,10,15,20,24])\n",
        "    else: \n",
        "        series[f\"{i}cut\"] = pd.cut(series[i], bins= [0,10,20,30,40,50,60,70,80,90, 100])"
      ],
      "metadata": {
        "id": "WgvgnoOPnf0A"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6EqE-9rDcM6",
        "outputId": "c7797316-d21d-4304-d464-ea7db6efcf67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1905, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ['ON_STREAM_HRS1cut',\n",
        "       'ON_STREAM_HRS2cut', 'ON_STREAM_HRS3cut', 'AVG_CHOKE_SIZE_P1cut',\n",
        "       'AVG_CHOKE_SIZE_P2cut', 'AVG_CHOKE_SIZE_P3cut']\n",
        "for i in data:\n",
        "    df = pd.get_dummies(series[i], prefix =i)\n",
        "    series.drop([i],axis=1, inplace=True)\n",
        "    series = pd.concat([series, df], axis=1)"
      ],
      "metadata": {
        "id": "xhZ_ySxcpqsM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series.drop([\"ON_STREAM_HRS1\",\"ON_STREAM_HRS2\",\"ON_STREAM_HRS3\", \"AVG_CHOKE_SIZE_P1\", \"AVG_CHOKE_SIZE_P2\", \"AVG_CHOKE_SIZE_P3\"],\n",
        "            axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "tXyarPZsqnUL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "KpoQJ7P7lmyb"
      },
      "outputs": [],
      "source": [
        "# Create a new directory in My Drive\n",
        "directory = '/content/drive/My Drive/my_trained_models'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # convert series to stationary \n",
        "series_diff = series.copy()\n",
        "diff_order = 1\n",
        "series_diff['BORE_OIL_VOL'] = series_diff['BORE_OIL_VOL'].diff(diff_order)\n",
        "\n",
        "# Define window size and number of the steps ahead for forecasting\n",
        "window_size = 4\n",
        "steps_ahead = 3\n",
        "\n",
        "# # convert the stationary series to supervise learning\n",
        "series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in= window_size, n_out= steps_ahead, dropnan=True)   \n",
        "\n",
        "# drop columns we don't want to predict\n",
        "pattern = re.compile(r\"(t-)|^BORE_OIL_VOL.*\")\n",
        "\n",
        "# Extract the column names that match the pattern\n",
        "matching_columns = [col for col in series_supervised.columns if re.search(pattern, col)]\n",
        "series_supervised = series_supervised[matching_columns]"
      ],
      "metadata": {
        "id": "6b5TKp5GhQE-"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # split into train and test sets\n",
        "n_features = int((len(series_supervised.columns) -steps_ahead)/window_size)\n",
        "series_supervised = series_supervised.values\n",
        "train_size = int(series_supervised.shape[0] * 0.8)\n",
        "test_size = series_supervised.shape[0] - train_size\n",
        "train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "print(\"train.shape:\",train.shape, \"test.shape:\",test.shape)\n",
        "\n",
        "# scale  the data to a feature range(0,1)\n",
        "scaler, train_scaled, test_scaled = scale(train, test)\n",
        "print('train_scaled.shape:',train_scaled.shape, \"test_scaled.shape:\",test_scaled.shape)\n",
        "\n",
        "# # reshape input to be 3D [samples, window_size, features]\n",
        "train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "train_X = train_X.reshape(train_X.shape[0], window_size, n_features)\n",
        "test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "test_X = test_X.reshape(test_X.shape[0], window_size, n_features )\n",
        "print(\"train_X.shape:\",train_X.shape, \"train_y.shape:\",train_y.shape,\n",
        "        \"test_X.shape:\", test_X.shape,\"test_y.shape:\",test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsv-ScobJY3w",
        "outputId": "83e030b6-ccef-4a12-9705-b67930fdcc57"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (1518, 227) test.shape: (380, 227)\n",
            "train_scaled.shape: (1518, 227) test_scaled.shape: (380, 227)\n",
            "train_X.shape: (1518, 4, 56) train_y.shape: (1518, 3) test_X.shape: (380, 4, 56) test_y.shape: (380, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grid search \n",
        "def get_hyper_param(n_epochs, num_hidden_layers, num_neurons, batch_size, window_size):\n",
        "    \"\"\" \n",
        "    This is a grid search function that generates all possible comibinations\n",
        "    from the search space \n",
        "\n",
        "    Args:\n",
        "    n_epochs: number of epochs\n",
        "    num_hidden_layers: number of hidden layers\n",
        "    num_neurons: number of neurons same for both input and hidden layers \n",
        "    batch_size: number of batch size \n",
        "    window_size: historical timesteps in the sliding window\n",
        "    \n",
        "    \"\"\"\n",
        "    hyper_param = []\n",
        "    for current_params in itertools.product(n_epochs, num_hidden_layers, num_neurons, batch_size, window_size):\n",
        "        hyper_param.append(list(current_params))\n",
        "    return hyper_param\n",
        "\n",
        "# Seacrh space\n",
        "n_epochs = [500]\n",
        "num_hidden_layers = [1, 2]\n",
        "num_neurons = [4, 8, 16, 32, 64]\n",
        "batch_size = [2, 4]\n",
        "window_size = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
        "\n",
        "hyper_param = get_hyper_param(n_epochs, num_hidden_layers, num_neurons, batch_size, window_size)\n",
        "len(hyper_param)# print the number of combinations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0EVoWtzzMsz",
        "outputId": "ae9992e3-246c-461d-ec9f-2497d48095c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparamter tuning\n",
        "def fit_lstm(steps_ahead = 3):\n",
        "    \n",
        "        # Create a new directory in My Drive\n",
        "    directory = '/content/drive/My Drive/my_trained_models'\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    # setting the session configurations for reproducibility.\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    np.random.seed(42)\n",
        "    np.random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                            inter_op_parallelism_threads=1)\n",
        "    from keras import backend as K\n",
        "    tf.random.set_seed(1234)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                                config=session_conf)\n",
        "    K.set_session(sess)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "    min_val_loss = math.inf \n",
        "    for n_epochs, num_hidden_layers, num_neurons, batch_size, window_size in hyper_param:\n",
        "        print('n_epochs', n_epochs, 'num_hidden_layers', num_hidden_layers, 'num_neurons',\n",
        "              num_neurons, \"batch_size\", batch_size, 'window_size', window_size)\n",
        "        combinations = [n_epochs, num_hidden_layers, num_neurons, batch_size, window_size]\n",
        "\n",
        "        #feature engineering\n",
        "        # # convert the stationary series to supervise learning\n",
        "        series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in= window_size, n_out= steps_ahead, dropnan=True)   \n",
        "\n",
        "        # drop columns we don't want to predict\n",
        "        pattern = re.compile(r\"(t-)|^BORE_OIL_VOL.*\")\n",
        "        # Extract the column names that match the pattern\n",
        "        matching_columns = [col for col in series_supervised.columns if re.search(pattern, col)]\n",
        "        series_supervised = series_supervised[matching_columns]\n",
        "\n",
        "        # # split into train and test sets\n",
        "        series_supervised = series_supervised.values\n",
        "        train_size = int(series_supervised.shape[0] * 0.8)\n",
        "        test_size = series_supervised.shape[0] - train_size\n",
        "        train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "        print(\"train.shape:\",train.shape, \"test.shape:\",test.shape)\n",
        "\n",
        "        # scale  the data to a feature range(0,1)\n",
        "        scaler, train_scaled, test_scaled = scale(train, test)\n",
        "        print('train_scaled.shape:',train_scaled.shape, \"test_scaled.shape:\",test_scaled.shape)\n",
        "\n",
        "        # reshape input to be 3D [samples, window_size, features]\n",
        "        n_features = len(series.columns)\n",
        "        train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "        train_X = train_X.reshape(train_X.shape[0], window_size, n_features)\n",
        "        test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "        test_X = test_X.reshape(test_X.shape[0], window_size, n_features )\n",
        "        print(\"train_X.shape:\",train_X.shape, \"train_y.shape:\",train_y.shape,\n",
        "              \"test_X.shape:\", test_X.shape,\"test_y.shape:\",test_y.shape)\n",
        "        \n",
        "        # instantiate the LSTM model\n",
        "        model = Sequential()\n",
        "\n",
        "        if num_hidden_layers != 1:\n",
        "  \n",
        "            for num in range(num_hidden_layers-1):\n",
        "                model.add(LSTM(num_neurons, input_shape=(window_size, n_features), return_sequences=True))\n",
        "            model.add(LSTM(num_neurons))\n",
        "\n",
        "        else:\n",
        "            model.add(LSTM(num_neurons, input_shape=(window_size, n_features)))\n",
        "        model.add(Dense(steps_ahead)) # output layer\n",
        "        model.compile(loss='mean_squared_error',\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "        \n",
        "        #prevent overfitting\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "        \n",
        "        # save the best weights\n",
        "        mcp_save = ModelCheckpoint(os.path.join(directory, f'{combinations}_weights.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "        # fit model\n",
        "        lstm_model = model.fit(train_X, train_y, epochs=n_epochs,\n",
        "                            callbacks=[early_stopping, mcp_save],\n",
        "                            batch_size=batch_size,\n",
        "                            validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "        \n",
        "        # Save the model  in HDF5 foramt with a filename that includes the hyperparamters\n",
        "        model.save(os.path.join(directory, f'{combinations}_model.h5'))\n",
        "        # Load the best weights\n",
        "        model.load_weights(os.path.join(directory, f'{combinations}_weights.hdf5'))\n",
        "        current_val_loss = model.evaluate(test_X, test_y, verbose=0) #lstm_model.history['val_loss'][-1]\n",
        "        if current_val_loss < min_val_loss:\n",
        "            min_val_loss = current_val_loss\n",
        "            best_params = [n_epochs,  num_hidden_layers, num_neurons, batch_size, window_size]\n",
        "\n",
        "        \n",
        "    print('final best params',\"n_epochs:\",best_params[0],\"num_hidden_layers:\",\n",
        "          best_params[1], \"num_neurons:\", best_params[2], \"batch_size:\", best_params[3],\n",
        "          \"window_size:\",best_params[4]) \n",
        "    return {\"best_params\": str(best_params) , \"MSE\": min_val_loss}#, lstm_model"
      ],
      "metadata": {
        "id": "WWzSZIJ36xtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the model and repeat the evaluation to reduce the certainty asscoicated with the random initialization of model weights\n",
        "# def run_model(n_repeats = 1):\n",
        "#     scores = [fit_lstm_random() for _ in range(n_repeats)]\n",
        "#     result = pd.DataFrame(scores)\n",
        "#     result = result.groupby(\"best_params\").mean()\n",
        "#     return result"
      ],
      "metadata": {
        "id": "Zpnlrc0t52h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_lstm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QpKzZlx53Qd",
        "outputId": "9ce5fabc-0902-4735-842d-b7df3fe83b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.1495e-05 - 889ms/epoch - 2ms/step\n",
            "Epoch 172/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.1203e-05 - 909ms/epoch - 2ms/step\n",
            "Epoch 173/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.0918e-05 - 870ms/epoch - 2ms/step\n",
            "Epoch 174/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.0642e-05 - 879ms/epoch - 2ms/step\n",
            "Epoch 175/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.0374e-05 - 895ms/epoch - 2ms/step\n",
            "Epoch 176/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.0114e-05 - 872ms/epoch - 2ms/step\n",
            "Epoch 177/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9863e-05 - 886ms/epoch - 2ms/step\n",
            "Epoch 178/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9619e-05 - 886ms/epoch - 2ms/step\n",
            "Epoch 179/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9383e-05 - 899ms/epoch - 2ms/step\n",
            "Epoch 180/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9154e-05 - 888ms/epoch - 2ms/step\n",
            "Epoch 181/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8933e-05 - 914ms/epoch - 2ms/step\n",
            "Epoch 182/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8719e-05 - 938ms/epoch - 2ms/step\n",
            "Epoch 183/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8511e-05 - 874ms/epoch - 2ms/step\n",
            "Epoch 184/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8311e-05 - 886ms/epoch - 2ms/step\n",
            "Epoch 185/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8117e-05 - 858ms/epoch - 2ms/step\n",
            "Epoch 186/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.7929e-05 - 877ms/epoch - 2ms/step\n",
            "Epoch 187/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.7748e-05 - 922ms/epoch - 2ms/step\n",
            "Epoch 188/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.7572e-05 - 929ms/epoch - 2ms/step\n",
            "Epoch 189/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.7403e-05 - 909ms/epoch - 2ms/step\n",
            "Epoch 190/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.7239e-05 - 873ms/epoch - 2ms/step\n",
            "Epoch 191/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.7081e-05 - 908ms/epoch - 2ms/step\n",
            "Epoch 192/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6928e-05 - 911ms/epoch - 2ms/step\n",
            "Epoch 193/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6780e-05 - 895ms/epoch - 2ms/step\n",
            "Epoch 194/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6637e-05 - 892ms/epoch - 2ms/step\n",
            "Epoch 195/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6500e-05 - 886ms/epoch - 2ms/step\n",
            "Epoch 196/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6367e-05 - 941ms/epoch - 2ms/step\n",
            "Epoch 197/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6238e-05 - 877ms/epoch - 2ms/step\n",
            "Epoch 198/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.6114e-05 - 908ms/epoch - 2ms/step\n",
            "Epoch 199/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.5995e-05 - 906ms/epoch - 2ms/step\n",
            "Epoch 200/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.5879e-05 - 864ms/epoch - 2ms/step\n",
            "Epoch 201/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5767e-05 - 873ms/epoch - 2ms/step\n",
            "Epoch 202/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5660e-05 - 919ms/epoch - 2ms/step\n",
            "Epoch 203/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5556e-05 - 891ms/epoch - 2ms/step\n",
            "Epoch 204/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5455e-05 - 855ms/epoch - 2ms/step\n",
            "Epoch 205/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5359e-05 - 900ms/epoch - 2ms/step\n",
            "Epoch 206/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5266e-05 - 912ms/epoch - 2ms/step\n",
            "Epoch 207/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5175e-05 - 896ms/epoch - 2ms/step\n",
            "Epoch 208/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5089e-05 - 879ms/epoch - 2ms/step\n",
            "Epoch 209/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5005e-05 - 922ms/epoch - 2ms/step\n",
            "Epoch 210/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4924e-05 - 938ms/epoch - 2ms/step\n",
            "Epoch 211/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4846e-05 - 890ms/epoch - 2ms/step\n",
            "Epoch 212/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4771e-05 - 909ms/epoch - 2ms/step\n",
            "Epoch 213/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4699e-05 - 929ms/epoch - 2ms/step\n",
            "Epoch 214/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4629e-05 - 927ms/epoch - 2ms/step\n",
            "Epoch 215/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4561e-05 - 919ms/epoch - 2ms/step\n",
            "Epoch 216/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4497e-05 - 925ms/epoch - 2ms/step\n",
            "Epoch 217/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4434e-05 - 882ms/epoch - 2ms/step\n",
            "Epoch 218/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4374e-05 - 882ms/epoch - 2ms/step\n",
            "Epoch 219/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4316e-05 - 860ms/epoch - 2ms/step\n",
            "Epoch 220/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4259e-05 - 871ms/epoch - 2ms/step\n",
            "Epoch 221/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4206e-05 - 882ms/epoch - 2ms/step\n",
            "Epoch 222/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4154e-05 - 934ms/epoch - 2ms/step\n",
            "Epoch 223/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4103e-05 - 940ms/epoch - 2ms/step\n",
            "Epoch 224/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4055e-05 - 916ms/epoch - 2ms/step\n",
            "Epoch 225/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.4009e-05 - 918ms/epoch - 2ms/step\n",
            "Epoch 226/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3965e-05 - 893ms/epoch - 2ms/step\n",
            "Epoch 227/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3922e-05 - 875ms/epoch - 2ms/step\n",
            "Epoch 228/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3880e-05 - 913ms/epoch - 2ms/step\n",
            "Epoch 229/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3841e-05 - 932ms/epoch - 2ms/step\n",
            "Epoch 230/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3802e-05 - 867ms/epoch - 2ms/step\n",
            "Epoch 231/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3766e-05 - 895ms/epoch - 2ms/step\n",
            "Epoch 232/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3731e-05 - 955ms/epoch - 3ms/step\n",
            "Epoch 233/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3697e-05 - 922ms/epoch - 2ms/step\n",
            "Epoch 234/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3665e-05 - 905ms/epoch - 2ms/step\n",
            "Epoch 235/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3633e-05 - 879ms/epoch - 2ms/step\n",
            "Epoch 236/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3604e-05 - 912ms/epoch - 2ms/step\n",
            "Epoch 237/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3575e-05 - 901ms/epoch - 2ms/step\n",
            "Epoch 238/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3548e-05 - 932ms/epoch - 2ms/step\n",
            "Epoch 239/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3522e-05 - 885ms/epoch - 2ms/step\n",
            "Epoch 240/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3497e-05 - 913ms/epoch - 2ms/step\n",
            "Epoch 241/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3473e-05 - 951ms/epoch - 3ms/step\n",
            "Epoch 242/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3450e-05 - 915ms/epoch - 2ms/step\n",
            "Epoch 243/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3429e-05 - 930ms/epoch - 2ms/step\n",
            "Epoch 244/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3408e-05 - 897ms/epoch - 2ms/step\n",
            "Epoch 245/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3388e-05 - 913ms/epoch - 2ms/step\n",
            "Epoch 246/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3370e-05 - 891ms/epoch - 2ms/step\n",
            "Epoch 247/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3352e-05 - 874ms/epoch - 2ms/step\n",
            "Epoch 248/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3335e-05 - 846ms/epoch - 2ms/step\n",
            "Epoch 249/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3320e-05 - 869ms/epoch - 2ms/step\n",
            "Epoch 250/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3305e-05 - 881ms/epoch - 2ms/step\n",
            "Epoch 251/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3291e-05 - 870ms/epoch - 2ms/step\n",
            "Epoch 252/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3277e-05 - 875ms/epoch - 2ms/step\n",
            "Epoch 253/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3265e-05 - 865ms/epoch - 2ms/step\n",
            "Epoch 254/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3253e-05 - 859ms/epoch - 2ms/step\n",
            "Epoch 255/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3243e-05 - 905ms/epoch - 2ms/step\n",
            "Epoch 256/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3232e-05 - 910ms/epoch - 2ms/step\n",
            "Epoch 257/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3223e-05 - 906ms/epoch - 2ms/step\n",
            "Epoch 258/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3215e-05 - 869ms/epoch - 2ms/step\n",
            "Epoch 259/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3207e-05 - 909ms/epoch - 2ms/step\n",
            "Epoch 260/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3200e-05 - 890ms/epoch - 2ms/step\n",
            "Epoch 261/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3193e-05 - 865ms/epoch - 2ms/step\n",
            "Epoch 262/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.3187e-05 - 892ms/epoch - 2ms/step\n",
            "Epoch 263/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3182e-05 - 881ms/epoch - 2ms/step\n",
            "Epoch 264/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3177e-05 - 876ms/epoch - 2ms/step\n",
            "Epoch 265/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3174e-05 - 875ms/epoch - 2ms/step\n",
            "Epoch 266/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3170e-05 - 862ms/epoch - 2ms/step\n",
            "Epoch 267/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3168e-05 - 862ms/epoch - 2ms/step\n",
            "Epoch 268/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3165e-05 - 898ms/epoch - 2ms/step\n",
            "Epoch 269/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3164e-05 - 865ms/epoch - 2ms/step\n",
            "Epoch 270/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3163e-05 - 880ms/epoch - 2ms/step\n",
            "Epoch 271/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3162e-05 - 873ms/epoch - 2ms/step\n",
            "Epoch 272/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3162e-05 - 915ms/epoch - 2ms/step\n",
            "Epoch 273/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3163e-05 - 868ms/epoch - 2ms/step\n",
            "Epoch 274/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3163e-05 - 830ms/epoch - 2ms/step\n",
            "Epoch 275/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3165e-05 - 867ms/epoch - 2ms/step\n",
            "Epoch 276/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3167e-05 - 827ms/epoch - 2ms/step\n",
            "Epoch 277/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3170e-05 - 874ms/epoch - 2ms/step\n",
            "Epoch 278/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3173e-05 - 828ms/epoch - 2ms/step\n",
            "Epoch 279/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3176e-05 - 849ms/epoch - 2ms/step\n",
            "Epoch 280/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3179e-05 - 875ms/epoch - 2ms/step\n",
            "Epoch 281/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3183e-05 - 859ms/epoch - 2ms/step\n",
            "Epoch 282/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3188e-05 - 883ms/epoch - 2ms/step\n",
            "Epoch 283/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3192e-05 - 855ms/epoch - 2ms/step\n",
            "Epoch 284/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3198e-05 - 865ms/epoch - 2ms/step\n",
            "Epoch 285/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3203e-05 - 860ms/epoch - 2ms/step\n",
            "Epoch 286/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3209e-05 - 858ms/epoch - 2ms/step\n",
            "Epoch 287/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3215e-05 - 866ms/epoch - 2ms/step\n",
            "Epoch 288/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3222e-05 - 840ms/epoch - 2ms/step\n",
            "Epoch 289/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3229e-05 - 848ms/epoch - 2ms/step\n",
            "Epoch 290/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3236e-05 - 849ms/epoch - 2ms/step\n",
            "Epoch 291/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3244e-05 - 839ms/epoch - 2ms/step\n",
            "Epoch 292/500\n",
            "Restoring model weights from the end of the best epoch: 272.\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.3252e-05 - 858ms/epoch - 2ms/step\n",
            "Epoch 292: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 3\n",
            "train.shape: (1519, 15) test.shape: (380, 15)\n",
            "train_scaled.shape: (1519, 15) test_scaled.shape: (380, 15)\n",
            "train_X.shape: (1519, 3, 4) train_y.shape: (1519, 3) test_X.shape: (380, 3, 4) test_y.shape: (380, 3)\n",
            "Epoch 1/500\n",
            "380/380 - 5s - loss: 0.3038 - val_loss: 0.2528 - 5s/epoch - 12ms/step\n",
            "Epoch 2/500\n",
            "380/380 - 1s - loss: 0.2013 - val_loss: 0.1721 - 1s/epoch - 3ms/step\n",
            "Epoch 3/500\n",
            "380/380 - 1s - loss: 0.1238 - val_loss: 0.1090 - 1s/epoch - 3ms/step\n",
            "Epoch 4/500\n",
            "380/380 - 1s - loss: 0.0695 - val_loss: 0.0631 - 1s/epoch - 3ms/step\n",
            "Epoch 5/500\n",
            "380/380 - 1s - loss: 0.0342 - val_loss: 0.0328 - 1s/epoch - 3ms/step\n",
            "Epoch 6/500\n",
            "380/380 - 1s - loss: 0.0156 - val_loss: 0.0166 - 1s/epoch - 3ms/step\n",
            "Epoch 7/500\n",
            "380/380 - 1s - loss: 0.0093 - val_loss: 0.0099 - 1s/epoch - 3ms/step\n",
            "Epoch 8/500\n",
            "380/380 - 1s - loss: 0.0079 - val_loss: 0.0071 - 1s/epoch - 3ms/step\n",
            "Epoch 9/500\n",
            "380/380 - 1s - loss: 0.0073 - val_loss: 0.0056 - 1s/epoch - 3ms/step\n",
            "Epoch 10/500\n",
            "380/380 - 1s - loss: 0.0069 - val_loss: 0.0045 - 1s/epoch - 3ms/step\n",
            "Epoch 11/500\n",
            "380/380 - 1s - loss: 0.0065 - val_loss: 0.0036 - 1s/epoch - 3ms/step\n",
            "Epoch 12/500\n",
            "380/380 - 1s - loss: 0.0062 - val_loss: 0.0029 - 1s/epoch - 3ms/step\n",
            "Epoch 13/500\n",
            "380/380 - 1s - loss: 0.0060 - val_loss: 0.0023 - 1s/epoch - 3ms/step\n",
            "Epoch 14/500\n",
            "380/380 - 1s - loss: 0.0057 - val_loss: 0.0019 - 1s/epoch - 3ms/step\n",
            "Epoch 15/500\n",
            "380/380 - 1s - loss: 0.0056 - val_loss: 0.0015 - 1s/epoch - 3ms/step\n",
            "Epoch 16/500\n",
            "380/380 - 1s - loss: 0.0054 - val_loss: 0.0013 - 1s/epoch - 3ms/step\n",
            "Epoch 17/500\n",
            "380/380 - 1s - loss: 0.0053 - val_loss: 0.0011 - 1s/epoch - 3ms/step\n",
            "Epoch 18/500\n",
            "380/380 - 1s - loss: 0.0052 - val_loss: 9.2281e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 19/500\n",
            "380/380 - 1s - loss: 0.0051 - val_loss: 8.1241e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 20/500\n",
            "380/380 - 1s - loss: 0.0051 - val_loss: 7.2886e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 21/500\n",
            "380/380 - 1s - loss: 0.0050 - val_loss: 6.6478e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 22/500\n",
            "380/380 - 1s - loss: 0.0050 - val_loss: 6.1489e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 23/500\n",
            "380/380 - 1s - loss: 0.0049 - val_loss: 5.7543e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 24/500\n",
            "380/380 - 1s - loss: 0.0049 - val_loss: 5.4375e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 25/500\n",
            "380/380 - 1s - loss: 0.0048 - val_loss: 5.1795e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 26/500\n",
            "380/380 - 1s - loss: 0.0048 - val_loss: 4.9667e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 27/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 4.7889e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 28/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 4.6385e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 29/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 4.5096e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 30/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 4.3979e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 31/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 4.2998e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 32/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 4.2128e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 33/500\n",
            "380/380 - 1s - loss: 0.0045 - val_loss: 4.1344e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 34/500\n",
            "380/380 - 1s - loss: 0.0045 - val_loss: 4.0633e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 35/500\n",
            "380/380 - 1s - loss: 0.0045 - val_loss: 3.9979e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 36/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 3.9372e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 37/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 3.8805e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 38/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 3.8269e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 39/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 3.7761e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 40/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 3.7275e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 41/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 3.6809e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 42/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.6359e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 43/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.5923e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 44/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.5500e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 45/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.5089e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 46/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.4687e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 47/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.4294e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 48/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.3910e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 49/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.3535e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 50/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.3166e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 51/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.2805e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 52/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.2452e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 53/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 3.2105e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 54/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 3.1765e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 55/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 3.1432e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 56/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.1107e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 57/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.0788e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 58/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.0476e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 59/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.0171e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 60/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.9873e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 61/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.9582e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 62/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.9298e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 63/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.9022e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 64/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.8752e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 65/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.8490e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 66/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.8234e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 67/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.7985e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 68/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.7744e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 69/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.7508e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 70/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.7280e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 71/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.7057e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 72/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.6841e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 73/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.6630e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 74/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.6425e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 75/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.6225e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 76/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.6029e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 77/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.5838e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 78/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.5652e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 79/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.5469e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 80/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.5289e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 81/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.5112e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 82/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.4938e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 83/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.4766e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 84/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.4596e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 85/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.4427e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 86/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.4260e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 87/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.4093e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 88/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.3926e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 89/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 2.3760e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 90/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 2.3593e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 91/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 2.3425e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 92/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 2.3257e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 93/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 2.3087e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 94/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 2.2916e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 95/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 2.2744e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 96/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 2.2569e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 97/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 2.2392e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 98/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 2.2213e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 99/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 2.2032e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 100/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 2.1849e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 101/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 2.1662e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 102/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 2.1474e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 103/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 2.1282e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 104/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 2.1088e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 105/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 2.0891e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 106/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 2.0691e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 107/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 2.0489e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 108/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 2.0284e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 109/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 2.0076e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 110/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.9866e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 111/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.9654e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 112/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.9440e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 113/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.9223e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 114/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.9004e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 115/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.8783e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 116/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.8561e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 117/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.8337e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 118/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.8112e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 119/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.7886e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 120/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.7659e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 121/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.7430e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 122/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.7202e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 123/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.6972e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 124/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.6743e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 125/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.6514e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 126/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.6284e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 127/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.6055e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 128/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.5826e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 129/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.5598e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 130/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5371e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 131/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5145e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 132/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.4920e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 133/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.4697e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 134/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.4475e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 135/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.4254e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 136/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.4036e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 137/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.3819e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 138/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.3604e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 139/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.3392e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 140/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.3182e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 141/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.2975e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 142/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.2770e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 143/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.2569e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 144/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.2370e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 145/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.2175e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 146/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.1983e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 147/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.1795e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 148/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.1610e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 149/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.1430e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 150/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.1254e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 151/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.1082e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 152/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.0915e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 153/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.0752e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 154/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.0595e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 155/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.0443e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 156/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.0296e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 157/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.0155e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 158/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.0019e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 159/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.8891e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 160/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.7652e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 161/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.6472e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 162/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.5352e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 163/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.4292e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 164/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.3292e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 165/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.2351e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 166/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 9.1469e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 167/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 9.0645e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 168/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.9875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 169/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.9159e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 170/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.8495e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 171/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.7879e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 172/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.7311e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 173/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.6785e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 174/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.6300e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 175/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.5853e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 176/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.5441e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 177/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.5061e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 178/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.4709e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 179/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.4385e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 180/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.4084e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 181/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.3805e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 182/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.3545e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 183/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.3303e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 184/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.3076e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 185/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.2865e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 186/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.2665e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 187/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.2478e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 188/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.2300e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 189/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.2132e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 190/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1974e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 191/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1822e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 192/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1679e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 193/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1542e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 194/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1411e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 195/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1287e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 196/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1168e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 197/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.1054e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 198/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0946e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 199/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0842e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 200/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0743e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 201/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0649e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 202/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0558e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 203/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0473e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 204/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0390e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 205/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0312e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 206/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0237e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 207/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0167e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 208/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0099e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 209/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 8.0035e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 210/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9975e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 211/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9917e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 212/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9862e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 213/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9811e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 214/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9762e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 215/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9717e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 216/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9673e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 217/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9633e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 218/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9595e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 219/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9559e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 220/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9526e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 221/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9494e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 222/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9465e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 223/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9437e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 224/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9412e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 225/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9389e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 226/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9367e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 227/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9347e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 228/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9329e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 229/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9311e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 230/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9295e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 231/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9281e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 232/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9267e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 233/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9255e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 234/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9244e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 235/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9234e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 236/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9225e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 237/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9217e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 238/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9209e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 239/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9202e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 240/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9196e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 241/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.9191e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 242/500\n",
            "380/380 - 1s - loss: 9.9917e-04 - val_loss: 7.9186e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 243/500\n",
            "380/380 - 1s - loss: 9.9816e-04 - val_loss: 7.9181e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 244/500\n",
            "380/380 - 1s - loss: 9.9716e-04 - val_loss: 7.9178e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 245/500\n",
            "380/380 - 1s - loss: 9.9619e-04 - val_loss: 7.9174e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 246/500\n",
            "380/380 - 1s - loss: 9.9524e-04 - val_loss: 7.9171e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 247/500\n",
            "380/380 - 1s - loss: 9.9431e-04 - val_loss: 7.9168e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 248/500\n",
            "380/380 - 1s - loss: 9.9340e-04 - val_loss: 7.9166e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 249/500\n",
            "380/380 - 1s - loss: 9.9251e-04 - val_loss: 7.9164e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 250/500\n",
            "380/380 - 1s - loss: 9.9164e-04 - val_loss: 7.9162e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 251/500\n",
            "380/380 - 1s - loss: 9.9079e-04 - val_loss: 7.9161e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 252/500\n",
            "380/380 - 1s - loss: 9.8996e-04 - val_loss: 7.9160e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 253/500\n",
            "380/380 - 1s - loss: 9.8915e-04 - val_loss: 7.9159e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 254/500\n",
            "380/380 - 1s - loss: 9.8835e-04 - val_loss: 7.9158e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 255/500\n",
            "380/380 - 1s - loss: 9.8758e-04 - val_loss: 7.9157e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 256/500\n",
            "380/380 - 1s - loss: 9.8681e-04 - val_loss: 7.9156e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 257/500\n",
            "380/380 - 1s - loss: 9.8607e-04 - val_loss: 7.9155e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 258/500\n",
            "380/380 - 1s - loss: 9.8534e-04 - val_loss: 7.9155e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 259/500\n",
            "380/380 - 1s - loss: 9.8463e-04 - val_loss: 7.9154e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 260/500\n",
            "380/380 - 1s - loss: 9.8393e-04 - val_loss: 7.9154e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 261/500\n",
            "380/380 - 1s - loss: 9.8325e-04 - val_loss: 7.9154e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 262/500\n",
            "380/380 - 1s - loss: 9.8258e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 263/500\n",
            "380/380 - 1s - loss: 9.8192e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 264/500\n",
            "380/380 - 1s - loss: 9.8128e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 265/500\n",
            "380/380 - 1s - loss: 9.8065e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 266/500\n",
            "380/380 - 1s - loss: 9.8004e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 267/500\n",
            "380/380 - 1s - loss: 9.7944e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 268/500\n",
            "380/380 - 1s - loss: 9.7885e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 269/500\n",
            "380/380 - 1s - loss: 9.7827e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 270/500\n",
            "380/380 - 1s - loss: 9.7771e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 271/500\n",
            "380/380 - 1s - loss: 9.7715e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 272/500\n",
            "380/380 - 1s - loss: 9.7661e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 273/500\n",
            "380/380 - 1s - loss: 9.7608e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 274/500\n",
            "380/380 - 1s - loss: 9.7556e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 275/500\n",
            "380/380 - 1s - loss: 9.7505e-04 - val_loss: 7.9152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 276/500\n",
            "380/380 - 1s - loss: 9.7455e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 277/500\n",
            "380/380 - 1s - loss: 9.7406e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 278/500\n",
            "380/380 - 1s - loss: 9.7358e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 279/500\n",
            "380/380 - 1s - loss: 9.7311e-04 - val_loss: 7.9153e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 280/500\n",
            "380/380 - 1s - loss: 9.7265e-04 - val_loss: 7.9154e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 281/500\n",
            "380/380 - 1s - loss: 9.7220e-04 - val_loss: 7.9154e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 282/500\n",
            "380/380 - 1s - loss: 9.7176e-04 - val_loss: 7.9155e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 283/500\n",
            "380/380 - 1s - loss: 9.7132e-04 - val_loss: 7.9155e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 284/500\n",
            "380/380 - 1s - loss: 9.7090e-04 - val_loss: 7.9156e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 285/500\n",
            "380/380 - 1s - loss: 9.7048e-04 - val_loss: 7.9157e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 286/500\n",
            "380/380 - 1s - loss: 9.7007e-04 - val_loss: 7.9158e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 287/500\n",
            "380/380 - 1s - loss: 9.6967e-04 - val_loss: 7.9159e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 288/500\n",
            "380/380 - 1s - loss: 9.6927e-04 - val_loss: 7.9160e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 289/500\n",
            "Restoring model weights from the end of the best epoch: 269.\n",
            "380/380 - 1s - loss: 9.6888e-04 - val_loss: 7.9161e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 289: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 4\n",
            "train.shape: (1518, 19) test.shape: (380, 19)\n",
            "train_scaled.shape: (1518, 19) test_scaled.shape: (380, 19)\n",
            "train_X.shape: (1518, 4, 4) train_y.shape: (1518, 3) test_X.shape: (380, 4, 4) test_y.shape: (380, 3)\n",
            "Epoch 1/500\n",
            "380/380 - 4s - loss: 0.1569 - val_loss: 0.1159 - 4s/epoch - 10ms/step\n",
            "Epoch 2/500\n",
            "380/380 - 1s - loss: 0.0659 - val_loss: 0.0546 - 1s/epoch - 3ms/step\n",
            "Epoch 3/500\n",
            "380/380 - 1s - loss: 0.0237 - val_loss: 0.0248 - 1s/epoch - 3ms/step\n",
            "Epoch 4/500\n",
            "380/380 - 1s - loss: 0.0106 - val_loss: 0.0135 - 1s/epoch - 3ms/step\n",
            "Epoch 5/500\n",
            "380/380 - 1s - loss: 0.0077 - val_loss: 0.0093 - 1s/epoch - 3ms/step\n",
            "Epoch 6/500\n",
            "380/380 - 1s - loss: 0.0069 - val_loss: 0.0072 - 1s/epoch - 3ms/step\n",
            "Epoch 7/500\n",
            "380/380 - 1s - loss: 0.0063 - val_loss: 0.0057 - 1s/epoch - 3ms/step\n",
            "Epoch 8/500\n",
            "380/380 - 1s - loss: 0.0058 - val_loss: 0.0045 - 1s/epoch - 3ms/step\n",
            "Epoch 9/500\n",
            "380/380 - 1s - loss: 0.0055 - val_loss: 0.0035 - 1s/epoch - 3ms/step\n",
            "Epoch 10/500\n",
            "380/380 - 1s - loss: 0.0052 - val_loss: 0.0028 - 1s/epoch - 3ms/step\n",
            "Epoch 11/500\n",
            "380/380 - 1s - loss: 0.0049 - val_loss: 0.0022 - 1s/epoch - 3ms/step\n",
            "Epoch 12/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 0.0018 - 1s/epoch - 3ms/step\n",
            "Epoch 13/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 0.0015 - 1s/epoch - 3ms/step\n",
            "Epoch 14/500\n",
            "380/380 - 1s - loss: 0.0045 - val_loss: 0.0012 - 1s/epoch - 3ms/step\n",
            "Epoch 15/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 0.0011 - 1s/epoch - 3ms/step\n",
            "Epoch 16/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 9.2084e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 17/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 8.0930e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 18/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 7.2029e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 19/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 6.4817e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 20/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 5.8894e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 21/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 5.3974e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 22/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 4.9845e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 23/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 4.6352e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 24/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 4.3375e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 25/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 4.0818e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 26/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 3.8610e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 27/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.6690e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 28/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.5012e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 29/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 3.3536e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 30/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 3.2232e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 31/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 3.1074e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 32/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 3.0040e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 33/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.9114e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 34/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.8280e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 35/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.7526e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 36/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.6842e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 37/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.6220e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 38/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.5651e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 39/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.5129e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 40/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.4650e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 41/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.4207e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 42/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.3797e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 43/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.3416e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 44/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.3062e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 45/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.2730e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 46/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.2420e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 47/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.2129e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 48/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.1854e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 49/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.1595e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 50/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.1349e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 51/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.1116e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 52/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.0895e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 53/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.0684e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 54/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.0482e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 55/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.0288e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 56/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.0103e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 57/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 1.9924e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 58/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 1.9752e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 59/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 1.9585e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 60/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 1.9424e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 61/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 1.9267e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 62/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.9114e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 63/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.8964e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 64/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.8818e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 65/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.8675e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 66/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.8533e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 67/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.8393e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 68/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.8255e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 69/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.8117e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 70/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.7980e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 71/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.7843e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 72/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7706e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 73/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7568e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 74/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7429e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 75/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7290e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 76/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7149e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 77/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.7007e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 78/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.6863e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 79/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.6717e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 80/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.6570e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 81/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.6421e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 82/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.6271e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 83/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.6119e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 84/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.5967e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 85/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.5813e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 86/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.5658e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 87/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.5503e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 88/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.5347e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 89/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.5192e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 90/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.5037e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 91/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.4883e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 92/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.4729e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 93/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.4577e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 94/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.4426e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 95/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.4276e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 96/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.4128e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 97/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.3982e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 98/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.3838e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 99/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.3696e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 100/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.3556e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 101/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.3418e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 102/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.3282e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 103/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.3148e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 104/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.3016e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 105/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.2886e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 106/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.2758e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 107/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.2632e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 108/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.2508e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 109/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.2385e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 110/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.2265e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 111/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.2146e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 112/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.2028e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 113/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.1912e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 114/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.1798e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 115/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.1685e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 116/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.1574e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 117/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.1464e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 118/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.1356e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 119/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.1249e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 120/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.1144e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 121/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.1040e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 122/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.0937e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 123/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.0836e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 124/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.0736e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 125/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.0637e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 126/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.0540e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 127/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.0445e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 128/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.0351e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 129/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.0258e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 130/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.0167e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 131/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.0077e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 132/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 9.9894e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 133/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 9.9029e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 134/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 9.8180e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 135/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 9.7347e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 136/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.6530e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 137/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.5729e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 138/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.4945e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 139/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.4178e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 140/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.3427e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 141/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.2693e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 142/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 9.1976e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 143/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.1276e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 144/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 9.0595e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 145/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 8.9930e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 146/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 8.9283e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 147/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 8.8653e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 148/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 8.8041e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 149/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 8.7447e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 150/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.6870e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 151/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.6310e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 152/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.5768e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 153/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.5244e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 154/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.4737e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 155/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.4248e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 156/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.3775e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 157/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.3320e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 158/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.2881e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 159/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 8.2460e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 160/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.2054e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 161/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.1665e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 162/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.1291e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 163/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.0934e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 164/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.0592e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 165/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 8.0265e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 166/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9952e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 167/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9655e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 168/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9372e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 169/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.9102e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 170/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8846e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 171/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8603e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 172/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 7.8373e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 173/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.8155e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 174/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.7949e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 175/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.7754e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 176/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.7571e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 177/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.7398e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 178/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.7236e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 179/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.7083e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 180/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6940e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 181/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6806e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 182/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6681e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 183/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6564e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 184/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6455e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 185/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6353e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 186/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6259e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 187/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6171e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 188/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6090e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 189/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.6015e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 190/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5945e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 191/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5881e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 192/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5822e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 193/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5767e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 194/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5717e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 195/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 7.5672e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 196/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5630e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 197/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5592e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 198/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5557e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 199/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5525e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 200/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5496e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 201/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5470e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 202/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5447e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 203/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5425e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 204/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5406e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 205/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5389e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 206/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5374e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 207/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5360e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 208/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5347e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 209/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5336e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 210/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5327e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 211/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5318e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 212/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5310e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 213/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5303e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 214/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5297e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 215/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5292e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 216/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5287e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 217/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5283e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 218/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5279e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 219/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 7.5276e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 220/500\n",
            "380/380 - 1s - loss: 9.9989e-04 - val_loss: 7.5273e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 221/500\n",
            "380/380 - 1s - loss: 9.9858e-04 - val_loss: 7.5271e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 222/500\n",
            "380/380 - 1s - loss: 9.9732e-04 - val_loss: 7.5269e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 223/500\n",
            "380/380 - 1s - loss: 9.9610e-04 - val_loss: 7.5267e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 224/500\n",
            "380/380 - 1s - loss: 9.9491e-04 - val_loss: 7.5265e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 225/500\n",
            "380/380 - 1s - loss: 9.9375e-04 - val_loss: 7.5263e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 226/500\n",
            "380/380 - 1s - loss: 9.9262e-04 - val_loss: 7.5262e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 227/500\n",
            "380/380 - 1s - loss: 9.9153e-04 - val_loss: 7.5261e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 228/500\n",
            "380/380 - 1s - loss: 9.9047e-04 - val_loss: 7.5259e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 229/500\n",
            "380/380 - 1s - loss: 9.8943e-04 - val_loss: 7.5258e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 230/500\n",
            "380/380 - 1s - loss: 9.8842e-04 - val_loss: 7.5257e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 231/500\n",
            "380/380 - 1s - loss: 9.8744e-04 - val_loss: 7.5256e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 232/500\n",
            "380/380 - 1s - loss: 9.8649e-04 - val_loss: 7.5255e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 233/500\n",
            "380/380 - 1s - loss: 9.8556e-04 - val_loss: 7.5254e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 234/500\n",
            "380/380 - 1s - loss: 9.8466e-04 - val_loss: 7.5253e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 235/500\n",
            "380/380 - 1s - loss: 9.8378e-04 - val_loss: 7.5252e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 236/500\n",
            "380/380 - 1s - loss: 9.8292e-04 - val_loss: 7.5251e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 237/500\n",
            "380/380 - 1s - loss: 9.8208e-04 - val_loss: 7.5251e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 238/500\n",
            "380/380 - 1s - loss: 9.8127e-04 - val_loss: 7.5250e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 239/500\n",
            "380/380 - 1s - loss: 9.8048e-04 - val_loss: 7.5249e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 240/500\n",
            "380/380 - 1s - loss: 9.7970e-04 - val_loss: 7.5248e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 241/500\n",
            "380/380 - 1s - loss: 9.7894e-04 - val_loss: 7.5248e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 242/500\n",
            "380/380 - 1s - loss: 9.7821e-04 - val_loss: 7.5247e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 243/500\n",
            "380/380 - 1s - loss: 9.7749e-04 - val_loss: 7.5246e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 244/500\n",
            "380/380 - 1s - loss: 9.7678e-04 - val_loss: 7.5246e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 245/500\n",
            "380/380 - 1s - loss: 9.7610e-04 - val_loss: 7.5245e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 246/500\n",
            "380/380 - 1s - loss: 9.7543e-04 - val_loss: 7.5245e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 247/500\n",
            "380/380 - 1s - loss: 9.7477e-04 - val_loss: 7.5244e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 248/500\n",
            "380/380 - 1s - loss: 9.7413e-04 - val_loss: 7.5244e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 249/500\n",
            "380/380 - 1s - loss: 9.7350e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 250/500\n",
            "380/380 - 1s - loss: 9.7289e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 251/500\n",
            "380/380 - 1s - loss: 9.7229e-04 - val_loss: 7.5243e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 252/500\n",
            "380/380 - 1s - loss: 9.7171e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 253/500\n",
            "380/380 - 1s - loss: 9.7114e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 254/500\n",
            "380/380 - 1s - loss: 9.7057e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 255/500\n",
            "380/380 - 1s - loss: 9.7002e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 256/500\n",
            "380/380 - 1s - loss: 9.6949e-04 - val_loss: 7.5243e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 257/500\n",
            "380/380 - 1s - loss: 9.6896e-04 - val_loss: 7.5244e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 258/500\n",
            "380/380 - 1s - loss: 9.6845e-04 - val_loss: 7.5244e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 259/500\n",
            "380/380 - 1s - loss: 9.6794e-04 - val_loss: 7.5245e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 260/500\n",
            "380/380 - 1s - loss: 9.6744e-04 - val_loss: 7.5246e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 261/500\n",
            "380/380 - 1s - loss: 9.6696e-04 - val_loss: 7.5247e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 262/500\n",
            "380/380 - 1s - loss: 9.6648e-04 - val_loss: 7.5248e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 263/500\n",
            "380/380 - 1s - loss: 9.6602e-04 - val_loss: 7.5249e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 264/500\n",
            "380/380 - 1s - loss: 9.6556e-04 - val_loss: 7.5250e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 265/500\n",
            "380/380 - 1s - loss: 9.6511e-04 - val_loss: 7.5252e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 266/500\n",
            "380/380 - 1s - loss: 9.6467e-04 - val_loss: 7.5254e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 267/500\n",
            "380/380 - 1s - loss: 9.6423e-04 - val_loss: 7.5256e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 268/500\n",
            "380/380 - 1s - loss: 9.6381e-04 - val_loss: 7.5258e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 269/500\n",
            "380/380 - 1s - loss: 9.6339e-04 - val_loss: 7.5260e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 270/500\n",
            "380/380 - 1s - loss: 9.6298e-04 - val_loss: 7.5262e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 271/500\n",
            "380/380 - 1s - loss: 9.6258e-04 - val_loss: 7.5265e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 272/500\n",
            "Restoring model weights from the end of the best epoch: 252.\n",
            "380/380 - 1s - loss: 9.6218e-04 - val_loss: 7.5268e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 272: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 5\n",
            "train.shape: (1517, 23) test.shape: (380, 23)\n",
            "train_scaled.shape: (1517, 23) test_scaled.shape: (380, 23)\n",
            "train_X.shape: (1517, 5, 4) train_y.shape: (1517, 3) test_X.shape: (380, 5, 4) test_y.shape: (380, 3)\n",
            "Epoch 1/500\n",
            "380/380 - 4s - loss: 0.3646 - val_loss: 0.2211 - 4s/epoch - 10ms/step\n",
            "Epoch 2/500\n",
            "380/380 - 1s - loss: 0.2035 - val_loss: 0.1219 - 1s/epoch - 4ms/step\n",
            "Epoch 3/500\n",
            "380/380 - 1s - loss: 0.0977 - val_loss: 0.0579 - 1s/epoch - 4ms/step\n",
            "Epoch 4/500\n",
            "380/380 - 1s - loss: 0.0393 - val_loss: 0.0232 - 1s/epoch - 4ms/step\n",
            "Epoch 5/500\n",
            "380/380 - 1s - loss: 0.0158 - val_loss: 0.0095 - 1s/epoch - 4ms/step\n",
            "Epoch 6/500\n",
            "380/380 - 1s - loss: 0.0091 - val_loss: 0.0047 - 1s/epoch - 3ms/step\n",
            "Epoch 7/500\n",
            "380/380 - 1s - loss: 0.0071 - val_loss: 0.0027 - 1s/epoch - 4ms/step\n",
            "Epoch 8/500\n",
            "380/380 - 1s - loss: 0.0062 - val_loss: 0.0018 - 1s/epoch - 4ms/step\n",
            "Epoch 9/500\n",
            "380/380 - 1s - loss: 0.0059 - val_loss: 0.0012 - 1s/epoch - 4ms/step\n",
            "Epoch 10/500\n",
            "380/380 - 1s - loss: 0.0056 - val_loss: 8.9334e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 11/500\n",
            "380/380 - 1s - loss: 0.0055 - val_loss: 6.9701e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 12/500\n",
            "380/380 - 1s - loss: 0.0053 - val_loss: 5.8389e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 13/500\n",
            "380/380 - 1s - loss: 0.0052 - val_loss: 5.2371e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 14/500\n",
            "380/380 - 1s - loss: 0.0052 - val_loss: 4.9547e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 15/500\n",
            "380/380 - 2s - loss: 0.0051 - val_loss: 4.8455e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 16/500\n",
            "380/380 - 1s - loss: 0.0050 - val_loss: 4.8130e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 17/500\n",
            "380/380 - 1s - loss: 0.0050 - val_loss: 4.8001e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 18/500\n",
            "380/380 - 1s - loss: 0.0050 - val_loss: 4.7790e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 19/500\n",
            "380/380 - 1s - loss: 0.0049 - val_loss: 4.7400e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 20/500\n",
            "380/380 - 1s - loss: 0.0049 - val_loss: 4.6837e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 21/500\n",
            "380/380 - 1s - loss: 0.0048 - val_loss: 4.6143e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 22/500\n",
            "380/380 - 1s - loss: 0.0048 - val_loss: 4.5369e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 23/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 4.4555e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 24/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 4.3734e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 25/500\n",
            "380/380 - 1s - loss: 0.0047 - val_loss: 4.2925e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 26/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 4.2143e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 27/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 4.1393e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 28/500\n",
            "380/380 - 1s - loss: 0.0046 - val_loss: 4.0680e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 29/500\n",
            "380/380 - 2s - loss: 0.0045 - val_loss: 4.0002e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 30/500\n",
            "380/380 - 1s - loss: 0.0045 - val_loss: 3.9360e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 31/500\n",
            "380/380 - 2s - loss: 0.0045 - val_loss: 3.8750e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 32/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 3.8169e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 33/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 3.7617e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 34/500\n",
            "380/380 - 1s - loss: 0.0044 - val_loss: 3.7089e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 35/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 3.6583e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 36/500\n",
            "380/380 - 2s - loss: 0.0043 - val_loss: 3.6099e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 37/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 3.5633e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 38/500\n",
            "380/380 - 1s - loss: 0.0043 - val_loss: 3.5183e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 39/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.4750e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 40/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.4331e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 41/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.3924e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 42/500\n",
            "380/380 - 1s - loss: 0.0042 - val_loss: 3.3530e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 43/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.3146e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 44/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.2772e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 45/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.2406e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 46/500\n",
            "380/380 - 1s - loss: 0.0041 - val_loss: 3.2048e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 47/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.1698e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 48/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.1353e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 49/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.1014e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 50/500\n",
            "380/380 - 1s - loss: 0.0040 - val_loss: 3.0679e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 51/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 3.0348e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 52/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 3.0020e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 53/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 2.9695e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 54/500\n",
            "380/380 - 1s - loss: 0.0039 - val_loss: 2.9372e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 55/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 2.9051e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 56/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 2.8730e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 57/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 2.8411e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 58/500\n",
            "380/380 - 1s - loss: 0.0038 - val_loss: 2.8091e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 59/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.7771e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 60/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.7451e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 61/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.7129e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 62/500\n",
            "380/380 - 1s - loss: 0.0037 - val_loss: 2.6807e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 63/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.6484e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 64/500\n",
            "380/380 - 2s - loss: 0.0036 - val_loss: 2.6159e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 65/500\n",
            "380/380 - 1s - loss: 0.0036 - val_loss: 2.5833e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 66/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.5505e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 67/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.5176e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 68/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.4845e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 69/500\n",
            "380/380 - 1s - loss: 0.0035 - val_loss: 2.4513e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 70/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.4180e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 71/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.3846e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 72/500\n",
            "380/380 - 1s - loss: 0.0034 - val_loss: 2.3511e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 73/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.3175e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 74/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.2840e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 75/500\n",
            "380/380 - 1s - loss: 0.0033 - val_loss: 2.2505e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 76/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.2171e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 77/500\n",
            "380/380 - 2s - loss: 0.0032 - val_loss: 2.1838e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 78/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.1507e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 79/500\n",
            "380/380 - 1s - loss: 0.0032 - val_loss: 2.1179e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 80/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.0854e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 81/500\n",
            "380/380 - 1s - loss: 0.0031 - val_loss: 2.0532e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 82/500\n",
            "380/380 - 2s - loss: 0.0031 - val_loss: 2.0216e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 83/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.9904e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 84/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.9598e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 85/500\n",
            "380/380 - 1s - loss: 0.0030 - val_loss: 1.9299e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 86/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.9008e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 87/500\n",
            "380/380 - 2s - loss: 0.0029 - val_loss: 1.8725e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 88/500\n",
            "380/380 - 1s - loss: 0.0029 - val_loss: 1.8450e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 89/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.8186e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 90/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7931e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 91/500\n",
            "380/380 - 1s - loss: 0.0028 - val_loss: 1.7688e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 92/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.7456e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 93/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.7236e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 94/500\n",
            "380/380 - 1s - loss: 0.0027 - val_loss: 1.7028e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 95/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.6832e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 96/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.6649e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 97/500\n",
            "380/380 - 1s - loss: 0.0026 - val_loss: 1.6479e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 98/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.6322e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 99/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.6177e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 100/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.6045e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 101/500\n",
            "380/380 - 1s - loss: 0.0025 - val_loss: 1.5925e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 102/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.5816e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 103/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.5719e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 104/500\n",
            "380/380 - 1s - loss: 0.0024 - val_loss: 1.5632e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 105/500\n",
            "380/380 - 2s - loss: 0.0024 - val_loss: 1.5555e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 106/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.5487e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 107/500\n",
            "380/380 - 2s - loss: 0.0023 - val_loss: 1.5428e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 108/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.5376e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 109/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.5331e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 110/500\n",
            "380/380 - 1s - loss: 0.0023 - val_loss: 1.5292e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 111/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.5258e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 112/500\n",
            "380/380 - 2s - loss: 0.0022 - val_loss: 1.5229e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 113/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.5203e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 114/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.5181e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 115/500\n",
            "380/380 - 1s - loss: 0.0022 - val_loss: 1.5161e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 116/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5142e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 117/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5125e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 118/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5109e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 119/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5092e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 120/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5076e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 121/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5059e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 122/500\n",
            "380/380 - 1s - loss: 0.0021 - val_loss: 1.5042e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 123/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.5023e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 124/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.5003e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 125/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.4982e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 126/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.4959e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 127/500\n",
            "380/380 - 1s - loss: 0.0020 - val_loss: 1.4935e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 128/500\n",
            "380/380 - 2s - loss: 0.0020 - val_loss: 1.4909e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 129/500\n",
            "380/380 - 2s - loss: 0.0020 - val_loss: 1.4881e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 130/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4851e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 131/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4820e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 132/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4786e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 133/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4752e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 134/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4715e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 135/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4676e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 136/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4636e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 137/500\n",
            "380/380 - 1s - loss: 0.0019 - val_loss: 1.4594e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 138/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4551e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 139/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4506e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 140/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4459e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 141/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4412e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 142/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4363e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 143/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4313e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 144/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4261e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 145/500\n",
            "380/380 - 1s - loss: 0.0018 - val_loss: 1.4209e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 146/500\n",
            "380/380 - 2s - loss: 0.0018 - val_loss: 1.4156e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 147/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.4101e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 148/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.4046e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 149/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3990e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 150/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3934e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 151/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3877e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 152/500\n",
            "380/380 - 2s - loss: 0.0017 - val_loss: 1.3819e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 153/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3761e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 154/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3702e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 155/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3643e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 156/500\n",
            "380/380 - 1s - loss: 0.0017 - val_loss: 1.3583e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 157/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3523e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 158/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3464e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 159/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3403e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 160/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3343e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 161/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3283e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 162/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3222e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 163/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3162e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 164/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3101e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 165/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.3041e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 166/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.2981e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 167/500\n",
            "380/380 - 1s - loss: 0.0016 - val_loss: 1.2921e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 168/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2861e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 169/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2802e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 170/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2742e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 171/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2683e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 172/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2624e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 173/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2566e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 174/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2508e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 175/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2450e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 176/500\n",
            "380/380 - 2s - loss: 0.0015 - val_loss: 1.2393e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 177/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2336e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 178/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2280e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 179/500\n",
            "380/380 - 1s - loss: 0.0015 - val_loss: 1.2224e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 180/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.2168e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 181/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.2113e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 182/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.2059e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 183/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.2005e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 184/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1952e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 185/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1899e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 186/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1847e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 187/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1795e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 188/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1744e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 189/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1694e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 190/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1644e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 191/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1595e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 192/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1547e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 193/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1499e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 194/500\n",
            "380/380 - 1s - loss: 0.0014 - val_loss: 1.1452e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 195/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1406e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 196/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1360e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 197/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1315e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 198/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1271e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 199/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1227e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 200/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1184e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 201/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1142e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 202/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1100e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 203/500\n",
            "380/380 - 2s - loss: 0.0013 - val_loss: 1.1059e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 204/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.1019e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 205/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0980e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 206/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0941e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 207/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0903e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 208/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0865e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 209/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0829e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 210/500\n",
            "380/380 - 2s - loss: 0.0013 - val_loss: 1.0793e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 211/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0757e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 212/500\n",
            "380/380 - 1s - loss: 0.0013 - val_loss: 1.0723e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 213/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0688e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 214/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0655e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 215/500\n",
            "380/380 - 2s - loss: 0.0012 - val_loss: 1.0622e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 216/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0590e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 217/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0559e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 218/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0528e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 219/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0498e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 220/500\n",
            "380/380 - 2s - loss: 0.0012 - val_loss: 1.0468e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 221/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0439e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 222/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0411e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 223/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0384e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 224/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0357e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 225/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0330e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 226/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0304e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 227/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0279e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 228/500\n",
            "380/380 - 2s - loss: 0.0012 - val_loss: 1.0254e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 229/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0230e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 230/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0206e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 231/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0183e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 232/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0161e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 233/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0139e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 234/500\n",
            "380/380 - 2s - loss: 0.0012 - val_loss: 1.0117e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 235/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0096e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 236/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0076e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 237/500\n",
            "380/380 - 1s - loss: 0.0012 - val_loss: 1.0056e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 238/500\n",
            "380/380 - 2s - loss: 0.0011 - val_loss: 1.0036e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 239/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 1.0017e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 240/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.9986e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 241/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.9805e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 242/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.9629e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 243/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.9458e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 244/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.9291e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 245/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.9127e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 246/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.8969e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 247/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.8815e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 248/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.8664e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 249/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.8518e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 250/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.8376e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 251/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.8237e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 252/500\n",
            "380/380 - 2s - loss: 0.0011 - val_loss: 9.8102e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 253/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7971e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 254/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7844e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 255/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7721e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 256/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7600e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 257/500\n",
            "380/380 - 2s - loss: 0.0011 - val_loss: 9.7484e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 258/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7370e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 259/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7260e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 260/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7153e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 261/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.7049e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 262/500\n",
            "380/380 - 2s - loss: 0.0011 - val_loss: 9.6948e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 263/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6851e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 264/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6756e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 265/500\n",
            "380/380 - 2s - loss: 0.0011 - val_loss: 9.6664e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 266/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6576e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 267/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6490e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 268/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6406e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 269/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6325e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 270/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6248e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 271/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6172e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 272/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6099e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 273/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.6028e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 274/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.5960e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 275/500\n",
            "380/380 - 2s - loss: 0.0011 - val_loss: 9.5893e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 276/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.5830e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 277/500\n",
            "380/380 - 1s - loss: 0.0011 - val_loss: 9.5768e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 278/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5709e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 279/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5651e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 280/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5595e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 281/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5543e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 282/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5491e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 283/500\n",
            "380/380 - 2s - loss: 0.0010 - val_loss: 9.5442e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 284/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5394e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 285/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5348e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 286/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5304e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 287/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5262e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 288/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5221e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 289/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5182e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 290/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5144e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 291/500\n",
            "380/380 - 2s - loss: 0.0010 - val_loss: 9.5108e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 292/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5073e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 293/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5040e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 294/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.5008e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 295/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4978e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 296/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4949e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 297/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4921e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 298/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4895e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 299/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4870e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 300/500\n",
            "380/380 - 2s - loss: 0.0010 - val_loss: 9.4846e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 301/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4822e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 302/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4801e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 303/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4780e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 304/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4760e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 305/500\n",
            "380/380 - 2s - loss: 0.0010 - val_loss: 9.4741e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 306/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4724e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 307/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4707e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 308/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4691e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 309/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4675e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 310/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4661e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 311/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4648e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 312/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4636e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 313/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4624e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 314/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4612e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 315/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4602e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 316/500\n",
            "380/380 - 1s - loss: 0.0010 - val_loss: 9.4593e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 317/500\n",
            "380/380 - 1s - loss: 9.9978e-04 - val_loss: 9.4584e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 318/500\n",
            "380/380 - 1s - loss: 9.9891e-04 - val_loss: 9.4575e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 319/500\n",
            "380/380 - 1s - loss: 9.9806e-04 - val_loss: 9.4568e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 320/500\n",
            "380/380 - 1s - loss: 9.9723e-04 - val_loss: 9.4560e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 321/500\n",
            "380/380 - 1s - loss: 9.9641e-04 - val_loss: 9.4553e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 322/500\n",
            "380/380 - 1s - loss: 9.9560e-04 - val_loss: 9.4547e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 323/500\n",
            "380/380 - 1s - loss: 9.9481e-04 - val_loss: 9.4542e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 324/500\n",
            "380/380 - 1s - loss: 9.9403e-04 - val_loss: 9.4537e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 325/500\n",
            "380/380 - 1s - loss: 9.9326e-04 - val_loss: 9.4533e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 326/500\n",
            "380/380 - 1s - loss: 9.9251e-04 - val_loss: 9.4529e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 327/500\n",
            "380/380 - 1s - loss: 9.9177e-04 - val_loss: 9.4525e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 328/500\n",
            "380/380 - 2s - loss: 9.9105e-04 - val_loss: 9.4522e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 329/500\n",
            "380/380 - 1s - loss: 9.9033e-04 - val_loss: 9.4519e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 330/500\n",
            "380/380 - 1s - loss: 9.8963e-04 - val_loss: 9.4517e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 331/500\n",
            "380/380 - 1s - loss: 9.8894e-04 - val_loss: 9.4515e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 332/500\n",
            "380/380 - 1s - loss: 9.8827e-04 - val_loss: 9.4513e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 333/500\n",
            "380/380 - 1s - loss: 9.8760e-04 - val_loss: 9.4512e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 334/500\n",
            "380/380 - 1s - loss: 9.8695e-04 - val_loss: 9.4511e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 335/500\n",
            "380/380 - 1s - loss: 9.8630e-04 - val_loss: 9.4510e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 336/500\n",
            "380/380 - 2s - loss: 9.8567e-04 - val_loss: 9.4510e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 337/500\n",
            "380/380 - 1s - loss: 9.8505e-04 - val_loss: 9.4510e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 338/500\n",
            "380/380 - 1s - loss: 9.8443e-04 - val_loss: 9.4510e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 339/500\n",
            "380/380 - 1s - loss: 9.8383e-04 - val_loss: 9.4510e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 340/500\n",
            "380/380 - 1s - loss: 9.8324e-04 - val_loss: 9.4511e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 341/500\n",
            "380/380 - 1s - loss: 9.8266e-04 - val_loss: 9.4512e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 342/500\n",
            "380/380 - 1s - loss: 9.8208e-04 - val_loss: 9.4513e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 343/500\n",
            "380/380 - 1s - loss: 9.8152e-04 - val_loss: 9.4514e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 344/500\n",
            "380/380 - 1s - loss: 9.8097e-04 - val_loss: 9.4515e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 345/500\n",
            "380/380 - 1s - loss: 9.8042e-04 - val_loss: 9.4518e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 346/500\n",
            "380/380 - 1s - loss: 9.7989e-04 - val_loss: 9.4519e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 347/500\n",
            "380/380 - 1s - loss: 9.7936e-04 - val_loss: 9.4521e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 348/500\n",
            "380/380 - 1s - loss: 9.7884e-04 - val_loss: 9.4524e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 349/500\n",
            "380/380 - 1s - loss: 9.7833e-04 - val_loss: 9.4526e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 350/500\n",
            "380/380 - 1s - loss: 9.7782e-04 - val_loss: 9.4528e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 351/500\n",
            "380/380 - 1s - loss: 9.7733e-04 - val_loss: 9.4531e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 352/500\n",
            "380/380 - 1s - loss: 9.7684e-04 - val_loss: 9.4533e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 353/500\n",
            "380/380 - 1s - loss: 9.7636e-04 - val_loss: 9.4536e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 354/500\n",
            "380/380 - 1s - loss: 9.7589e-04 - val_loss: 9.4539e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 355/500\n",
            "380/380 - 1s - loss: 9.7542e-04 - val_loss: 9.4542e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 356/500\n",
            "Restoring model weights from the end of the best epoch: 336.\n",
            "380/380 - 1s - loss: 9.7496e-04 - val_loss: 9.4544e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 356: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 6\n",
            "train.shape: (1516, 27) test.shape: (380, 27)\n",
            "train_scaled.shape: (1516, 27) test_scaled.shape: (380, 27)\n",
            "train_X.shape: (1516, 6, 4) train_y.shape: (1516, 3) test_X.shape: (380, 6, 4) test_y.shape: (380, 3)\n",
            "Epoch 1/500\n",
            "379/379 - 3s - loss: 0.2789 - val_loss: 0.2441 - 3s/epoch - 9ms/step\n",
            "Epoch 2/500\n",
            "379/379 - 1s - loss: 0.2116 - val_loss: 0.1870 - 1s/epoch - 3ms/step\n",
            "Epoch 3/500\n",
            "379/379 - 1s - loss: 0.1546 - val_loss: 0.1404 - 1s/epoch - 3ms/step\n",
            "Epoch 4/500\n",
            "379/379 - 1s - loss: 0.1050 - val_loss: 0.0994 - 1s/epoch - 3ms/step\n",
            "Epoch 5/500\n",
            "379/379 - 1s - loss: 0.0648 - val_loss: 0.0644 - 1s/epoch - 3ms/step\n",
            "Epoch 6/500\n",
            "379/379 - 1s - loss: 0.0370 - val_loss: 0.0386 - 1s/epoch - 3ms/step\n",
            "Epoch 7/500\n",
            "379/379 - 1s - loss: 0.0207 - val_loss: 0.0220 - 1s/epoch - 3ms/step\n",
            "Epoch 8/500\n",
            "379/379 - 1s - loss: 0.0125 - val_loss: 0.0125 - 1s/epoch - 3ms/step\n",
            "Epoch 9/500\n",
            "379/379 - 1s - loss: 0.0089 - val_loss: 0.0075 - 1s/epoch - 3ms/step\n",
            "Epoch 10/500\n",
            "379/379 - 1s - loss: 0.0075 - val_loss: 0.0049 - 1s/epoch - 3ms/step\n",
            "Epoch 11/500\n",
            "379/379 - 1s - loss: 0.0069 - val_loss: 0.0035 - 1s/epoch - 3ms/step\n",
            "Epoch 12/500\n",
            "379/379 - 1s - loss: 0.0065 - val_loss: 0.0027 - 1s/epoch - 3ms/step\n",
            "Epoch 13/500\n",
            "379/379 - 1s - loss: 0.0063 - val_loss: 0.0021 - 1s/epoch - 3ms/step\n",
            "Epoch 14/500\n",
            "379/379 - 1s - loss: 0.0060 - val_loss: 0.0017 - 1s/epoch - 3ms/step\n",
            "Epoch 15/500\n",
            "379/379 - 1s - loss: 0.0059 - val_loss: 0.0014 - 1s/epoch - 3ms/step\n",
            "Epoch 16/500\n",
            "379/379 - 1s - loss: 0.0057 - val_loss: 0.0011 - 1s/epoch - 3ms/step\n",
            "Epoch 17/500\n",
            "379/379 - 1s - loss: 0.0056 - val_loss: 9.4283e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 18/500\n",
            "379/379 - 1s - loss: 0.0055 - val_loss: 7.9055e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 19/500\n",
            "379/379 - 1s - loss: 0.0053 - val_loss: 6.7180e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 20/500\n",
            "379/379 - 1s - loss: 0.0052 - val_loss: 5.7991e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 21/500\n",
            "379/379 - 1s - loss: 0.0052 - val_loss: 5.0969e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 22/500\n",
            "379/379 - 1s - loss: 0.0051 - val_loss: 4.5705e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 23/500\n",
            "379/379 - 1s - loss: 0.0050 - val_loss: 4.1859e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 24/500\n",
            "379/379 - 1s - loss: 0.0049 - val_loss: 3.9140e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 25/500\n",
            "379/379 - 1s - loss: 0.0049 - val_loss: 3.7289e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 26/500\n",
            "379/379 - 1s - loss: 0.0048 - val_loss: 3.6077e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 27/500\n",
            "379/379 - 1s - loss: 0.0048 - val_loss: 3.5309e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 28/500\n",
            "379/379 - 1s - loss: 0.0047 - val_loss: 3.4831e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 29/500\n",
            "379/379 - 1s - loss: 0.0047 - val_loss: 3.4529e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 30/500\n",
            "379/379 - 1s - loss: 0.0046 - val_loss: 3.4326e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 31/500\n",
            "379/379 - 1s - loss: 0.0046 - val_loss: 3.4176e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 32/500\n",
            "379/379 - 1s - loss: 0.0045 - val_loss: 3.4052e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 33/500\n",
            "379/379 - 1s - loss: 0.0045 - val_loss: 3.3940e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 34/500\n",
            "379/379 - 1s - loss: 0.0045 - val_loss: 3.3835e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 35/500\n",
            "379/379 - 1s - loss: 0.0044 - val_loss: 3.3736e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 36/500\n",
            "379/379 - 1s - loss: 0.0044 - val_loss: 3.3640e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 37/500\n",
            "379/379 - 1s - loss: 0.0043 - val_loss: 3.3549e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 38/500\n",
            "379/379 - 1s - loss: 0.0043 - val_loss: 3.3461e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 39/500\n",
            "379/379 - 1s - loss: 0.0043 - val_loss: 3.3374e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 40/500\n",
            "379/379 - 1s - loss: 0.0042 - val_loss: 3.3289e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 41/500\n",
            "379/379 - 1s - loss: 0.0042 - val_loss: 3.3203e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 42/500\n",
            "379/379 - 1s - loss: 0.0042 - val_loss: 3.3114e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 43/500\n",
            "379/379 - 1s - loss: 0.0041 - val_loss: 3.3019e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 44/500\n",
            "379/379 - 1s - loss: 0.0041 - val_loss: 3.2916e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 45/500\n",
            "379/379 - 1s - loss: 0.0041 - val_loss: 3.2802e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 46/500\n",
            "379/379 - 1s - loss: 0.0040 - val_loss: 3.2675e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 47/500\n",
            "379/379 - 1s - loss: 0.0040 - val_loss: 3.2534e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 48/500\n",
            "379/379 - 1s - loss: 0.0040 - val_loss: 3.2375e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 49/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 3.2197e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 50/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 3.1998e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 51/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 3.1778e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 52/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 3.1535e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 53/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 3.1269e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 54/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 3.0980e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 55/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 3.0669e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 56/500\n",
            "379/379 - 1s - loss: 0.0037 - val_loss: 3.0336e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 57/500\n",
            "379/379 - 1s - loss: 0.0037 - val_loss: 2.9985e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 58/500\n",
            "379/379 - 1s - loss: 0.0037 - val_loss: 2.9615e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 59/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.9231e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 60/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.8835e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 61/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.8429e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 62/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.8017e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 63/500\n",
            "379/379 - 1s - loss: 0.0035 - val_loss: 2.7602e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 64/500\n",
            "379/379 - 1s - loss: 0.0035 - val_loss: 2.7187e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 65/500\n",
            "379/379 - 1s - loss: 0.0035 - val_loss: 2.6775e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 66/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.6370e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 67/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.5973e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 68/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.5587e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 69/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.5213e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 70/500\n",
            "379/379 - 1s - loss: 0.0033 - val_loss: 2.4855e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 71/500\n",
            "379/379 - 1s - loss: 0.0033 - val_loss: 2.4512e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 72/500\n",
            "379/379 - 1s - loss: 0.0033 - val_loss: 2.4186e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 73/500\n",
            "379/379 - 1s - loss: 0.0033 - val_loss: 2.3876e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 74/500\n",
            "379/379 - 1s - loss: 0.0032 - val_loss: 2.3584e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 75/500\n",
            "379/379 - 1s - loss: 0.0032 - val_loss: 2.3309e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 76/500\n",
            "379/379 - 1s - loss: 0.0032 - val_loss: 2.3051e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 77/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 2.2808e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 78/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 2.2581e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 79/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 2.2367e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 80/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 2.2167e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 81/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 2.1980e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 82/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 2.1803e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 83/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 2.1636e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 84/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 2.1478e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 85/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 2.1327e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 86/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 2.1183e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 87/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 2.1045e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 88/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 2.0912e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 89/500\n",
            "379/379 - 1s - loss: 0.0028 - val_loss: 2.0782e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 90/500\n",
            "379/379 - 1s - loss: 0.0028 - val_loss: 2.0656e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 91/500\n",
            "379/379 - 1s - loss: 0.0028 - val_loss: 2.0533e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 92/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 2.0412e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 93/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 2.0292e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 94/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 2.0173e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 95/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 2.0054e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 96/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.9936e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 97/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.9817e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 98/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.9698e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 99/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.9578e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 100/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.9457e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 101/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.9335e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 102/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.9212e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 103/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.9088e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 104/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.8961e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 105/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.8834e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 106/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.8704e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 107/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.8574e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 108/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.8441e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 109/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.8307e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 110/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.8171e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 111/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.8033e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 112/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.7893e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 113/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.7752e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 114/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.7610e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 115/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.7465e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 116/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.7320e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 117/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.7172e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 118/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.7024e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 119/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.6873e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 120/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.6722e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 121/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.6570e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 122/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.6416e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 123/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.6261e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 124/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.6106e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 125/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.5949e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 126/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.5792e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 127/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.5635e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 128/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.5476e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 129/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.5318e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 130/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.5159e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 131/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.5000e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 132/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.4841e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 133/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.4682e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 134/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.4523e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 135/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.4365e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 136/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.4207e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 137/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.4049e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 138/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.3892e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 139/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.3737e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 140/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 1.3582e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 141/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 1.3427e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 142/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 1.3274e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 143/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 1.3123e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 144/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 1.2972e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 145/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 1.2823e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 146/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 1.2676e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 147/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 1.2530e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 148/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 1.2386e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 149/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 1.2244e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 150/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 1.2104e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 151/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1966e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 152/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1829e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 153/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1695e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 154/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1563e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 155/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1434e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 156/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1307e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 157/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 1.1182e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 158/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.1060e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 159/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0940e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 160/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0823e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 161/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0708e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 162/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0596e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 163/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0487e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 164/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0380e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 165/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 1.0277e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 166/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 1.0176e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 167/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 1.0078e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 168/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.9824e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 169/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.8898e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 170/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.8001e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 171/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.7131e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 172/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.6290e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 173/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.5477e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 174/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.4691e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 175/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.3933e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 176/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 9.3202e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 177/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 9.2498e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 178/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 9.1820e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 179/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 9.1169e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 180/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 9.0542e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 181/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.9941e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 182/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.9365e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 183/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.8814e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 184/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.8285e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 185/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.7779e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 186/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.7297e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 187/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.6834e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 188/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.6394e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 189/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.5974e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 190/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.5573e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 191/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.5192e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 192/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.4827e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 193/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 8.4482e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 194/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.4152e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 195/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.3839e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 196/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.3540e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 197/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.3258e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 198/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.2989e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 199/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.2732e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 200/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.2489e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 201/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.2258e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 202/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.2037e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 203/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.1829e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 204/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.1630e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 205/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.1441e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 206/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.1261e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 207/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.1090e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 208/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.0927e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 209/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 8.0773e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 210/500\n",
            "379/379 - 1s - loss: 9.9935e-04 - val_loss: 8.0624e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 211/500\n",
            "379/379 - 1s - loss: 9.9725e-04 - val_loss: 8.0484e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 212/500\n",
            "379/379 - 1s - loss: 9.9524e-04 - val_loss: 8.0349e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 213/500\n",
            "379/379 - 1s - loss: 9.9330e-04 - val_loss: 8.0221e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 214/500\n",
            "379/379 - 1s - loss: 9.9143e-04 - val_loss: 8.0098e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 215/500\n",
            "379/379 - 1s - loss: 9.8964e-04 - val_loss: 7.9981e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 216/500\n",
            "379/379 - 1s - loss: 9.8791e-04 - val_loss: 7.9869e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 217/500\n",
            "379/379 - 1s - loss: 9.8624e-04 - val_loss: 7.9762e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 218/500\n",
            "379/379 - 1s - loss: 9.8464e-04 - val_loss: 7.9660e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 219/500\n",
            "379/379 - 1s - loss: 9.8310e-04 - val_loss: 7.9561e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 220/500\n",
            "379/379 - 1s - loss: 9.8161e-04 - val_loss: 7.9467e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 221/500\n",
            "379/379 - 1s - loss: 9.8017e-04 - val_loss: 7.9376e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 222/500\n",
            "379/379 - 1s - loss: 9.7878e-04 - val_loss: 7.9290e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 223/500\n",
            "379/379 - 1s - loss: 9.7744e-04 - val_loss: 7.9206e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 224/500\n",
            "379/379 - 1s - loss: 9.7615e-04 - val_loss: 7.9127e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 225/500\n",
            "379/379 - 1s - loss: 9.7490e-04 - val_loss: 7.9049e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 226/500\n",
            "379/379 - 1s - loss: 9.7369e-04 - val_loss: 7.8975e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 227/500\n",
            "379/379 - 1s - loss: 9.7253e-04 - val_loss: 7.8904e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 228/500\n",
            "379/379 - 1s - loss: 9.7140e-04 - val_loss: 7.8835e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 229/500\n",
            "379/379 - 1s - loss: 9.7030e-04 - val_loss: 7.8769e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 230/500\n",
            "379/379 - 1s - loss: 9.6925e-04 - val_loss: 7.8705e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 231/500\n",
            "379/379 - 1s - loss: 9.6822e-04 - val_loss: 7.8643e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 232/500\n",
            "379/379 - 1s - loss: 9.6723e-04 - val_loss: 7.8583e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 233/500\n",
            "379/379 - 1s - loss: 9.6627e-04 - val_loss: 7.8526e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 234/500\n",
            "379/379 - 1s - loss: 9.6534e-04 - val_loss: 7.8471e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 235/500\n",
            "379/379 - 1s - loss: 9.6444e-04 - val_loss: 7.8417e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 236/500\n",
            "379/379 - 1s - loss: 9.6356e-04 - val_loss: 7.8365e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 237/500\n",
            "379/379 - 1s - loss: 9.6271e-04 - val_loss: 7.8315e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 238/500\n",
            "379/379 - 1s - loss: 9.6188e-04 - val_loss: 7.8266e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 239/500\n",
            "379/379 - 1s - loss: 9.6108e-04 - val_loss: 7.8219e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 240/500\n",
            "379/379 - 1s - loss: 9.6030e-04 - val_loss: 7.8174e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 241/500\n",
            "379/379 - 1s - loss: 9.5954e-04 - val_loss: 7.8130e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 242/500\n",
            "379/379 - 1s - loss: 9.5881e-04 - val_loss: 7.8087e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 243/500\n",
            "379/379 - 1s - loss: 9.5809e-04 - val_loss: 7.8046e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 244/500\n",
            "379/379 - 1s - loss: 9.5739e-04 - val_loss: 7.8006e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 245/500\n",
            "379/379 - 1s - loss: 9.5671e-04 - val_loss: 7.7967e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 246/500\n",
            "379/379 - 1s - loss: 9.5605e-04 - val_loss: 7.7930e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 247/500\n",
            "379/379 - 1s - loss: 9.5541e-04 - val_loss: 7.7893e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 248/500\n",
            "379/379 - 1s - loss: 9.5478e-04 - val_loss: 7.7858e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 249/500\n",
            "379/379 - 1s - loss: 9.5417e-04 - val_loss: 7.7824e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 250/500\n",
            "379/379 - 1s - loss: 9.5357e-04 - val_loss: 7.7791e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 251/500\n",
            "379/379 - 1s - loss: 9.5299e-04 - val_loss: 7.7759e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 252/500\n",
            "379/379 - 1s - loss: 9.5243e-04 - val_loss: 7.7728e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 253/500\n",
            "379/379 - 1s - loss: 9.5187e-04 - val_loss: 7.7698e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 254/500\n",
            "379/379 - 1s - loss: 9.5133e-04 - val_loss: 7.7669e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 255/500\n",
            "379/379 - 1s - loss: 9.5081e-04 - val_loss: 7.7640e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 256/500\n",
            "379/379 - 1s - loss: 9.5029e-04 - val_loss: 7.7613e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 257/500\n",
            "379/379 - 1s - loss: 9.4979e-04 - val_loss: 7.7587e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 258/500\n",
            "379/379 - 1s - loss: 9.4930e-04 - val_loss: 7.7561e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 259/500\n",
            "379/379 - 1s - loss: 9.4882e-04 - val_loss: 7.7536e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 260/500\n",
            "379/379 - 1s - loss: 9.4835e-04 - val_loss: 7.7512e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 261/500\n",
            "379/379 - 1s - loss: 9.4789e-04 - val_loss: 7.7488e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 262/500\n",
            "379/379 - 1s - loss: 9.4744e-04 - val_loss: 7.7466e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 263/500\n",
            "379/379 - 1s - loss: 9.4700e-04 - val_loss: 7.7444e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 264/500\n",
            "379/379 - 1s - loss: 9.4657e-04 - val_loss: 7.7422e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 265/500\n",
            "379/379 - 1s - loss: 9.4615e-04 - val_loss: 7.7402e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 266/500\n",
            "379/379 - 1s - loss: 9.4573e-04 - val_loss: 7.7382e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 267/500\n",
            "379/379 - 1s - loss: 9.4533e-04 - val_loss: 7.7363e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 268/500\n",
            "379/379 - 1s - loss: 9.4493e-04 - val_loss: 7.7344e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 269/500\n",
            "379/379 - 1s - loss: 9.4454e-04 - val_loss: 7.7326e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 270/500\n",
            "379/379 - 1s - loss: 9.4416e-04 - val_loss: 7.7309e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 271/500\n",
            "379/379 - 1s - loss: 9.4379e-04 - val_loss: 7.7292e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 272/500\n",
            "379/379 - 1s - loss: 9.4342e-04 - val_loss: 7.7275e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 273/500\n",
            "379/379 - 1s - loss: 9.4306e-04 - val_loss: 7.7260e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 274/500\n",
            "379/379 - 1s - loss: 9.4271e-04 - val_loss: 7.7245e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 275/500\n",
            "379/379 - 1s - loss: 9.4236e-04 - val_loss: 7.7230e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 276/500\n",
            "379/379 - 1s - loss: 9.4202e-04 - val_loss: 7.7216e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 277/500\n",
            "379/379 - 1s - loss: 9.4169e-04 - val_loss: 7.7202e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 278/500\n",
            "379/379 - 1s - loss: 9.4136e-04 - val_loss: 7.7188e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 279/500\n",
            "379/379 - 1s - loss: 9.4104e-04 - val_loss: 7.7175e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 280/500\n",
            "379/379 - 1s - loss: 9.4072e-04 - val_loss: 7.7163e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 281/500\n",
            "379/379 - 1s - loss: 9.4041e-04 - val_loss: 7.7151e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 282/500\n",
            "379/379 - 1s - loss: 9.4011e-04 - val_loss: 7.7139e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 283/500\n",
            "379/379 - 1s - loss: 9.3981e-04 - val_loss: 7.7127e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 284/500\n",
            "379/379 - 1s - loss: 9.3951e-04 - val_loss: 7.7117e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 285/500\n",
            "379/379 - 1s - loss: 9.3922e-04 - val_loss: 7.7106e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 286/500\n",
            "379/379 - 1s - loss: 9.3893e-04 - val_loss: 7.7096e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 287/500\n",
            "379/379 - 1s - loss: 9.3865e-04 - val_loss: 7.7086e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 288/500\n",
            "379/379 - 1s - loss: 9.3837e-04 - val_loss: 7.7077e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 289/500\n",
            "379/379 - 1s - loss: 9.3810e-04 - val_loss: 7.7068e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 290/500\n",
            "379/379 - 1s - loss: 9.3783e-04 - val_loss: 7.7059e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 291/500\n",
            "379/379 - 1s - loss: 9.3757e-04 - val_loss: 7.7050e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 292/500\n",
            "379/379 - 1s - loss: 9.3731e-04 - val_loss: 7.7042e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 293/500\n",
            "379/379 - 1s - loss: 9.3705e-04 - val_loss: 7.7034e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 294/500\n",
            "379/379 - 1s - loss: 9.3680e-04 - val_loss: 7.7027e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 295/500\n",
            "379/379 - 1s - loss: 9.3655e-04 - val_loss: 7.7019e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 296/500\n",
            "379/379 - 1s - loss: 9.3630e-04 - val_loss: 7.7012e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 297/500\n",
            "379/379 - 1s - loss: 9.3606e-04 - val_loss: 7.7006e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 298/500\n",
            "379/379 - 1s - loss: 9.3582e-04 - val_loss: 7.6999e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 299/500\n",
            "379/379 - 1s - loss: 9.3558e-04 - val_loss: 7.6993e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 300/500\n",
            "379/379 - 1s - loss: 9.3535e-04 - val_loss: 7.6987e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 301/500\n",
            "379/379 - 1s - loss: 9.3512e-04 - val_loss: 7.6981e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 302/500\n",
            "379/379 - 1s - loss: 9.3489e-04 - val_loss: 7.6976e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 303/500\n",
            "379/379 - 1s - loss: 9.3466e-04 - val_loss: 7.6970e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 304/500\n",
            "379/379 - 1s - loss: 9.3444e-04 - val_loss: 7.6965e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 305/500\n",
            "379/379 - 1s - loss: 9.3422e-04 - val_loss: 7.6960e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 306/500\n",
            "379/379 - 1s - loss: 9.3401e-04 - val_loss: 7.6955e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 307/500\n",
            "379/379 - 1s - loss: 9.3379e-04 - val_loss: 7.6951e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 308/500\n",
            "379/379 - 1s - loss: 9.3358e-04 - val_loss: 7.6946e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 309/500\n",
            "379/379 - 1s - loss: 9.3338e-04 - val_loss: 7.6942e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 310/500\n",
            "379/379 - 1s - loss: 9.3317e-04 - val_loss: 7.6938e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 311/500\n",
            "379/379 - 1s - loss: 9.3297e-04 - val_loss: 7.6934e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 312/500\n",
            "379/379 - 1s - loss: 9.3276e-04 - val_loss: 7.6931e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 313/500\n",
            "379/379 - 1s - loss: 9.3256e-04 - val_loss: 7.6927e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 314/500\n",
            "379/379 - 1s - loss: 9.3237e-04 - val_loss: 7.6923e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 315/500\n",
            "379/379 - 1s - loss: 9.3217e-04 - val_loss: 7.6920e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 316/500\n",
            "379/379 - 1s - loss: 9.3198e-04 - val_loss: 7.6917e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 317/500\n",
            "379/379 - 1s - loss: 9.3179e-04 - val_loss: 7.6914e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 318/500\n",
            "379/379 - 1s - loss: 9.3160e-04 - val_loss: 7.6911e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 319/500\n",
            "379/379 - 1s - loss: 9.3141e-04 - val_loss: 7.6909e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 320/500\n",
            "379/379 - 1s - loss: 9.3123e-04 - val_loss: 7.6906e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 321/500\n",
            "379/379 - 1s - loss: 9.3104e-04 - val_loss: 7.6903e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 322/500\n",
            "379/379 - 1s - loss: 9.3086e-04 - val_loss: 7.6901e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 323/500\n",
            "379/379 - 1s - loss: 9.3068e-04 - val_loss: 7.6899e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 324/500\n",
            "379/379 - 1s - loss: 9.3050e-04 - val_loss: 7.6897e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 325/500\n",
            "379/379 - 1s - loss: 9.3033e-04 - val_loss: 7.6895e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 326/500\n",
            "379/379 - 1s - loss: 9.3015e-04 - val_loss: 7.6893e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 327/500\n",
            "379/379 - 1s - loss: 9.2998e-04 - val_loss: 7.6891e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 328/500\n",
            "379/379 - 1s - loss: 9.2981e-04 - val_loss: 7.6890e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 329/500\n",
            "379/379 - 1s - loss: 9.2964e-04 - val_loss: 7.6888e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 330/500\n",
            "379/379 - 1s - loss: 9.2947e-04 - val_loss: 7.6886e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 331/500\n",
            "379/379 - 1s - loss: 9.2930e-04 - val_loss: 7.6885e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 332/500\n",
            "379/379 - 1s - loss: 9.2914e-04 - val_loss: 7.6884e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 333/500\n",
            "379/379 - 1s - loss: 9.2897e-04 - val_loss: 7.6882e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 334/500\n",
            "379/379 - 1s - loss: 9.2881e-04 - val_loss: 7.6881e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 335/500\n",
            "379/379 - 1s - loss: 9.2865e-04 - val_loss: 7.6880e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 336/500\n",
            "379/379 - 1s - loss: 9.2849e-04 - val_loss: 7.6879e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 337/500\n",
            "379/379 - 1s - loss: 9.2833e-04 - val_loss: 7.6879e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 338/500\n",
            "379/379 - 1s - loss: 9.2817e-04 - val_loss: 7.6878e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 339/500\n",
            "379/379 - 1s - loss: 9.2801e-04 - val_loss: 7.6877e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 340/500\n",
            "379/379 - 1s - loss: 9.2785e-04 - val_loss: 7.6877e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 341/500\n",
            "379/379 - 1s - loss: 9.2770e-04 - val_loss: 7.6876e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 342/500\n",
            "379/379 - 1s - loss: 9.2755e-04 - val_loss: 7.6876e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 343/500\n",
            "379/379 - 1s - loss: 9.2739e-04 - val_loss: 7.6875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 344/500\n",
            "379/379 - 1s - loss: 9.2724e-04 - val_loss: 7.6875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 345/500\n",
            "379/379 - 1s - loss: 9.2709e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 346/500\n",
            "379/379 - 1s - loss: 9.2694e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 347/500\n",
            "379/379 - 1s - loss: 9.2679e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 348/500\n",
            "379/379 - 1s - loss: 9.2665e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 349/500\n",
            "379/379 - 1s - loss: 9.2650e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 350/500\n",
            "379/379 - 1s - loss: 9.2636e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 351/500\n",
            "379/379 - 1s - loss: 9.2621e-04 - val_loss: 7.6874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 352/500\n",
            "379/379 - 1s - loss: 9.2607e-04 - val_loss: 7.6875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 353/500\n",
            "379/379 - 1s - loss: 9.2593e-04 - val_loss: 7.6875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 354/500\n",
            "379/379 - 1s - loss: 9.2578e-04 - val_loss: 7.6875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 355/500\n",
            "379/379 - 1s - loss: 9.2564e-04 - val_loss: 7.6876e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 356/500\n",
            "379/379 - 1s - loss: 9.2550e-04 - val_loss: 7.6876e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 357/500\n",
            "379/379 - 1s - loss: 9.2536e-04 - val_loss: 7.6876e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 358/500\n",
            "379/379 - 1s - loss: 9.2522e-04 - val_loss: 7.6877e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 359/500\n",
            "379/379 - 1s - loss: 9.2509e-04 - val_loss: 7.6878e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 360/500\n",
            "379/379 - 1s - loss: 9.2495e-04 - val_loss: 7.6879e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 361/500\n",
            "379/379 - 1s - loss: 9.2481e-04 - val_loss: 7.6879e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 362/500\n",
            "379/379 - 1s - loss: 9.2468e-04 - val_loss: 7.6880e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 363/500\n",
            "379/379 - 1s - loss: 9.2454e-04 - val_loss: 7.6881e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 364/500\n",
            "379/379 - 1s - loss: 9.2441e-04 - val_loss: 7.6882e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 365/500\n",
            "379/379 - 1s - loss: 9.2428e-04 - val_loss: 7.6883e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 366/500\n",
            "379/379 - 1s - loss: 9.2414e-04 - val_loss: 7.6884e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 367/500\n",
            "379/379 - 1s - loss: 9.2401e-04 - val_loss: 7.6885e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 368/500\n",
            "Restoring model weights from the end of the best epoch: 348.\n",
            "379/379 - 1s - loss: 9.2388e-04 - val_loss: 7.6886e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 368: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 7\n",
            "train.shape: (1516, 31) test.shape: (379, 31)\n",
            "train_scaled.shape: (1516, 31) test_scaled.shape: (379, 31)\n",
            "train_X.shape: (1516, 7, 4) train_y.shape: (1516, 3) test_X.shape: (379, 7, 4) test_y.shape: (379, 3)\n",
            "Epoch 1/500\n",
            "379/379 - 4s - loss: 0.3816 - val_loss: 0.3108 - 4s/epoch - 11ms/step\n",
            "Epoch 2/500\n",
            "379/379 - 1s - loss: 0.2121 - val_loss: 0.1954 - 1s/epoch - 4ms/step\n",
            "Epoch 3/500\n",
            "379/379 - 1s - loss: 0.1064 - val_loss: 0.1195 - 1s/epoch - 4ms/step\n",
            "Epoch 4/500\n",
            "379/379 - 1s - loss: 0.0513 - val_loss: 0.0741 - 1s/epoch - 3ms/step\n",
            "Epoch 5/500\n",
            "379/379 - 1s - loss: 0.0274 - val_loss: 0.0495 - 1s/epoch - 3ms/step\n",
            "Epoch 6/500\n",
            "379/379 - 1s - loss: 0.0185 - val_loss: 0.0367 - 1s/epoch - 4ms/step\n",
            "Epoch 7/500\n",
            "379/379 - 1s - loss: 0.0152 - val_loss: 0.0293 - 1s/epoch - 4ms/step\n",
            "Epoch 8/500\n",
            "379/379 - 1s - loss: 0.0133 - val_loss: 0.0241 - 1s/epoch - 4ms/step\n",
            "Epoch 9/500\n",
            "379/379 - 1s - loss: 0.0119 - val_loss: 0.0200 - 1s/epoch - 3ms/step\n",
            "Epoch 10/500\n",
            "379/379 - 1s - loss: 0.0107 - val_loss: 0.0165 - 1s/epoch - 4ms/step\n",
            "Epoch 11/500\n",
            "379/379 - 1s - loss: 0.0097 - val_loss: 0.0135 - 1s/epoch - 3ms/step\n",
            "Epoch 12/500\n",
            "379/379 - 1s - loss: 0.0088 - val_loss: 0.0111 - 1s/epoch - 3ms/step\n",
            "Epoch 13/500\n",
            "379/379 - 1s - loss: 0.0081 - val_loss: 0.0090 - 1s/epoch - 3ms/step\n",
            "Epoch 14/500\n",
            "379/379 - 1s - loss: 0.0075 - val_loss: 0.0074 - 1s/epoch - 4ms/step\n",
            "Epoch 15/500\n",
            "379/379 - 1s - loss: 0.0070 - val_loss: 0.0060 - 1s/epoch - 3ms/step\n",
            "Epoch 16/500\n",
            "379/379 - 1s - loss: 0.0066 - val_loss: 0.0049 - 1s/epoch - 3ms/step\n",
            "Epoch 17/500\n",
            "379/379 - 1s - loss: 0.0062 - val_loss: 0.0040 - 1s/epoch - 4ms/step\n",
            "Epoch 18/500\n",
            "379/379 - 1s - loss: 0.0059 - val_loss: 0.0033 - 1s/epoch - 3ms/step\n",
            "Epoch 19/500\n",
            "379/379 - 1s - loss: 0.0056 - val_loss: 0.0027 - 1s/epoch - 3ms/step\n",
            "Epoch 20/500\n",
            "379/379 - 1s - loss: 0.0054 - val_loss: 0.0022 - 1s/epoch - 3ms/step\n",
            "Epoch 21/500\n",
            "379/379 - 1s - loss: 0.0052 - val_loss: 0.0018 - 1s/epoch - 4ms/step\n",
            "Epoch 22/500\n",
            "379/379 - 1s - loss: 0.0051 - val_loss: 0.0015 - 1s/epoch - 3ms/step\n",
            "Epoch 23/500\n",
            "379/379 - 1s - loss: 0.0049 - val_loss: 0.0013 - 1s/epoch - 3ms/step\n",
            "Epoch 24/500\n",
            "379/379 - 1s - loss: 0.0048 - val_loss: 0.0011 - 1s/epoch - 4ms/step\n",
            "Epoch 25/500\n",
            "379/379 - 1s - loss: 0.0047 - val_loss: 9.3640e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 26/500\n",
            "379/379 - 1s - loss: 0.0046 - val_loss: 8.1459e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 27/500\n",
            "379/379 - 1s - loss: 0.0045 - val_loss: 7.1701e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 28/500\n",
            "379/379 - 1s - loss: 0.0044 - val_loss: 6.3847e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 29/500\n",
            "379/379 - 1s - loss: 0.0044 - val_loss: 5.7489e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 30/500\n",
            "379/379 - 1s - loss: 0.0043 - val_loss: 5.2310e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 31/500\n",
            "379/379 - 1s - loss: 0.0043 - val_loss: 4.8062e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 32/500\n",
            "379/379 - 1s - loss: 0.0042 - val_loss: 4.4553e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 33/500\n",
            "379/379 - 1s - loss: 0.0042 - val_loss: 4.1635e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 34/500\n",
            "379/379 - 1s - loss: 0.0041 - val_loss: 3.9190e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 35/500\n",
            "379/379 - 1s - loss: 0.0041 - val_loss: 3.7126e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 36/500\n",
            "379/379 - 1s - loss: 0.0040 - val_loss: 3.5373e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 37/500\n",
            "379/379 - 1s - loss: 0.0040 - val_loss: 3.3871e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 38/500\n",
            "379/379 - 1s - loss: 0.0040 - val_loss: 3.2576e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 39/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 3.1450e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 40/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 3.0464e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 41/500\n",
            "379/379 - 1s - loss: 0.0039 - val_loss: 2.9594e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 42/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 2.8819e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 43/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 2.8123e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 44/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 2.7495e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 45/500\n",
            "379/379 - 1s - loss: 0.0038 - val_loss: 2.6921e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 46/500\n",
            "379/379 - 1s - loss: 0.0037 - val_loss: 2.6394e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 47/500\n",
            "379/379 - 1s - loss: 0.0037 - val_loss: 2.5905e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 48/500\n",
            "379/379 - 1s - loss: 0.0037 - val_loss: 2.5448e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 49/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.5018e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 50/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.4609e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 51/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.4219e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 52/500\n",
            "379/379 - 1s - loss: 0.0036 - val_loss: 2.3842e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 53/500\n",
            "379/379 - 1s - loss: 0.0035 - val_loss: 2.3477e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 54/500\n",
            "379/379 - 1s - loss: 0.0035 - val_loss: 2.3122e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 55/500\n",
            "379/379 - 1s - loss: 0.0035 - val_loss: 2.2773e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 56/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.2429e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 57/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.2090e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 58/500\n",
            "379/379 - 1s - loss: 0.0034 - val_loss: 2.1754e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 59/500\n",
            "379/379 - 1s - loss: 0.0033 - val_loss: 2.1421e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 60/500\n",
            "379/379 - 1s - loss: 0.0033 - val_loss: 2.1090e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 61/500\n",
            "379/379 - 1s - loss: 0.0032 - val_loss: 2.0761e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 62/500\n",
            "379/379 - 1s - loss: 0.0032 - val_loss: 2.0435e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 63/500\n",
            "379/379 - 1s - loss: 0.0032 - val_loss: 2.0112e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 64/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 1.9793e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 65/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 1.9478e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 66/500\n",
            "379/379 - 1s - loss: 0.0031 - val_loss: 1.9170e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 67/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 1.8867e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 68/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 1.8573e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 69/500\n",
            "379/379 - 1s - loss: 0.0030 - val_loss: 1.8287e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 70/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 1.8012e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 71/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 1.7746e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 72/500\n",
            "379/379 - 1s - loss: 0.0029 - val_loss: 1.7492e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 73/500\n",
            "379/379 - 1s - loss: 0.0028 - val_loss: 1.7249e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 74/500\n",
            "379/379 - 1s - loss: 0.0028 - val_loss: 1.7017e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 75/500\n",
            "379/379 - 1s - loss: 0.0028 - val_loss: 1.6796e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 76/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 1.6586e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 77/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 1.6385e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 78/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 1.6194e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 79/500\n",
            "379/379 - 1s - loss: 0.0027 - val_loss: 1.6012e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 80/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.5838e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 81/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.5670e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 82/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.5509e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 83/500\n",
            "379/379 - 1s - loss: 0.0026 - val_loss: 1.5354e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 84/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.5204e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 85/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.5059e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 86/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.4918e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 87/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.4780e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 88/500\n",
            "379/379 - 1s - loss: 0.0025 - val_loss: 1.4646e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 89/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.4515e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 90/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.4386e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 91/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.4260e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 92/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.4136e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 93/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.4014e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 94/500\n",
            "379/379 - 1s - loss: 0.0024 - val_loss: 1.3893e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 95/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.3775e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 96/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.3658e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 97/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.3542e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 98/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.3428e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 99/500\n",
            "379/379 - 1s - loss: 0.0023 - val_loss: 1.3315e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 100/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.3204e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 101/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.3093e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 102/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.2984e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 103/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.2875e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 104/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.2768e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 105/500\n",
            "379/379 - 1s - loss: 0.0022 - val_loss: 1.2661e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 106/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.2555e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 107/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.2449e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 108/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.2344e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 109/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.2239e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 110/500\n",
            "379/379 - 1s - loss: 0.0021 - val_loss: 1.2134e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 111/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.2029e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 112/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.1924e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 113/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.1818e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 114/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.1712e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 115/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.1605e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 116/500\n",
            "379/379 - 1s - loss: 0.0020 - val_loss: 1.1497e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 117/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.1389e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 118/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.1279e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 119/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.1169e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 120/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.1057e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 121/500\n",
            "379/379 - 1s - loss: 0.0019 - val_loss: 1.0945e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 122/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.0832e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 123/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.0718e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 124/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.0603e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 125/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.0487e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 126/500\n",
            "379/379 - 1s - loss: 0.0018 - val_loss: 1.0371e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 127/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.0255e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 128/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.0138e-04 - 1s/epoch - 3ms/step\n",
            "Epoch 129/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 1.0022e-04 - 1s/epoch - 4ms/step\n",
            "Epoch 130/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 9.9049e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 131/500\n",
            "379/379 - 1s - loss: 0.0017 - val_loss: 9.7887e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 132/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 9.6729e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 133/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 9.5579e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 134/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 9.4438e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 135/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 9.3308e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 136/500\n",
            "379/379 - 1s - loss: 0.0016 - val_loss: 9.2191e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 137/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 9.1089e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 138/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 9.0005e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 139/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 8.8940e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 140/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 8.7895e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 141/500\n",
            "379/379 - 1s - loss: 0.0015 - val_loss: 8.6872e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 142/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 8.5873e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 143/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 8.4899e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 144/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 8.3952e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 145/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 8.3032e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 146/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 8.2142e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 147/500\n",
            "379/379 - 1s - loss: 0.0014 - val_loss: 8.1281e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 148/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 8.0451e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 149/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 7.9652e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 150/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 7.8886e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 151/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 7.8152e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 152/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 7.7450e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 153/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 7.6781e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 154/500\n",
            "379/379 - 1s - loss: 0.0013 - val_loss: 7.6145e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 155/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.5542e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 156/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.4971e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 157/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.4432e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 158/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.3925e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 159/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.3448e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 160/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.3002e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 161/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.2586e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 162/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.2198e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 163/500\n",
            "379/379 - 1s - loss: 0.0012 - val_loss: 7.1839e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 164/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.1506e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 165/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.1199e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 166/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.0917e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 167/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.0659e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 168/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.0424e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 169/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.0211e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 170/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 7.0018e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 171/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9844e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 172/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9689e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 173/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9551e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 174/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9429e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 175/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9322e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 176/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9229e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 177/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9150e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 178/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9082e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 179/500\n",
            "379/379 - 1s - loss: 0.0011 - val_loss: 6.9026e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 180/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8980e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 181/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8943e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 182/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8915e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 183/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8895e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 184/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8881e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 185/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8875e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 186/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8874e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 187/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8878e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 188/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8887e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 189/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8900e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 190/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8917e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 191/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8936e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 192/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8959e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 193/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.8984e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 194/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9011e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 195/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9039e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 196/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9069e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 197/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9100e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 198/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9132e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 199/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9165e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 200/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9198e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 201/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9232e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 202/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9266e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 203/500\n",
            "379/379 - 1s - loss: 0.0010 - val_loss: 6.9300e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 204/500\n",
            "379/379 - 1s - loss: 9.9988e-04 - val_loss: 6.9333e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 205/500\n",
            "379/379 - 1s - loss: 9.9885e-04 - val_loss: 6.9367e-05 - 1s/epoch - 4ms/step\n",
            "Epoch 206/500\n",
            "Restoring model weights from the end of the best epoch: 186.\n",
            "379/379 - 1s - loss: 9.9787e-04 - val_loss: 6.9401e-05 - 1s/epoch - 3ms/step\n",
            "Epoch 206: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 8\n",
            "train.shape: (1515, 35) test.shape: (379, 35)\n",
            "train_scaled.shape: (1515, 35) test_scaled.shape: (379, 35)\n",
            "train_X.shape: (1515, 8, 4) train_y.shape: (1515, 3) test_X.shape: (379, 8, 4) test_y.shape: (379, 3)\n",
            "Epoch 1/500\n",
            "379/379 - 4s - loss: 0.0289 - val_loss: 0.0231 - 4s/epoch - 12ms/step\n",
            "Epoch 2/500\n",
            "379/379 - 2s - loss: 0.0091 - val_loss: 0.0080 - 2s/epoch - 5ms/step\n",
            "Epoch 3/500\n",
            "379/379 - 2s - loss: 0.0062 - val_loss: 0.0042 - 2s/epoch - 5ms/step\n",
            "Epoch 4/500\n",
            "379/379 - 2s - loss: 0.0057 - val_loss: 0.0029 - 2s/epoch - 5ms/step\n",
            "Epoch 5/500\n",
            "379/379 - 2s - loss: 0.0053 - val_loss: 0.0022 - 2s/epoch - 5ms/step\n",
            "Epoch 6/500\n",
            "379/379 - 2s - loss: 0.0051 - val_loss: 0.0017 - 2s/epoch - 5ms/step\n",
            "Epoch 7/500\n",
            "379/379 - 2s - loss: 0.0049 - val_loss: 0.0013 - 2s/epoch - 5ms/step\n",
            "Epoch 8/500\n",
            "379/379 - 2s - loss: 0.0048 - val_loss: 0.0011 - 2s/epoch - 5ms/step\n",
            "Epoch 9/500\n",
            "379/379 - 2s - loss: 0.0047 - val_loss: 8.7139e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 10/500\n",
            "379/379 - 2s - loss: 0.0046 - val_loss: 7.3909e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 11/500\n",
            "379/379 - 2s - loss: 0.0045 - val_loss: 6.4266e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 12/500\n",
            "379/379 - 2s - loss: 0.0045 - val_loss: 5.7182e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 13/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 5.1935e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 14/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 4.8013e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 15/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 4.5055e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 16/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 4.2804e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 17/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 4.1075e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 18/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 3.9735e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 19/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 3.8686e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 20/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 3.7855e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 21/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 3.7190e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 22/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 3.6651e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 23/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 3.6206e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 24/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 3.5834e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 25/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 3.5517e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 26/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 3.5241e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 27/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 3.4997e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 28/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 3.4776e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 29/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 3.4574e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 30/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 3.4384e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 31/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.4205e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 32/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.4033e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 33/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.3865e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 34/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.3701e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 35/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.3539e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 36/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.3378e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 37/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 3.3216e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 38/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 3.3055e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 39/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 3.2891e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 40/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 3.2726e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 41/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 3.2559e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 42/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 3.2389e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 43/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 3.2216e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 44/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 3.2039e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 45/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 3.1858e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 46/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 3.1673e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 47/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 3.1484e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 48/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 3.1290e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 49/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 3.1091e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 50/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 3.0886e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 51/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 3.0677e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 52/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 3.0461e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 53/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 3.0240e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 54/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 3.0013e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 55/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.9780e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 56/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.9542e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 57/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.9297e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 58/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.9046e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 59/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.8789e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 60/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.8526e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 61/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.8258e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 62/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.7985e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 63/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.7706e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 64/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.7422e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 65/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.7134e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 66/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.6841e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 67/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.6545e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 68/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.6246e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 69/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.5944e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 70/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.5640e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 71/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.5334e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 72/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.5027e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 73/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.4720e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 74/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.4412e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 75/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.4106e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 76/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.3800e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 77/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.3497e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 78/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.3196e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 79/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2898e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 80/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2603e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 81/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2313e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 82/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.2026e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 83/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1745e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 84/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1468e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 85/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1197e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 86/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.0932e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 87/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.0673e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 88/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.0419e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 89/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.0172e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 90/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 1.9932e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 91/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 1.9697e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 92/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 1.9470e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 93/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 1.9248e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 94/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 1.9033e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 95/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 1.8825e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 96/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 1.8622e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 97/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 1.8426e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 98/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 1.8236e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 99/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 1.8051e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 100/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 1.7872e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 101/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 1.7699e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 102/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.7531e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 103/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.7367e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 104/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.7209e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 105/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.7055e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 106/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.6906e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 107/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.6761e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 108/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.6620e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 109/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.6483e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 110/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.6349e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 111/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.6219e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 112/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.6092e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 113/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.5968e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 114/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.5847e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 115/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.5729e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 116/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.5613e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 117/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.5500e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 118/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.5390e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 119/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.5281e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 120/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.5175e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 121/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.5071e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 122/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.4969e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 123/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.4868e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 124/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.4769e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 125/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.4672e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 126/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.4577e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 127/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.4483e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 128/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.4390e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 129/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.4299e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 130/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.4209e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 131/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.4121e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 132/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4033e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 133/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.3947e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 134/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.3863e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 135/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.3778e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 136/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.3696e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 137/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.3614e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 138/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.3533e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 139/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3453e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 140/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3374e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 141/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3296e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 142/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3219e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 143/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3142e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 144/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3067e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 145/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.2992e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 146/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.2918e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 147/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2844e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 148/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2772e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 149/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2700e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 150/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2629e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 151/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2559e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 152/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2489e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 153/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2420e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 154/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2351e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 155/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2284e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 156/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2216e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 157/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2150e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 158/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2084e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 159/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2018e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 160/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1954e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 161/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1889e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 162/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1826e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 163/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1763e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 164/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1700e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 165/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1638e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 166/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1577e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 167/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1516e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 168/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1455e-04 - 2s/epoch - 4ms/step\n",
            "Epoch 169/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1395e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 170/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1336e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 171/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1277e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 172/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1219e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 173/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1161e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 174/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1104e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 175/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1047e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 176/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0990e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 177/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0935e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 178/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0879e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 179/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0824e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 180/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0770e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 181/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0716e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 182/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0662e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 183/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0610e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 184/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0557e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 185/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0505e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 186/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0454e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 187/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0403e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 188/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0352e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 189/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0302e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 190/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0253e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 191/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0204e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 192/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0156e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 193/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0108e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 194/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0060e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 195/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0013e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 196/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.9670e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 197/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.9212e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 198/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.8759e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 199/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.8310e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 200/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.7867e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 201/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.7429e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 202/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.6997e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 203/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.6570e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 204/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.6149e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 205/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.5733e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 206/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.5322e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 207/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.4917e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 208/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.4518e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 209/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.4123e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 210/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.3734e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 211/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.3351e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 212/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.2973e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 213/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.2601e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 214/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.2235e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 215/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.1874e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 216/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.1518e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 217/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.1169e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 218/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.0825e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 219/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.0486e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 220/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 9.0153e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 221/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.9826e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 222/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.9504e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 223/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.9188e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 224/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.8878e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 225/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.8572e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 226/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.8273e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 227/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.7979e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 228/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.7691e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 229/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.7408e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 230/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.7130e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 231/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.6858e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 232/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.6591e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 233/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.6330e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 234/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.6074e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 235/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.5824e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 236/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.5579e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 237/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.5339e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 238/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.5104e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 239/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.4874e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 240/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.4650e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 241/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.4430e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 242/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.4216e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 243/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.4007e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 244/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.3803e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 245/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.3603e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 246/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.3408e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 247/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.3218e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 248/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.3033e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 249/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.2853e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 250/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.2677e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 251/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.2505e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 252/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.2338e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 253/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.2176e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 254/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.2018e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 255/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1864e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 256/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1715e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 257/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1570e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 258/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1429e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 259/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1292e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 260/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1159e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 261/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.1030e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 262/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0905e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 263/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0784e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 264/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0666e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 265/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0552e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 266/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0442e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 267/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0336e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 268/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0233e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 269/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0133e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 270/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 8.0037e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 271/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.9944e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 272/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.9854e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 273/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.9768e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 274/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.9684e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 275/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.9604e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 276/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9526e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 277/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9452e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 278/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9380e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 279/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9311e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 280/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9245e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 281/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9182e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 282/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9121e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 283/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9063e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 284/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.9007e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 285/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8954e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 286/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8903e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 287/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8855e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 288/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8808e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 289/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8764e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 290/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8722e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 291/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8682e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 292/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8645e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 293/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8609e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 294/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8575e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 295/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8543e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 296/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8513e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 297/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8485e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 298/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8458e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 299/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8433e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 300/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8410e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 301/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8389e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 302/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8368e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 303/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8350e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 304/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8333e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 305/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8317e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 306/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8303e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 307/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8290e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 308/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8278e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 309/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8267e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 310/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8258e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 311/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8250e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 312/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8243e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 313/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8237e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 314/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8232e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 315/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8228e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 316/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8225e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 317/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.8223e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 318/500\n",
            "379/379 - 2s - loss: 9.9975e-04 - val_loss: 7.8222e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 319/500\n",
            "379/379 - 2s - loss: 9.9896e-04 - val_loss: 7.8222e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 320/500\n",
            "379/379 - 2s - loss: 9.9817e-04 - val_loss: 7.8223e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 321/500\n",
            "379/379 - 2s - loss: 9.9740e-04 - val_loss: 7.8224e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 322/500\n",
            "379/379 - 2s - loss: 9.9664e-04 - val_loss: 7.8226e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 323/500\n",
            "379/379 - 2s - loss: 9.9589e-04 - val_loss: 7.8229e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 324/500\n",
            "379/379 - 2s - loss: 9.9516e-04 - val_loss: 7.8233e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 325/500\n",
            "379/379 - 2s - loss: 9.9443e-04 - val_loss: 7.8238e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 326/500\n",
            "379/379 - 2s - loss: 9.9372e-04 - val_loss: 7.8243e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 327/500\n",
            "379/379 - 2s - loss: 9.9302e-04 - val_loss: 7.8249e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 328/500\n",
            "379/379 - 2s - loss: 9.9234e-04 - val_loss: 7.8255e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 329/500\n",
            "379/379 - 2s - loss: 9.9166e-04 - val_loss: 7.8262e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 330/500\n",
            "379/379 - 2s - loss: 9.9100e-04 - val_loss: 7.8269e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 331/500\n",
            "379/379 - 2s - loss: 9.9034e-04 - val_loss: 7.8277e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 332/500\n",
            "379/379 - 2s - loss: 9.8970e-04 - val_loss: 7.8286e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 333/500\n",
            "379/379 - 2s - loss: 9.8907e-04 - val_loss: 7.8295e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 334/500\n",
            "379/379 - 2s - loss: 9.8844e-04 - val_loss: 7.8305e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 335/500\n",
            "379/379 - 2s - loss: 9.8783e-04 - val_loss: 7.8314e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 336/500\n",
            "379/379 - 2s - loss: 9.8723e-04 - val_loss: 7.8325e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 337/500\n",
            "379/379 - 2s - loss: 9.8663e-04 - val_loss: 7.8336e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 338/500\n",
            "379/379 - 2s - loss: 9.8605e-04 - val_loss: 7.8347e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 339/500\n",
            "Restoring model weights from the end of the best epoch: 319.\n",
            "379/379 - 2s - loss: 9.8548e-04 - val_loss: 7.8358e-05 - 2s/epoch - 4ms/step\n",
            "Epoch 339: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 9\n",
            "train.shape: (1514, 39) test.shape: (379, 39)\n",
            "train_scaled.shape: (1514, 39) test_scaled.shape: (379, 39)\n",
            "train_X.shape: (1514, 9, 4) train_y.shape: (1514, 3) test_X.shape: (379, 9, 4) test_y.shape: (379, 3)\n",
            "Epoch 1/500\n",
            "379/379 - 4s - loss: 0.2853 - val_loss: 0.1082 - 4s/epoch - 11ms/step\n",
            "Epoch 2/500\n",
            "379/379 - 2s - loss: 0.1740 - val_loss: 0.0560 - 2s/epoch - 5ms/step\n",
            "Epoch 3/500\n",
            "379/379 - 2s - loss: 0.0931 - val_loss: 0.0198 - 2s/epoch - 5ms/step\n",
            "Epoch 4/500\n",
            "379/379 - 2s - loss: 0.0406 - val_loss: 0.0034 - 2s/epoch - 5ms/step\n",
            "Epoch 5/500\n",
            "379/379 - 2s - loss: 0.0157 - val_loss: 5.6474e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 6/500\n",
            "379/379 - 2s - loss: 0.0083 - val_loss: 0.0013 - 2s/epoch - 5ms/step\n",
            "Epoch 7/500\n",
            "379/379 - 2s - loss: 0.0067 - val_loss: 0.0017 - 2s/epoch - 5ms/step\n",
            "Epoch 8/500\n",
            "379/379 - 2s - loss: 0.0062 - val_loss: 0.0015 - 2s/epoch - 5ms/step\n",
            "Epoch 9/500\n",
            "379/379 - 2s - loss: 0.0059 - val_loss: 0.0013 - 2s/epoch - 5ms/step\n",
            "Epoch 10/500\n",
            "379/379 - 2s - loss: 0.0057 - val_loss: 0.0011 - 2s/epoch - 5ms/step\n",
            "Epoch 11/500\n",
            "379/379 - 2s - loss: 0.0055 - val_loss: 8.7168e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 12/500\n",
            "379/379 - 2s - loss: 0.0054 - val_loss: 7.2141e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 13/500\n",
            "379/379 - 2s - loss: 0.0052 - val_loss: 6.0584e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 14/500\n",
            "379/379 - 2s - loss: 0.0051 - val_loss: 5.1910e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 15/500\n",
            "379/379 - 2s - loss: 0.0050 - val_loss: 4.5535e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 16/500\n",
            "379/379 - 2s - loss: 0.0049 - val_loss: 4.0925e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 17/500\n",
            "379/379 - 2s - loss: 0.0048 - val_loss: 3.7628e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 18/500\n",
            "379/379 - 2s - loss: 0.0048 - val_loss: 3.5280e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 19/500\n",
            "379/379 - 2s - loss: 0.0047 - val_loss: 3.3603e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 20/500\n",
            "379/379 - 2s - loss: 0.0047 - val_loss: 3.2389e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 21/500\n",
            "379/379 - 2s - loss: 0.0046 - val_loss: 3.1492e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 22/500\n",
            "379/379 - 2s - loss: 0.0046 - val_loss: 3.0812e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 23/500\n",
            "379/379 - 2s - loss: 0.0046 - val_loss: 3.0278e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 24/500\n",
            "379/379 - 2s - loss: 0.0045 - val_loss: 2.9845e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 25/500\n",
            "379/379 - 2s - loss: 0.0045 - val_loss: 2.9481e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 26/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 2.9167e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 27/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 2.8887e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 28/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 2.8632e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 29/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 2.8397e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 30/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 2.8177e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 31/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 2.7968e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 32/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 2.7768e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 33/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 2.7576e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 34/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 2.7390e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 35/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 2.7209e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 36/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 2.7034e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 37/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 2.6863e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 38/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 2.6696e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 39/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 2.6533e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 40/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 2.6375e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 41/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 2.6221e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 42/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 2.6071e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 43/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 2.5926e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 44/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 2.5785e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 45/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 2.5649e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 46/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 2.5517e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 47/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 2.5390e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 48/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 2.5266e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 49/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 2.5147e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 50/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 2.5032e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 51/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 2.4921e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 52/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 2.4814e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 53/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 2.4711e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 54/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4611e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 55/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4515e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 56/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4421e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 57/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4331e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 58/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4243e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 59/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.4159e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 60/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.4077e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 61/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.3998e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 62/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.3921e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 63/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.3846e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 64/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.3773e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 65/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.3702e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 66/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.3634e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 67/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.3566e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 68/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.3501e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 69/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.3437e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 70/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.3374e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 71/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.3312e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 72/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.3252e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 73/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.3192e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 74/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.3134e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 75/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.3076e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 76/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.3019e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 77/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2963e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 78/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2907e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 79/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2853e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 80/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2798e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 81/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2744e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 82/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2690e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 83/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2637e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 84/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2584e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 85/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2531e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 86/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2479e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 87/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2427e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 88/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2375e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 89/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2323e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 90/500\n",
            "379/379 - 3s - loss: 0.0030 - val_loss: 2.2272e-04 - 3s/epoch - 7ms/step\n",
            "Epoch 91/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2220e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 92/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.2169e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 93/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.2118e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 94/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.2067e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 95/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.2016e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 96/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1965e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 97/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1914e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 98/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1863e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 99/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1812e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 100/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1761e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 101/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1710e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 102/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1659e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 103/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1608e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 104/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1557e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 105/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1506e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 106/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1455e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 107/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1404e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 108/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1352e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 109/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1301e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 110/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1249e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 111/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1197e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 112/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1145e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 113/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.1093e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 114/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.1040e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 115/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0987e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 116/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0934e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 117/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0881e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 118/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0828e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 119/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0774e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 120/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0720e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 121/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0665e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 122/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0610e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 123/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0555e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 124/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0500e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 125/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0443e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 126/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0387e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 127/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0330e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 128/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0273e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 129/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0215e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 130/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 2.0157e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 131/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 2.0098e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 132/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 2.0039e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 133/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9979e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 134/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9919e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 135/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9858e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 136/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9797e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 137/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9735e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 138/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9673e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 139/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9610e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 140/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9546e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 141/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9482e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 142/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9418e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 143/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9353e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 144/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9287e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 145/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9221e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 146/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9154e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 147/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9087e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 148/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.9019e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 149/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8950e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 150/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8881e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 151/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8812e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 152/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8742e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 153/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8671e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 154/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8600e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 155/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8529e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 156/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8457e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 157/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8384e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 158/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.8311e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 159/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.8238e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 160/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.8164e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 161/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.8090e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 162/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.8015e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 163/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7940e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 164/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7864e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 165/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7788e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 166/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7712e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 167/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7636e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 168/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7559e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 169/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7482e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 170/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7404e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 171/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7326e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 172/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7248e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 173/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7170e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 174/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7092e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 175/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7013e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 176/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.6934e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 177/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.6855e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 178/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.6776e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 179/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6697e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 180/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6617e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 181/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6538e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 182/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6458e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 183/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6378e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 184/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6299e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 185/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6219e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 186/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6139e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 187/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6059e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 188/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.5979e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 189/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.5899e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 190/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.5820e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 191/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5740e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 192/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5660e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 193/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5580e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 194/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5501e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 195/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5421e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 196/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5341e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 197/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5262e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 198/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5183e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 199/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5103e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 200/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5024e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 201/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4945e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 202/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4866e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 203/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4787e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 204/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4709e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 205/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4630e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 206/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4552e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 207/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4474e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 208/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4396e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 209/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4318e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 210/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4240e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 211/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4162e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 212/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4085e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 213/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4008e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 214/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3930e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 215/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3854e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 216/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3777e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 217/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3700e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 218/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3624e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 219/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3547e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 220/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3471e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 221/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3395e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 222/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3320e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 223/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3244e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 224/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3169e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 225/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3093e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 226/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3018e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 227/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2943e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 228/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2869e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 229/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2794e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 230/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2720e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 231/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2646e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 232/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2571e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 233/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2498e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 234/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2424e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 235/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2350e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 236/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2277e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 237/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2204e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 238/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2131e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 239/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2058e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 240/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1986e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 241/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1913e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 242/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1841e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 243/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1769e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 244/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1697e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 245/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1626e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 246/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1554e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 247/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1483e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 248/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1412e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 249/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1342e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 250/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1271e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 251/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1201e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 252/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1131e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 253/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1061e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 254/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0992e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 255/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0923e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 256/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0854e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 257/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0785e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 258/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0717e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 259/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0649e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 260/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0581e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 261/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0514e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 262/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0447e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 263/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0380e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 264/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0314e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 265/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0248e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 266/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0182e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 267/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0117e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 268/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0052e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 269/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.9876e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 270/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.9236e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 271/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.8601e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 272/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.7970e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 273/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.7344e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 274/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.6723e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 275/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.6107e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 276/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.5495e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 277/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.4889e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 278/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.4289e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 279/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.3694e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 280/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.3103e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 281/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.2520e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 282/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.1942e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 283/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.1370e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 284/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.0805e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 285/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 9.0245e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 286/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 8.9692e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 287/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 8.9145e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 288/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 8.8606e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 289/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.8073e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 290/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.7548e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 291/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.7029e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 292/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.6518e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 293/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.6014e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 294/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.5518e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 295/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.5029e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 296/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.4548e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 297/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.4075e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 298/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.3610e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 299/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.3153e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 300/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.2704e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 301/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.2264e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 302/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.1831e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 303/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.1408e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 304/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.0993e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 305/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.0586e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 306/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 8.0189e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 307/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.9799e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 308/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.9419e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 309/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.9047e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 310/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.8685e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 311/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.8331e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 312/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.7986e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 313/500\n",
            "379/379 - 2s - loss: 0.0012 - val_loss: 7.7651e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 314/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.7324e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 315/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.7006e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 316/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.6697e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 317/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.6397e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 318/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.6106e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 319/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.5825e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 320/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.5552e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 321/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.5288e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 322/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.5033e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 323/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.4786e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 324/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.4548e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 325/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.4319e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 326/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.4099e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 327/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.3887e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 328/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.3684e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 329/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.3489e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 330/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.3301e-05 - 2s/epoch - 6ms/step\n",
            "Epoch 331/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.3123e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 332/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2952e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 333/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2789e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 334/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2634e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 335/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2487e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 336/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2347e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 337/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2215e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 338/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.2090e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 339/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1972e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 340/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1861e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 341/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1757e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 342/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1660e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 343/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1569e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 344/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1485e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 345/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1407e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 346/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1335e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 347/500\n",
            "379/379 - 2s - loss: 0.0011 - val_loss: 7.1269e-05 - 2s/epoch - 6ms/step\n",
            "Epoch 348/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1209e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 349/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1154e-05 - 2s/epoch - 6ms/step\n",
            "Epoch 350/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1106e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 351/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1062e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 352/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1023e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 353/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0990e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 354/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0962e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 355/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0938e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 356/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0918e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 357/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0903e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 358/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0893e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 359/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0886e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 360/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0883e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 361/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0885e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 362/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0889e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 363/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0898e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 364/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0910e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 365/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0924e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 366/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0942e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 367/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0963e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 368/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.0987e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 369/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1013e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 370/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1043e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 371/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1074e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 372/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1108e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 373/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1144e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 374/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1182e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 375/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1222e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 376/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1265e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 377/500\n",
            "379/379 - 2s - loss: 0.0010 - val_loss: 7.1308e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 378/500\n",
            "379/379 - 2s - loss: 9.9963e-04 - val_loss: 7.1354e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 379/500\n",
            "379/379 - 2s - loss: 9.9843e-04 - val_loss: 7.1401e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 380/500\n",
            "Restoring model weights from the end of the best epoch: 360.\n",
            "379/379 - 2s - loss: 9.9725e-04 - val_loss: 7.1450e-05 - 2s/epoch - 5ms/step\n",
            "Epoch 380: early stopping\n",
            "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 10\n",
            "train.shape: (1513, 43) test.shape: (379, 43)\n",
            "train_scaled.shape: (1513, 43) test_scaled.shape: (379, 43)\n",
            "train_X.shape: (1513, 10, 4) train_y.shape: (1513, 3) test_X.shape: (379, 10, 4) test_y.shape: (379, 3)\n",
            "Epoch 1/500\n",
            "379/379 - 5s - loss: 0.2451 - val_loss: 0.2099 - 5s/epoch - 12ms/step\n",
            "Epoch 2/500\n",
            "379/379 - 2s - loss: 0.1752 - val_loss: 0.1517 - 2s/epoch - 5ms/step\n",
            "Epoch 3/500\n",
            "379/379 - 2s - loss: 0.1166 - val_loss: 0.0978 - 2s/epoch - 6ms/step\n",
            "Epoch 4/500\n",
            "379/379 - 2s - loss: 0.0688 - val_loss: 0.0531 - 2s/epoch - 6ms/step\n",
            "Epoch 5/500\n",
            "379/379 - 2s - loss: 0.0324 - val_loss: 0.0207 - 2s/epoch - 5ms/step\n",
            "Epoch 6/500\n",
            "379/379 - 2s - loss: 0.0114 - val_loss: 0.0054 - 2s/epoch - 6ms/step\n",
            "Epoch 7/500\n",
            "379/379 - 2s - loss: 0.0054 - val_loss: 0.0018 - 2s/epoch - 6ms/step\n",
            "Epoch 8/500\n",
            "379/379 - 2s - loss: 0.0047 - val_loss: 0.0011 - 2s/epoch - 6ms/step\n",
            "Epoch 9/500\n",
            "379/379 - 2s - loss: 0.0046 - val_loss: 8.6725e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 10/500\n",
            "379/379 - 2s - loss: 0.0045 - val_loss: 7.5462e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 11/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 6.6312e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 12/500\n",
            "379/379 - 2s - loss: 0.0044 - val_loss: 5.8467e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 13/500\n",
            "379/379 - 2s - loss: 0.0043 - val_loss: 5.1829e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 14/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 4.6314e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 15/500\n",
            "379/379 - 2s - loss: 0.0042 - val_loss: 4.1800e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 16/500\n",
            "379/379 - 2s - loss: 0.0041 - val_loss: 3.8142e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 17/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.5195e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 18/500\n",
            "379/379 - 2s - loss: 0.0040 - val_loss: 3.2822e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 19/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 3.0909e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 20/500\n",
            "379/379 - 2s - loss: 0.0039 - val_loss: 2.9359e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 21/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 2.8098e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 22/500\n",
            "379/379 - 2s - loss: 0.0038 - val_loss: 2.7067e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 23/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 2.6222e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 24/500\n",
            "379/379 - 2s - loss: 0.0037 - val_loss: 2.5528e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 25/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4957e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 26/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4487e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 27/500\n",
            "379/379 - 2s - loss: 0.0036 - val_loss: 2.4099e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 28/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.3780e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 29/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.3516e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 30/500\n",
            "379/379 - 2s - loss: 0.0035 - val_loss: 2.3297e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 31/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.3114e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 32/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.2961e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 33/500\n",
            "379/379 - 2s - loss: 0.0034 - val_loss: 2.2833e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 34/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.2724e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 35/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.2632e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 36/500\n",
            "379/379 - 2s - loss: 0.0033 - val_loss: 2.2551e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 37/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2481e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 38/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2417e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 39/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2359e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 40/500\n",
            "379/379 - 2s - loss: 0.0032 - val_loss: 2.2304e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 41/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2250e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 42/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2196e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 43/500\n",
            "379/379 - 2s - loss: 0.0031 - val_loss: 2.2140e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 44/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2082e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 45/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.2021e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 46/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.1957e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 47/500\n",
            "379/379 - 2s - loss: 0.0030 - val_loss: 2.1889e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 48/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1816e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 49/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1741e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 50/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1662e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 51/500\n",
            "379/379 - 2s - loss: 0.0029 - val_loss: 2.1580e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 52/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1494e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 53/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1407e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 54/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1317e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 55/500\n",
            "379/379 - 2s - loss: 0.0028 - val_loss: 2.1225e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 56/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1132e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 57/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.1036e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 58/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.0940e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 59/500\n",
            "379/379 - 2s - loss: 0.0027 - val_loss: 2.0842e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 60/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0743e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 61/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0642e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 62/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0541e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 63/500\n",
            "379/379 - 2s - loss: 0.0026 - val_loss: 2.0437e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 64/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0333e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 65/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0226e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 66/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0118e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 67/500\n",
            "379/379 - 2s - loss: 0.0025 - val_loss: 2.0008e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 68/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9896e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 69/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9782e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 70/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9666e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 71/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9547e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 72/500\n",
            "379/379 - 2s - loss: 0.0024 - val_loss: 1.9426e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 73/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9302e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 74/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9176e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 75/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.9047e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 76/500\n",
            "379/379 - 2s - loss: 0.0023 - val_loss: 1.8916e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 77/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8782e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 78/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8645e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 79/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8504e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 80/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8362e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 81/500\n",
            "379/379 - 2s - loss: 0.0022 - val_loss: 1.8216e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 82/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.8067e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 83/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7916e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 84/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7762e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 85/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7605e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 86/500\n",
            "379/379 - 2s - loss: 0.0021 - val_loss: 1.7446e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 87/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7284e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 88/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.7119e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 89/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.6953e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 90/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.6784e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 91/500\n",
            "379/379 - 2s - loss: 0.0020 - val_loss: 1.6614e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 92/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6442e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 93/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6269e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 94/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.6094e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 95/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.5920e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 96/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.5745e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 97/500\n",
            "379/379 - 2s - loss: 0.0019 - val_loss: 1.5569e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 98/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5395e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 99/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5221e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 100/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.5048e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 101/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4876e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 102/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4706e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 103/500\n",
            "379/379 - 2s - loss: 0.0018 - val_loss: 1.4539e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 104/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4374e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 105/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4211e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 106/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.4051e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 107/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3894e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 108/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3740e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 109/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3589e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 110/500\n",
            "379/379 - 2s - loss: 0.0017 - val_loss: 1.3442e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 111/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3299e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 112/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3159e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 113/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.3022e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 114/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2890e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 115/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2761e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 116/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2635e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 117/500\n",
            "379/379 - 2s - loss: 0.0016 - val_loss: 1.2513e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 118/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2395e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 119/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2280e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 120/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2169e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 121/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.2060e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 122/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1955e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 123/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1853e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 124/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1754e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 125/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1658e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 126/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1565e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 127/500\n",
            "379/379 - 2s - loss: 0.0015 - val_loss: 1.1475e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 128/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1387e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 129/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1302e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 130/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1219e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 131/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1138e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 132/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.1060e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 133/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0983e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 134/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0909e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 135/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0837e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 136/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0766e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 137/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0698e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 138/500\n",
            "379/379 - 2s - loss: 0.0014 - val_loss: 1.0631e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 139/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0565e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 140/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0502e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 141/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0440e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 142/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0379e-04 - 2s/epoch - 5ms/step\n",
            "Epoch 143/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0319e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 144/500\n",
            "379/379 - 2s - loss: 0.0013 - val_loss: 1.0261e-04 - 2s/epoch - 6ms/step\n",
            "Epoch 145/500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs 500 num_hidden_layers 1 num_neurons 4 batch_size 4 window_size 7"
      ],
      "metadata": {
        "id": "pP6LD4IB_ruS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Add, Reshape, BatchNormalization, Concatenate\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "j-r_aXekI0bz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tcn import TCN"
      ],
      "metadata": {
        "id": "JPR39hgh43DU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EvEswvoTXy5",
        "outputId": "b86f3b45-b74c-4354-e461-00ec734b2af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "380/380 - 5s - loss: 0.0395 - val_loss: 0.0022 - 5s/epoch - 13ms/step\n",
            "Epoch 2/700\n",
            "380/380 - 2s - loss: 0.0108 - val_loss: 0.0012 - 2s/epoch - 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "# os.environ['PYTHONHASHSEED'] = '0'\n",
        "# np.random.seed(42)\n",
        "# np.random.seed(12345)\n",
        "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "#                                         inter_op_parallelism_threads=1)\n",
        "# from keras import backend as K\n",
        "# tf.random.set_seed(1234)\n",
        "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "#                             config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons=65# 22\n",
        "\n",
        "\n",
        "input_tensor=Input(shape=(window_size, n_features))\n",
        "\n",
        "# conv1 = Conv1D(filters = 16, kernel_size=1, dilation_rate=1, padding='same')(input_tensor)\n",
        "\n",
        "# conv2 = Conv1D(filters = 5, kernel_size=1, dilation_rate=1, padding='same')(conv1)\n",
        "\n",
        "\n",
        "# conv3 = Conv1D(filters = 20, kernel_size=4, dilation_rate=1, padding='causal')(conv2)\n",
        "# tcn1 = TCN(input_shape=(window_size, n_features), kernel_size = 14,\n",
        "#             nb_filters=46, return_sequences=True, dilations=[1, 1])(input_tensor)\n",
        "\n",
        "\n",
        "lstm_output = LSTM(neurons, activation=\"tanh\")(input_tensor)\n",
        "\n",
        "# Create the concatenate layer\n",
        "# concatenate_output = Concatenate()([conv3, lstm_output])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "outputs = Dense(steps_ahead)(lstm_output) # output layer\n",
        "model = Model(input_tensor, outputs)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "\n",
        "\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 700\n",
        "loss_tracking = list()\n",
        "\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_X, train_y,#callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=4, validation_data=(test_X, test_y),\n",
        "                     verbose=2,\n",
        "                     shuffle=False)\n",
        "    # to find for which epoch each loss belongs\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "    # Save the model every 10 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "        #model.save(f'model_{epoch}Eps.h5')\n",
        "        model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tcn --no-dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZrYOYH45_XT",
        "outputId": "18b56a16-fbd2-4c0d-dfdb-383b67dfa221"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tcn import TCN"
      ],
      "metadata": {
        "id": "BMnR7SV06YzQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# conv1 = Conv1D(filters = 46, kernel_size=1, dilation_rate=1, padding='same')(input_tensor)\n",
        "\n",
        "\n",
        "# conv2 = Conv1D(filters = 25, kernel_size=1, dilation_rate=1, padding='same')(conv1)\n",
        "\n",
        "\n",
        "# conv3 = Conv1D(filters = 46, kernel_size=1, dilation_rate=1, padding='same')(conv2)\n",
        "model = Sequential([\n",
        "    model.add(Conv1D(filters = 146, kernel_size=1, dilation_rate=1, padding='same')),\n",
        "    model.add(Conv1D(filters = 125, kernel_size=1, dilation_rate=1, padding='same')),\n",
        "    model.add(Conv1D(filters = 110, kernel_size=1, dilation_rate=1, padding='same')),\n",
        "    model.add(Conv1D(filters = 146, kernel_size=4, dilation_rate=16, padding='causal')),\n",
        "    LSTM(64),\n",
        "    Dense(3)\n",
        "])\n",
        "\n",
        "# model.add(Conv1D(filters = 46, kernel_size=1, dilation_rate=1, padding='same'))\n",
        "# model.add(Conv1D(filters = 25, kernel_size=1, dilation_rate=1, padding='same'))\n",
        "# model.add(Conv1D(filters = 10, kernel_size=1, dilation_rate=1, padding='same'))\n",
        "# model.add(Conv1D(filters = 46, kernel_size=2, dilation_rate=8, padding='causal'))\n",
        "# model.add(Conv1D(filters = 46, kernel_size=4, dilation_rate=16, padding='causal'))\n",
        "\n",
        "# conv4 = Conv1D(filters = 10, kernel_size=1, dilation_rate=1, padding='same')(conv3)\n",
        "# conv5 = Conv1D(filters = 10, kernel_size=1, dilation_rate=1, padding='same')(conv4)\n",
        "\n",
        "\n",
        "# lstm_output = LSTM(neurons, activation=\"tanh\")(conv3)\n",
        " \n",
        "# outputs = Dense(steps_ahead)(lstm_output) # output layer\n",
        "# model = Model(input_tensor, outputs)\n",
        "# model.add(Dense(steps_ahead))\n",
        "\n",
        "# Define the TCN layers\n",
        "# model.add(TCN(nb_filters=46, kernel_size=1, dilations=[1,1,1], nb_stacks=3, input_shape =(window_size, n_features),\n",
        "#           padding='same',# use_skip_connections=True,\n",
        "#            #return_sequences=True,\n",
        "#           activation='relu'#, kernel_initializer='he_normal'#,dropout_rate=0.1\n",
        "#           ))\n",
        "# model.add(LSTM(65))\n",
        "# output layer\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
        "\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 500\n",
        "loss_tracking = list()\n",
        "\n",
        "history = model.fit(train_X, train_y,\n",
        "                    epochs=500, batch_size=4, validation_data=(test_X, test_y),\n",
        "                     verbose=2,\n",
        "                     shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "owXCqrE_e_rn",
        "outputId": "ae25c4bb-b2ce-413a-f870-a4a7946844c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d0c8c5681b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# conv3 = Conv1D(filters = 46, kernel_size=1, dilation_rate=1, padding='same')(conv2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model = Sequential([\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m146\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'add'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEKVnLYPD47l",
        "outputId": "e6a47993-c994-4b46-d6aa-85cf6ab053ae"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 4, 46) dtype=float32 (created by layer 'conv1d_4')>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                            config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    TCN(input_shape=(window_size, n_features), nb_filters=256, return_sequences=True, dilations=[1, 2, 4, 8, 16, 32]),\n",
        "    keras.layers.Dense(steps_ahead)\n",
        "    ])\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "                            save_best_only=True,\n",
        "                            monitor='val_loss', mode='min') \n",
        "\n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 700\n",
        "loss_tracking = list()\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=4, validation_data=(test_X, test_y),\n",
        "                     verbose=2,\n",
        "                     shuffle=False)\n",
        "    # to find for which epoch each loss belongs\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "    # Save the model every 10 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "        #model.save(f'model_{epoch}Eps.h5')\n",
        "        model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ],
      "metadata": {
        "id": "lZ7I0rvzsWSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "59164b9e-a67f-43ad-b704-77bf91ef23ac"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-bd94d439ade0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model = keras.models.Sequential([\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mTCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_ahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tcn import TCN\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "import keras"
      ],
      "metadata": {
        "id": "s7OzpLLfDDRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnKJQzBtEoFu",
        "outputId": "631f09f7-8020-486f-ad90-745531b8bf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 4, 4) dtype=float32 (created by layer 'input_4')>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  best tcn architecture is the one used in the papaer"
      ],
      "metadata": {
        "id": "Vi-k3p80zLmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyrxlI_zh4_P"
      },
      "outputs": [],
      "source": [
        "# load the trained saved model\n",
        "model_saved = tf.keras.models.load_model('/content/drive/MyDrive/my_trained_models/[500, 1, 4, 2, 2]_model.h5')\n",
        "# Load the best weights\n",
        "model_saved.load_weights('/content/drive/MyDrive/my_trained_models/[500, 1, 4, 2, 2]_weights.hdf5')\n",
        "#print the loss of the best weights\n",
        "model_saved.evaluate(test_X, test_y, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUQ9MQO4e0uQ",
        "outputId": "b99be15b-9cc0-49d2-bcfe-101dea4207ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:82\n",
            "Validation loss: 6.0132886574137956e-05\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_X, test_y, verbose=0)\n",
        "best_epoch = loss_tracking.index(score) + 1\n",
        "# validation loss and corresponding epoch for the saved model\n",
        "print(f'Epoch:{best_epoch}\\nValidation loss: {score}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfmgjN3OhMYp"
      },
      "outputs": [],
      "source": [
        "# # continue if training is interrupted \n",
        "# model.compile(loss='mean_squared_error',\n",
        "#               optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n",
        "# early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2,\n",
        "#                                 restore_best_weights=True, mode='min')\n",
        "# # save the best weights if training is interrupted\n",
        "# mcp_save = ModelCheckpoint(os.path.join(directory, 'mdl_wts.hdf5'),\n",
        "#                             save_best_only=True,\n",
        "#                             monitor='val_loss', mode='min') \n",
        "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# # Set the initial and total number of epochs\n",
        "# initial_epoch = 1\n",
        "# n_epochs = 2000\n",
        "\n",
        "# # Run the training loop\n",
        "# for epoch in range(initial_epoch , n_epochs+1):\n",
        "#     print(f'Epoch {epoch}/{n_epochs}')\n",
        "#     # Train the model for one epoch\n",
        "#     history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save, reduce_lr_loss],\n",
        "#                     epochs=1, batch_size=2, validation_data=(test_X, test_y),\n",
        "#                      verbose=2,\n",
        "#                      shuffle=False)\n",
        "#     # to find for which epoch each loss belongs\n",
        "#     validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "#     loss_tracking.append(validation_loss)\n",
        "#     # Save the model every 10 epochs\n",
        "#     if epoch % 50 == 0:\n",
        "#         # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "#         #model.save(f'model_{epoch}Eps.h5')\n",
        "#         model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Om2PkqgiVjri",
        "outputId": "fbc63826-635b-4156-df77-b765c7a709a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(5))\n",
        "#plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(loss_tracking, label='test')\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHohbk8uYRIh"
      },
      "source": [
        "**MinMax Scaler equation**\n",
        "$$x' = \\frac{(x - min)}{(max - min)} \\times (new\\ max\\ value - new\\ min\\  value) + new\\ min\\ value$$<br/>\n",
        "\n",
        "\n",
        "$$x = \\frac{(max - min)\\times (new\\ min\\ value + x') + (new\\ max\\ value - new\\ min\\ value)\\times min}{new\\ max\\ value - new\\ min\\ value}$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$x$ is the inverse scaled value\n",
        "$x'$ is the scaled value\n",
        "$min$ is the minimum value of the original data\n",
        "$max$ is the maximum value of the original data.<br/>\n",
        "$new\\ max\\ value$ and $new\\ min\\ value$ is the new range that we want to scale the data to. For example: $(1,0)\\ or\\ (1,-1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ3IIvIhvHaz",
        "outputId": "456f6e77-dd94-4cb6-ab74-4610d322bcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# make a prediction \n",
        "# select the number of obersvtions for prediction\n",
        "n_obs = len(test)\n",
        "yhat = model.predict(test_X[-n_obs:], verbose=1)\n",
        "\n",
        "\n",
        "# invert scaling \n",
        "scaled_y = pd.DataFrame(test_y)\n",
        "scaled_yhat = pd.DataFrame(yhat) ## ravel () converting into 1D array\n",
        "#obtain the min and max from the training set\n",
        "unscaled_train = pd.DataFrame(series_supervised[:len(train)])\n",
        "#new feature range\n",
        "new_max_value = 1 \n",
        "new_min_value= 0\n",
        "feature_range = new_max_value - new_min_value\n",
        "\n",
        "def transform_column(column):\n",
        "    min_value = min(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    max_value = max(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    return ((max_value - min_value) * (new_min_value + column) + (feature_range  * min_value)) / feature_range \n",
        "    \n",
        "# invert scaling for actual\n",
        "inv_scale_y = scaled_y.apply(transform_column, axis=0)\n",
        "inv_scale_y = inv_scale_y.values\n",
        "# invert scaling for forecast\n",
        "inv_scale_yhat = scaled_yhat.apply(transform_column, axis=0)\n",
        "inv_scale_yhat = inv_scale_yhat.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(inv_scale_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UqsUebr1EW6w",
        "outputId": "7b82872d-d57f-4330-eb04-42df14eea60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0\n",
              "0    3718.221536\n",
              "1    3741.556734\n",
              "2    3364.042301\n",
              "3    3333.536720\n",
              "4    3312.214262\n",
              "..           ...\n",
              "375  1659.440731\n",
              "376  1662.711432\n",
              "377  1707.494884\n",
              "378  1725.420844\n",
              "379  1620.632599\n",
              "\n",
              "[380 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3177619c-302f-4188-8724-7744ac1bf03e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3718.221536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3741.556734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3364.042301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3333.536720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3312.214262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>1659.440731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>1662.711432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1707.494884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>1725.420844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>1620.632599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>380 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3177619c-302f-4188-8724-7744ac1bf03e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3177619c-302f-4188-8724-7744ac1bf03e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3177619c-302f-4188-8724-7744ac1bf03e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqftbPYxvEE5"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for actual \n",
        "df = pd.DataFrame(series.iloc[-len(test)-steps_ahead:,-1])\n",
        "n_vars = df.shape[1]\n",
        "columns = df.columns\n",
        "cols, names = list(), list()\n",
        "for i in range(0, steps_ahead):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "        names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "    else:\n",
        "        names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "# put it all together\n",
        "agg = pd.concat(cols, axis=1)\n",
        "agg.columns = names\n",
        "agg.dropna(inplace=True)\n",
        "agg = agg.iloc[:-1]\n",
        "#drop all the variables that we don't want to predict\n",
        "#agg.drop(columns=vars_to_drop, inplace=True)\n",
        "agg = agg.to_numpy()\n",
        "inv_y = np.add(inv_scale_y,agg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWAqc4iTkxvn"
      },
      "source": [
        "* To invert the differencing of time series for multistep prediction:<br/>\n",
        "The equation is given by $$\n",
        "\\hat x_{t+h|t}=x_t+(\\widehat{\\Delta x_{t+1}}+\\dots+\\widehat{\\Delta x_{t+h}}).\n",
        "$$ <br/>\n",
        "where: <br/>\n",
        "$\\hat x_{t+h|t}$ is the predicted value of the time series x at time $t$+h, given the value of the time series at time $t$.<br/>\n",
        "$x_t$ is the value of the time series $x$ at time t.<br/>\n",
        "${\\Delta x_{t+1}}$ is the difference between the value of the time series $x$ at time $t+1$ and the value of the time series at time t.<br/>\n",
        "${\\Delta x_{t+2}}$ is the difference between the value of the time series $x$ at time $t+2$ and the value of the time series at time $t+1$.<br/>\n",
        "${\\Delta x_{t+h}}$ is the difference between the value of the time series $x$ at time $t+h$ and the value of the time series at time $t+h-1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSJErK0WDkX4"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for forecast\n",
        "# to invert the diffrenced predicted values,the the predicted differenced value is added\n",
        "# to previous predicted diffenced values and last available observation in test set(Xt) as explained above\n",
        "originalSeries_supervised = series_to_supervised(series, series.columns, n_in=window_size, n_out=steps_ahead, dropnan=True)\n",
        "current_timestep = 1\n",
        "originalSeries_xt = originalSeries_supervised[['BORE_OIL_VOL(t)','BORE_OIL_VOL(t+1)']]\n",
        "# A predicted value at any given step ahead is a result of the previous cumulative differnced predicted values and current time step\n",
        "col = []\n",
        "inv_yhat_cum = np.cumsum(inv_scale_yhat, axis=1)\n",
        "\n",
        "for i in range(n_obs):\n",
        "    #.ravel() flattens the series into a one-dimensional array\n",
        "    inverted_diff_yhat = originalSeries_xt[-n_obs:].values[i] + inv_yhat_cum[i]\n",
        "    col.append(inverted_diff_yhat)\n",
        "col = pd.DataFrame(col)\n",
        "inv_yhat = col.values # convert df to NumpyArray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqrt(mean_squared_error(inv_scale_y, inv_scale_yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsKsb0qwWlId",
        "outputId": "8203c832-1f9c-4039-e33f-b9c5e71c2d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "241.86829147086527"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(inv_scale_y, inv_scale_yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9QW-H4qWt5w",
        "outputId": "1800d786-ea1f-46f9-917e-607c579dbb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8927672890049398"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51SnY7n5e0nx",
        "outputId": "425c2666-877c-40be-e76b-8da4869f1ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Average scores for the vector output 2 steps ahead:\n",
            "\n",
            "Test RMSE: 517.58664\n",
            "Test MAE: 304.76658\n",
            "Test r2: 0.45559\n",
            "Test wMAPE: 13.34431 \n",
            "Test SMAPE: 16.53452 \n"
          ]
        }
      ],
      "source": [
        "# Performance evaluation\n",
        "rmse_test, RMSPE_test, MAE_test, MAPE_test, r2_test, wMAPE_test, SMAPE_test  = [], [], [], [], [], [], []\n",
        "# calculate the score for each day\n",
        "\n",
        "for i in range(test_y.shape[1]):\n",
        "    result_rmse = sqrt(mean_squared_error(inv_y[:,i], inv_yhat[:,i]))\n",
        "    result_RMSPE = RMSPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAE = mean_absolute_error(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAPE = MAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_r2 = r2_score(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_wMAPE = wMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_SMAPE = SMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "\n",
        "    rmse_test.append(result_rmse)\n",
        "    RMSPE_test.append(result_RMSPE)\n",
        "    MAE_test.append(result_MAE)\n",
        "    MAPE_test.append(result_MAPE)\n",
        "    r2_test.append(result_r2)\n",
        "    wMAPE_test.append(result_wMAPE)\n",
        "    SMAPE_test.append(result_SMAPE)\n",
        "    \n",
        "## calculate overall score\n",
        "print(\"The Average scores for the vector output {} steps ahead:\\n\".format(steps_ahead))\n",
        "print('Test RMSE: %.5f' % np.mean(rmse_test))\n",
        "#print('Test RMSPE: %.5f' % np.mean(RMSPE_test)) because of that the denominator (actual) has some zero values\n",
        "print('Test MAE: %.5f' % np.mean(MAE_test))\n",
        "#print('Test MAPE: %.5f' % np.mean(MAPE_test)) #because of that the denominator (actual) has some zero values\n",
        "print('Test r2: %.5f' % np.mean(r2_test))\n",
        "print('Test wMAPE: %.5f ' % np.mean(wMAPE_test))\n",
        "print('Test SMAPE: %.5f ' % np.mean(SMAPE_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4KkEyXsJvDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "870b7b56-869a-4336-cab9-05d16b5c5a06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1224x1080 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAANaCAYAAACUey/mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde3yU5Z3///cnISHJHQ7J3COEAGYCCIIKSuqJqgjVRREtbrXU/lqwdmn72PrVHtSyayuy9aeutpbutvbrrj+1qwUPdbduF/e32pZ12y+WglpXbXdlychBwSQcM0PO1/ePuTNMQhIm52Tyej4e88jMfd8zuaKY9s11va/bnHMCAAAAAAB9L2uwBwAAAAAAQKYidAMAAAAA0E8I3QAAAAAA9BNCNwAAAAAA/YTQDQAAAABAPyF0AwAAAADQT04aus1sppm9kfI4Yma3mlmxmb1kZu8GX4uC683Mvm9mO8zsTTM7p/9/DAAAAAAAhh7rzn26zSxb0l5J50n6c0kHnHP3mdk3JBU55+4wsysl3SzpyuC69c6587r6XN/3XVlZWQ9/hIEVi8Xked5gDwMAAAAAMtpwyl7bt2+vds6FOzo3qpuftVjS/zjn3jOzayQtDI4/IWmzpDskXSPpxy6R5l81s/FmVuKc+6CzDy0rK9O2bdu6OZTBsXnzZi1cuHCwhwEAAAAAGW04ZS8ze6+zc93tdK+QtCF4PiElSO+TNCF4Xippd8p79gTHAAAAAAAYUdIO3WaWK+lqSc+2PxfMaqe/Tj3xeavNbJuZbauqqurOWwEAAAAAGBa6M9N9haTXnHP7g9f7zaxEkoKvHwbH90qakvK+ycGxNpxzjzjnKpxzFeFwh0vfAQAAAAAY1roTuj+l40vLJekFSSuD5ysl/Szl+GeDXczPl3S4qz43AAAAAACpYvVNqmvq1mLqISutjdTMzJN0maQvpBy+T9IzZnaTpPckXR8c36TEzuU7JMUl3dhnowUAAAAAZISGphbtPhhXZVVMldUx7ayOqbK6VpXVMe0/Uq/Pzs7VksEeZB9IK3Q752KSQu2O1Sixm3n7a50StxMDAAAAAIxgLS1OHxypSwTrmlgQsBPBevfBY2puOT6bXezlKuJ7umhGWBHfU+HRTjcEH1a6e8swAAAAAACSnHM6GG9UZXWtdgaz1qmP+qaW5LUFudmK+J7OKB2nq+dOUiTsKeIXKhLyNK4gp83nbt68Z6B/lH5B6AYAAAAAnFSsvknRmiBMt1kSHtPhY43J60ZlmaaGClTue7pohp8I1b6n8rCnU8aMlpkN4k8x8AjdAAAAAABJJ+9Zpyodn6+I7+nquZNU5nsq9z1FfE+Ti/I1Krs7e3ZnNkI3AAAAAIwgLS1O+47UHQ/V3ehZl/ueImFPpxZ7ys/NHsSfYvggdAMAAABAhkntWVdWx5OhemdVTNGamOoaj/es83MSPes5peO0bO4kRYIZ64jvaXxB7iD+FJmB0A0AAAAAw1S8oen4pmU96FlHfE8Txo68nvVAInQPsK1bt2rTpk1au3btsPpsAAAAAIOjsblFuw/Ek+F6Z0rA3nekrs21k8blKRL2tGxuiSJ+IT3rIYDQPcC2bt2qu+++u99Cd399NgAAAID+05Oe9Udn+G2WgpeF6FkPRRkXupubm9Xc3KzcXLoHAAAAAIaWg7GG5PJvetYjw7BfX7Bq1SpVVFTon/7pnzRnzhzl5eXpiiuuUEVFhf7lX/5Fs2fPVkFBgZYuXaoDBw5ox44duvTSS+V5nioqKvTmm2+2+bxHH31Us2fPVn5+vnzf1yWXXKK33347eb6hoUG33367pkyZotGjR2vu3LnatGlTWmN9/PHHdfPNN0uSzExmpoULFybPv/XWW1q6dKnGjBmjMWPG6LrrrtO+ffuS5xsbG/X1r39dU6dO1ejRozVp0iQtX75cDQ0NJ/1sAAAAAAMj3tCkt98/rJ+/+b7+9pfv6qvPvKHlP/yN5q37N539Vy/pTx/+P/r6s7/X//73nfrjB0dVOj5f/895p+qe5WfoJ392nl5ds1jvrPsTbbrlIv3ghnP0tctn6tpzJuvsqUUE7mEoI2a6o9Gobr/9dn3rW9/SxIkTdd9992nXrl361re+pW9/+9uKx+O6+eabtXr1akWjUf3Zn/2Zbr/9dq1Zs0YrVqzQ22+/LTPTK6+8oi9+8Ytat26dLrjgAh05ckRbtmzR4cOHk9/rrrvu0v/8z//o7rvv1rRp0/TMM8/o6quv1rZt2zRv3rwux7l06VJ97Wtf03e+8x1t2bJFkjR27FhJ0o4dO7RgwQJVVFToySefVFNTk775zW9q2bJl2rp1q8xM9957r5566indd999ikQi2rdvnzZt2qTm5uYuPxsAAABA3+pJz/qqs9r2rEuL8pVDzzrjZUTorqmp0csvv5wMvU8++aQ2b96sLVu2aNq0aZKkN998Uw888ICeeOIJffazn5WU2EZ/6dKl+uMf/6jTTz9dW7du1VlnnaU1a9YkP/vqq69OPv/FL36hV199VZs3b9Yll1wiSbr88sv13//937rnnnv07LPPdjnOcDissrIySdL555/f5tzdd9+tiRMn6sUXX0wujT/rrLM0a9Ysbdq0SUuXLtXWrVt1ww03aOXKlcn3XX/99ZKk/Pz8Tj8bAAAAQPe1tDjtP1qnyqpYypLwxGPXgXibnnVRQY4ivqcF032Vh+lZ47iMCN2lpaUnzDKXlZUlA7ckTZ8+XZK0aNGiE47t3btXp59+uubNm6fbb79dX/nKV7R8+XKdf/75bbrhL7/8soqLi7VgwQI1NTUljy9evFiPP/54r36Gl19+WStXrlRWVlbysyORiMrKyrRt2zYtXbpU8+bN08MPP6wJEyZoyZIlOvPMM9naHwAAAOilznrW79XEdayxOXlda8969qSxWnpmSSJYhz1FQp6KPJZ9o2MZEbonTJhwwrHx48e3ed0anlOPtx6rq0ss//jYxz6mxx57TN///ve1fv16FRYW6jOf+Yz++q//Wp7nqbq6WgcOHFBOTs4J3y87u3d/e1VdXa37779f999//wnndu/eLUm68847lZWVpR/+8Ie64447VFpaqttuu0233HJLr743AAAAkOniDU2KVseTwTp15vpQvN39rIsLEruDT/cTodr3VO4Xcj9r9EhGhO6+/IO/cuVKrVy5UlVVVXr++ef1la98RWPGjNF9992n4uJi+b6vF198sc++X6vi4mItX75cn//850845/u+JCkvL0/r1q3TunXr9O677+pHP/qRbr31Vs2cOVNLlizp8zEBAAAAw0n7nnXq44PDbXvWJePyFPG95Ix1Ykl4oSbTs0Yfy4jQ3R/C4bC+8IUv6Pnnn9c777wjKbGM/MEHH1RhYaFmzZrVo89NnV3Py8tLHl+8eLHefvttzZ8/P62/RJgxY4YefPBB/eAHP9A777yjJUuWdPrZAAAAQKboSc/6wmnHe9ZlIU9lfoEKcolCGBj8SUtx11136cCBA1q4cKF839frr7+uf//3f9d9990nSbrsssv0kY98RJdddpnuuOMOzZkzR0eOHNEbb7yhuro63XvvvSf9Hq1hff369Vq0aJHGjh2rmTNnau3atTr33HO1dOlSfe5zn5Pv+9q7d69eeuklrVq1SgsXLtTy5cs1f/58nX322crPz9dzzz2npqYmXXzxxV1+NgAAADDcHIo3tNkRvHWH8Gh1rE3POi8nSxG/ULNL6FljaCJ0p/jIRz6ihx56SBs3btTRo0d16qmnau3atcnOtJlp3bp1+s1vfqPvfe972rVrl4qLizVv3rzkPbJP5qKLLtJtt92m9evXa82aNbr44ou1efNmnXbaaXr11Vd15513avXq1Tp27JhKS0u1ePHi5IZvF154oZ5++mk98MADamlp0ezZs/XTn/5UFRUVXX42AAAAMBT1pGd94bRQ0LFOhOsJY/KUlUXPGkOXOedOflU/q6iocNu2bRvsYaRl8+bNWrhw4WAPAwAAABgWGptbtOfgsUSorkqvZ936oGc9sg2n7GVm251zFR2dY6YbAAAAQK8457TvyPGedbRdz7oppWc9PuhZXzAtlJit9gsTXWt61shQ/KnuQ845NTc3d3o+OzubWwwAAABg2Opuz/r0krG6kp41RjhCdx964okndOONN3Z6/rHHHtOqVasGbkAAAABANx1raFa0JiVUVyX61pXVMR1M6Vln07MG0kLo7kPLli3T7373u07PRyKRARwNAAAA0LGe9KyTM9bBY0pxAT1rIA2E7j4UCoUUCoUGexgAAACAnHPaf6ReO4NZ6tQl4e171uPyc1QepmcN9Af+CwIAAACGsY561q2P9j3rspCnWSVjdMWZE5PButynZw30J0I3AAAAMMT1pGd9AT1rYEggdAMAAABDQGvPOhrsCF6Zsiz8/XY964ljEz3rK84sCZaD07MGhipCNwAAADBAetKzPn9aSJFQcMst31NZyJM3mv8bDwwXaf3XambjJf29pDMkOUmfk/Rfkp6WVCYpKul659xBS9yIer2kKyXFJa1yzr3W5yMHAAAAhqhD8YY23erWznW0JqZ4Az1rYCRJ96/I1kv6V+fcJ8wsV1KBpL+Q9Avn3H1m9g1J35B0h6QrJM0IHudJejj4CgAAAGSMznrW0Zq4DsQaktdlZ5mmFOUr4ns6vzykSNhLLgmfOJaeNZDpThq6zWycpIslrZIk51yDpAYzu0bSwuCyJyRtViJ0XyPpx845J+lVMxtvZiXOuQ/6fPQAAABAP2pK3s86/Z71kjMmJkN1me9pSlGBckfRswZGqnRmuiOSqiQ9ZmZzJW2XdIukCSlBep+kCcHzUkm7U96/JzhG6AYAAMCQ075nHU1ZEr6rpm3PemzeKJWHCxMz1j49awAnl85vhlGSzpF0s3Put2a2Xoml5EnOOWdmrsN3d8LMVktaLUlTp07tzlsBAACAbjscbzy+gVk6PeuJY7RkzsRExzrsKeIXqqggR4ktjAAgPemE7j2S9jjnfhu8fk6J0L2/ddm4mZVI+jA4v1fSlJT3Tw6OteGce0TSI5JUUVHRrcAOAAAAdKSuMehZV7UuBz/+oGcNYDCcNHQ75/aZ2W4zm+mc+y9JiyW9EzxWSrov+Pqz4C0vSPqymW1UYgO1w/S5AQAA0Fe607OeMHa0Ir6nP5lzvGcdCdOzBjBw0i2e3CzpqWDn8p2SbpSUJekZM7tJ0nuSrg+u3aTE7cJ2KHHLsBv7dMQAAADIeM45fXi0PtgR/HiwpmcNYLhJ67eQc+4NSRUdnFrcwbVO0p/3clwAAAAYAdr3rFMfqT3r0aOyFPE9zZxAzxrA8MJf/QEAAKBf9aRnfV4kpIhfoIhfqEjYUwk9awDDFKEbAAAAvdbU3KK9h44ldwRPDdZ7Dx1rcy09awAjCaEbAAAAaemqZ737QFyNzW171pFwoc6NFCdCdfAo8z0V0rMGMILwGw8AAABtHD7WeDxUt1sSTs8aALqH0A0AADACte9ZR1OCdU1KzzrLpCnFBYr4ns6NFAfLwelZA0C6CN0AAAAZqque9fuHj8kdXw2e7FlfPmfi8Q3MfE9Ti+lZA0BvELoBAACGsdaedWqgTnSua7WrXc96THA/a3rWADBw+O0KAAAwDHTWs45WxxRL6VnnjspSJORpxiljgllrL7lDeLGXS88aAAYYoRsAAGCIqGts1ns1cVVW156wJDydnnWZX6BJ4/LpWQPAEELoBgAAGEAd9ayjNYkl4e171qeMae1ZTwiWgtOzBoDhhtANAADQx5xzqjpa3+ZWW+n0rMtCniLhxHJwetYAkBn4TQ4AANBDh481Jm+1dTxgJzrX9KwBABKhGwAAoEvd6VlPLkr0rCtOLVZ5+Pju4PSsAWDkInQDAIARr7nFae/BY9pZXXvCrbfS7VlPKc7X6FHZg/dDAACGJEI3AAAYETrrWUdrYtpVE1dDc0vy2jF5o1Tue/pIWZEi/hR61gCAHuN/NQAAQEbpbs96erhQl82eoEiwiVnE9xSiZw0A6COEbgAAMOwc71mnhOrgeXVtej3rknH5yqZnDQDoZ4RuAAAwJHWnZx0OetYfO31CMlSXhz1NKS6gZw0AGFSEbgAAMGicc6qqrW+zI3jrkvATetajR6k83LZnHQl5KvMLNCYvZxB/CgAAOkfoBgAA/e5IXWMyWKf2rKPVcdXWNyWvyx2VpbJQgaaFE7PW5T49awDA8EboBgAAfaKusVm7DsS1s6p7PevW5eAR39Ok8fSsAQCZhdANAADSltqzbr9D+N5D9KwBAGiP0A0AANrobs86EvY0/9QifWL+5ESw9gvpWQMAECB0AwAwQh2pS7mfdUrArqyOpdWzLgt58gvpWQMA0BVCNwAAGSzdnrWZNLkoXxG/UPNPLaJnDQBAHyF0AwAwzDW3OL1/6FhiCXhVbdo967LWnrWf6Fnn5dCzBgCgrxG6AQAYBk7oWdfEks/fo2cNAMCQRegGAGAISbtnnZ2lU0OJ224tOv2URM/aL1TEp2cNAMBQklboNrOopKOSmiU1OecqzKxY0tOSyiRFJV3vnDtoif+VXy/pSklxSaucc6/1/dABABie6puatasmnlwC3jpjvbM6pura+uR19KwBABj+ujPTfalzrjrl9Tck/cI5d5+ZfSN4fYekKyTNCB7nSXo4+AoAwIjRnZ61Xzha5b6nxbNOUSRMzxoAgEzSm+Xl10haGDx/QtJmJUL3NZJ+7Jxzkl41s/FmVuKc+6A3AwUAYKhxzqm6tiG5K/jO6s571oWjR6k86Fn/6TmTVR6E6zLf01h61gAAZKx0Q7eT9G9m5iT9b+fcI5ImpATpfZImBM9LJe1Oee+e4BihGwAwLB2ta0z2qlt71tFgI7Oj9KwBAEAX0g3dH3XO7TWzUyS9ZGZ/TD3pnHNBIE+bma2WtFqSpk6d2p23AgDQ57rTsy4dn6+I7+nac0oTHetwocrpWQMAgA6kFbqdc3uDrx+a2T9KOlfS/tZl42ZWIunD4PK9kqakvH1ycKz9Zz4i6RFJqqio6FZgBwCgJ1p71qk7gu8MlobvPXhMLSfpWUd8T1PpWQMAgG44aeg2M09SlnPuaPD8cknrJL0gaaWk+4KvPwve8oKkL5vZRiU2UDtMnxsAMFC627OO+J7OnlKka8+mZw0AAPpeOjPdEyT9Y9BDGyXpJ865fzWz30l6xsxukvSepOuD6zcpcbuwHUrcMuzGPh81AGDEO1rXqGh1XDura9vMXHfZs551yvHbboU9hQtH07MGAAD96qSh2zm3U9LcDo7XSFrcwXEn6c/7ZHQAgBGts551ZU1MVUfpWQMAgKGvN7cMAwCg17rXs85VxPd06cxwclfw8jA9awAAMHQRugEA/S61Zx1NCdWJW2/F1dBEzxoAAGQmQjcAoM+k27POyTadGvKCWWt61gAAIHMRugEA3VLf1KzdB+LaWdV+OXjXPeuyIFiX+4UqLaJnDQAARgZCNwDgBB31rFsfew7G6VkDAACkidANACOUc041sYbk8u+uetZebrYiYU9zp4zXx88uVbl/vGc9Lp+eNQAAQGcI3QCQ4VJ71tHqeDJY76yO6WgdPWsAAID+ROgGgAzQnZ71pHH5Kg97Wn52aTJYl/uFmjQ+T6OyswbxpwAAAMg8hG4AGCZaWpzeP3y8Z50asLvqWZf5XrAcvFCnhuhZAwAADCRCNwAMIZ31rKPVcVXWxOhZAwAADDOEbgAYBLX1TYq2LgGvinXZs55aXKCIX6hLZoZTloN7Co+hZw0AADDUEboBoJ+071lHa44vCf8wjZ51xPdUOj6fnjUAAMAwRugGgF7oTs865CV61pecFlYkTM8aAABgJCB0A8BJOOd0IOhZt+4IXpkye13fWc963iRFwolgHQl5GldAzxoAAGCkIXQDQKCznnVldUxH6FkDAACgBwjdAEaUhqYW7ToQD8J0bZsl4R31rCO+p2vmBT3rYEk4PWsAAACki9ANIOO071mnPnYfoGcNAACAgUPoBjAsdadnXZCbrYjv6czScbpmLj1rAAAADBxCN4AhLVbfdMJsdaJzXdtlz7osFPSsw55OoWcNAACAQULoBjDo0u1ZS1LpeHrWAAAAGD4I3QAGREuL0wdH6pK7gu/somddHPSsLz4tnNwVPBL2dGqxp/xcetYAAAAYPgjdAPpMRz3raEq4pmcNAACAkYbQDaDb0u1Zj8oyTQ0VqNz3dNEMPxGq6VkDAABgBCF0A+hQa886mhqqg771/iOd96zLWpeD+54mF9GzBgAAwMhG6AZGsK561nsOHlNzStG6tWd90Qx61gAAAEC6CN1AhnPO6WC8MRGqq2InLAtP7Vnn5yR61meUjtPVcycldgcPHuMLcgfxpwAAAACGJ0I3kCE66lm3Pg4fa0xe11nPOuJ7mjCWnjUAAADQlwjdwDDS0NSi3QfjwXLwrnvWk8blKRL2tGxuiSJ+IT1rAAAAYBCkHbrNLFvSNkl7nXNXmVlE0kZJIUnbJX3GOddgZqMl/VjSfEk1kj7pnIv2+ciBDNWmZ10TS/atK6tj2n2SnnXroyxEzxoAAAAYCroz032LpD9IGhu8vl/SQ865jWb2I0k3SXo4+HrQOTfdzFYE132yD8cMDHs96VnPKR2nZfSsAQAAgGElrdBtZpMlLZV0j6SvWqL0uUjSDcElT0haq0ToviZ4LknPSfpbMzPnnBMwwsTqmxStCcJ0myXhHfSsiwsU8T19dLqvSNgLdggvpGcNAAAADGPpznR/T9LtksYEr0OSDjnnmoLXeySVBs9LJe2WJOdck5kdDq6v7pMRA0NMX/SsS4vylUPPGgAAAMg4Jw3dZnaVpA+dc9vNbGFffWMzWy1ptSRNnTq1rz4W6BctLU77jtQdD9Vd9KyLCnKCGeuwysP0rAEAAICRLJ2Z7gWSrjazKyXlKdHpXi9pvJmNCma7J0vaG1y/V9IUSXvMbJSkcUpsqNaGc+4RSY9IUkVFBUvPMehSe9aV1fFkqN5ZFVO0Jqa6xo571ledFfSsw54iIU9FHj1rAAAAAAknDd3OuTWS1khSMNP9defcp83sWUmfUGIH85WSfha85YXg9Zbg/C/pc2MoiTek3M+anjUAAACAftSb+3TfIWmjmX1b0uuSHg2OPyrpH8xsh6QDklb0bohA9zU2t2j3gXgyXO9MCdj7jtS1ubZkXJ4ivqerzipJhOqwp4hfqMn0rAEAAAD0UrdCt3Nus6TNwfOdks7t4Jo6Sdf1wdiALvWkZ71gup/sWZeFPJX5BSrI7c3fPQEAAABA50gbGPIOxhqSy7+76lnn5WQp4hdqziR61gAAAACGBkI3hoTUnnU0pWNdWR3ToXjHPesF0/2gY50I1xPG5Ckri541AAAAgKGD0I0B05Oe9dIz6VkDAAAAGL4I3ehTLS1O+4/WqbKq7Wx1ZXVMuw7E2/Ssxwc96wunhxKz1X5homtNzxoAAABAhiDZoEc661m/VxPXscbm5HWtPevZJWOTs9b0rAEAAACMFIRudCre0KRodTwZrDvrWWfTswYAAACADhG6R7j2PevUxweHu+5Ztz6mFBfQswYAAACADhC6R4Du9KzH5eeoPOzpgmn0rAEAAACgt0hRGeRQvKHNjuCtO4RHq2Mn9KzLQp5OLxmjK8+cmAzW5T49awAAAADoS4TuYaYnPesLp4XoWQMAAADAICB0D0GNzS3ac/BYIlRXdd2znjg20bO+8sySYDk4PWsAAAAAGCoI3YPEOad9R9r2rKMpPeumTnrWkVBwyy3fU1nIkzeaf4UAAAAAMFSR2PpZd3vWs0rG6Ap61gAAAACQEQjdfeBYQ7OiNSmhuirRt66sjulgu571lKJ8RXxPF5SHFAl7ySXhE8fSswYAAACATEPo7oYPj9TpjQ+btOM/dqbVs74ipWdd5nuaUlSg3FH0rAEAAABgpCB0d8MLv39f33utXtIfNDZvlMrDhYkZa5+eNQAAAADgRKTDbrjyzBK56kr96eUXqaggR2YsBwcAAAAAdI7Q3Q2TxudrRlG2itnYDAAAAACQBgrGAAAAAAD0E0I3AAAAAAD9hNANAAAAAEA/IXQDAAAAANBPzDk32GOQmVVJem+wx5EmX1L1YA8CAAAAADLccMpepzrnwh2dGBKhezgxs23OuYrBHgcAAAAAZLJMyV4sLwcAAAAAoJ8QugEAAAAA6CeE7u57ZLAHAAAAAAAjQEZkLzrdAAAAAAD0E2a6AQAAAADoJ4TuNJnZ/2dmH5rZW4M9FgAAAADIRGY2xcx+ZWbvmNnbZnbLYI+pt1heniYzu1hSraQfO+fOGOzxAAAAAECmMbMSSSXOudfMbIyk7ZI+7px7Z5CH1mPMdKfJOfeKpAODPQ4AAAAAyFTOuQ+cc68Fz49K+oOk0sEdVe8QugEAAAAAQ46ZlUk6W9JvB3ckvUPoBgAAAAAMKWZWKOmnkm51zh0Z7PH0BqEbAAAAADBkmFmOEoH7Kefc84M9nt4idAMAAAAAhgQzM0mPSvqDc+67gz2evkDoTpOZbZC0RdJMM9tjZjcN9pgAAAAAIMMskPQZSYvM7I3gceVgD6o3uGUYAAAAAAD9hJluAAAAAAD6CaEbAIABZGZ/aWZvm9mbwZK584Ljt5pZwSCMp8zM3uqnz46amd8fnw0AwHAxarAHAADASGFmF0i6StI5zrn6IJDmBqdvlfSkpPhgjQ8AAPQ9ZroBABg4JZKqnXP1kuScq3bOvW9m/0vSJEm/MrNfSZKZXW5mW8zsNTN7Nrhfaevs8V+b2X+a2VYzmx4cv87M3jKz35vZK+2/sZkVmtkvgs/7TzO7JuV0tpn9XTAD/29mlh+8Z5qZ/auZbTez/zCzWcHxZWb2WzN73cxeNrMJwfFQ8P63zezvJVm//ZMEAGCYYCM1AAAGSBCcfy2pQNLLkp52zv17cC4qqcI5Vx3MgD8v6QrnXMzM7pA02jm3Lrju75xz95jZZyVd75y7ysz+U9IS59xeMxvvnDvU7nuPklTgnDsSfP6rkmZIOlXSjuB7v2Fmz0h6wTn3pJn9QtIXnXPvBsvg73XOLTKzIkmHnHPOzD4v6XTn3AIVNdUAACAASURBVNfM7PtK/KXCOjNbKunnksLOuep+/McKAMCQxvJyAAAGiHOu1szmS7pI0qWSnjazbzjnHm936fmSZkv6TeJ2pcpV4raVrTakfH0oeP4bSY8Hofn5Dr69Sfp/zexiSS2SSiVNCM5VOufeCJ5vl1QW/AXBhZKeDcYgSaODr5ODsZcEY6sMjl8s6drgZ/0XMzvY9T8RAAAyH6EbAIAB5JxrlrRZ0uZgdnqlpMfbXWaSXnLOfaqzj2n/3Dn3xWA2eqmk7WY23zlXk3LdpyWFJc13zjUGM+Z5wbn6lOuaJeUrUUE75Jyb18H3/xtJ33XOvWBmCyWt7fQHBgBghKPTDQDAADGzmWY2I+XQPEnvBc+PShoTPH9V0oKUvrZnZqelvO+TKV+3BNdMc8791jn3LUlVkqa0+/bjJH0YBO5LlVhW3inn3BFJlWZ2XfD5ZmZzUz5rb/B8ZcrbXpF0Q3D9FZKKuvoeAACMBMx0AwAwcAol/Y2ZjZfUpESXenVw7hFJ/2pm7zvnLjWzVZI2mFnrku47Jf138LzIzN5UYoa6dTb8gSDQm6RfSPp9u+/9lKR/DmbXt0n6Yxrj/bSkh83sTkk5kjYGn7tWiWXnByX9UlIkuP7uYMxvS/o/knal8T0AAMhobKQGAMAwkrrh2mCPBQAAnBzLywEAAAAA6CfMdAMAAAAA0E+GRKfb931XVlY22MNISywWk+d5gz0MAAAAAMhowyl7bd++vdo5F+7o3JAI3WVlZdq2bdtgDyMtmzdv1sKFCwd7GAAAAACQ0YZT9jKz9zo7R6cbAAAAAIB+QugGAAAAAKCfpB26zSzbzF43s58HryNm9lsz22FmT5tZbnB8dPB6R3C+rH+GDgAAAADA0Nadme5bJP0h5fX9kh5yzk2XdFDSTcHxmyQdDI4/FFwHAAAAAECXYvVNemvvYf3z79/XB7Utgz2cPpHWRmpmNlnSUkn3SPqqmZmkRZJuCC55QtJaSQ9LuiZ4LknPSfpbMzPHvckAAAAAYMRraGrR7oNxVVbFVFkd087qmCqra1VZHdP+I/XJ6z45M1efGsRx9pV0dy//nqTbJY0JXockHXLONQWv90gqDZ6XStotSc65JjM7HFxf3ScjBgAAAAAMaS0tTh8cqQuCda0qq+PJYL374DE1txyfky32chXxPX10eljlYU8RP/HY9c72QfwJ+s5JQ7eZXSXpQ+fcdjNb2Fff2MxWS1otSVOnTu2rjwUAAAAADADnnA7GG1VZXaudwax16qO+6fjy8PycbEV8T3NKx2nZ3EnJYB3xPY0vyO3w8/f/lw3Uj9Kv0pnpXiDpajO7UlKepLGS1ksab2ajgtnuyZL2BtfvlTRF0h4zGyVpnKSa9h/qnHtE0iOSVFFRwdJzAAAAABiCYvVNitYEYbrNkvCYDh9rTF43Kss0tbggmLX2FQlmrcv9Qk0YO1qJlvLIc9LQ7ZxbI2mNJAUz3V93zn3azJ6V9AlJGyWtlPSz4C0vBK+3BOd/SZ8bAAAAAIaudHvWkjRpXJ4iYU/L5pYo4hcq4hco4hdqclG+crK5K3V76Xa6O3KHpI1m9m1Jr0t6NDj+qKR/MLMdkg5IWtG7IQIAAAAAequlxWnfkbrjoboq1mnPuqggp8OedVnIU35u9iD+FMNPt0K3c26zpM3B852Szu3gmjpJ1/XB2AAAAAAA3dBRzzpaE9POqsTXusaOe9ZXnRX0rMOeIiFPRV7HPWt0X29mugEAAAAAgyDe0HR80zJ61kPasA/da9eu1d13363p06fr3XffPeH8jBkztGPHDt11111au3Ztm3ORSETRaFTvvvuupk+f3ubc5s2bdemll3b4PW+66Sb9/d///UnHtnXrVm3atOmE79sX+vOzAQAAAAy+xuYW7T4QT4brnSkBe9+RujbXlozLU8T3dNVZJYlQHfboWQ8Rwz50S1JeXp4qKyu1bds2VVRUJI//7ne/UzQaVV5e3gnv2bJli6LRqCRpw4YN+uY3v9nhZz/11FMqLy9Pvn7ttde0ZMmStMa1detW3X333f0WuvvrswEAAAAMjJ70rBdM95M967KQpzK/QAW5GRHtMlJG/JvxPE/nnHOONm7c2CZ0b9y4UYsWLdL27SfeVH3Dhg3yPE9nnHFGl6H7rLPO0hlnnJF8XVdX1yaEAwAAAMDJHIw1JJd/t4bqjnrWeTlZiviFmjOJnnWmyIjQLUkrVqzQ2rVr9cADD8jM5JzTM888o3Xr1p0Qupubm/XMM8/o6quv1sKFC/WFL3xBv//97zV37tw+G8/jjz+um2++WZKSPYlLLrlEmzdvliS99dZbuuOOO/TKK69IkpYsWaK/+Zu/0cSJEyVJjY2NWrNmjZ555hnt379foVBI5513np5++mn95Cc/6fKzAQAAAAy8jnrWlcH9rQ/FO+5ZL5juBx3rRLieMCZPWVn0rDNJxoTua6+9Vl/60pf061//WhdddJH+4z/+Q1VVVbr22mt12223tbn2V7/6lfbv368VK1boox/9qL785S9rw4YNHYbu5uZmNTU1tXntnDvphgNLly7V1772NX3nO9/Rli1bJEljx46VJO3YsUMLFixQRUWFnnzySTU1Nemb3/ymli1bpq1bt8rMdO+99+qpp57Sfffdp0gkon379mnTpk1qbm7u8rMBAAAA9J+e9KyXnknPeiTLmNA9fvx4LVmyRBs3btRFF12kjRs3asmSJRo3btwJ127YsCF5fW5uri6//HJt3LhR99577wlhet68eSe8/7HHHtOqVau6HE84HFZZWZkk6fzzz29z7u6779bEiRP14osvKjc3sUTkrLPO0qxZs7Rp0yYtXbpUW7du1Q033KCVK1cm33f99ddLkvLz8zv9bAAAAAC909qzjqbsCN762HUg3qZnPT7oWV84PZSYrfYLE11retYIZNSfghUrVujWW2/Vd7/7XT333HP6/ve/f8I1DQ0Nev7557V8+fJk4F2xYoU+85nPaMuWLbrwwgvbXL9x40ZNmzYt+Xr79u1atmxZr8b58ssva+XKlcrKykrOokciEZWVlWnbtm1aunSp5s2bp4cfflgTJkzQkiVLdOaZZ7KdPwAAANCHutuznl0yNjlrTc8a6cqo0H311Vfr85//vP7yL/9SsVisw3D84osv6tChQ7ryyit16NAhSdLChQs1evRobdiw4YTQPWfOnDYbqdXW1ioUCvVqnNXV1br//vt1//33n3Bu9+7dkqQ777xTWVlZ+uEPf6g77rhDpaWluu2223TLLbf06nsDAAAAI0m8oUnR6ngyWKfOXKf2rLPpWaOfZFTo9jxPV111lR566CFdd9118jzvhGs2bNggSbruuutOOPfss8/qe9/7nrKzs/t1nMXFxVq+fLk+//nPn3DO931JidugrVu3TuvWrdO7776rH/3oR7r11ls1c+bMtG9ZBgAAAIwEnfWsozUxfXC4655162NKcQE9a/SLjArdkvSlL31J9fX1+uIXv3jCuVgspn/+53/Wpz71Ka1evbrNuddff11f/epX9ctf/lKXXXZZn4yldfl6XV1dm3uFL168WG+//bbmz5+f1pLxGTNm6MEHH9QPfvADvfPOO8kuekefDQAAAGSilhan/UfrVFl18p71uPwclYc9XTCNnjUGX8b9iVu4cKEWLlzY4bmf/exnisfjuuWWW3Teeee1ObdgwQLdc8892rBhQ5vQ/eabb6q2tjb5+p133tGECRN0+umnn3Qss2bNkiStX79eixYt0tixYzVz5kytXbtW5557rpYuXarPfe5z8n1fe/fu1UsvvaRVq1Zp4cKFWr58uebPn6+zzz5b+fn5eu6559TU1KSLL764y88GAAAAhrPUnnU0ZeY6Wh3Tscbm5HV5OVkqC3k6vWSMrjxzYjJYl/v0rDG0ZFzo7sqGDRs0Y8aMEwK3JOXk5Oj666/XT37yEz388MPJ45/+9KdPuHbx4sV6+eWXT/r9LrroIt12221av3691qxZo4svvlibN2/WaaedpldffVV33nmnVq9erWPHjqm0tFSLFy/W9OnTJUkXXnihnn76aT3wwANqaWnR7Nmz9dOf/lQVFRVdfjYAAAAw1PWkZ33htBA9awxL5pw7+VX9rKKiwm3btm2wh5GWzZs3dzqTDgAAACChsblFew4eS4TqqrbLwdv3rCeOzUvuCF5OzxqB4ZS9zGy7c66io3MjaqYbAAAAQN9xLnE/64561rsPxNXURc+6LAjWZSFP3mhiCTIXf7p7yDmn5ubmTs9nZ2dzX20AAABkhEPxhuSO4JX0rIFuIXT30BNPPKEbb7yx0/OPPfaYVq1aNXADAgAAAHqhfc+6sjoefI3pYAc967JQgS4oD7VZEj5xLD1roD1Cdw8tW7ZMv/vd7zo9H4lEBnA0AAAAwMn1pGd9xZkl9KyBXiB091AoFFIoFBrsYQAAAABtOOe0/0i9dgaz1KlLwne161mPzRul8nBhYsY62MiMnjXQt/gvCQAAABiGutuznlUyRlek9Kwjvqeighz2IQL6GaEbAAAAGKKONTQrWpMSqqtinfaspxTlK+J79KyBIYbQDQAAAAyijnrW0ZrEDPb7nfSsl5yR0rMOe5pSVKDcUfSsgaGI0A0AAAD0s570rM+nZw1kBP6rBQAAAPrIoXhDmx3BWzvX0ZqY4g3He9ajR2Up4nuaOXGMlpwxMXEv67CniF9IzxrIMCcN3WaWJ+kVSaOD659zzt1lZo9LukTS4eDSVc65NyzxG2K9pCslxYPjr/XH4AEAAICB1pOe9fn0rIERK52Z7npJi5xztWaWI+nXZvZicO4259xz7a6/QtKM4HGepIeDrwAAAMCw0JTsWQez1SnLwtv3rCeMHU3PGkCnThq6nXNOUm3wMid4uM7foWsk/Th436tmNt7MSpxzH/R6tAAAAEAf6ahnHa1JhOxdNR33rM9r7VmnPOhZA+hKWr8hzCxb0nZJ0yX9wDn3WzP7kqR7zOxbkn4h6RvOuXpJpZJ2p7x9T3CM0A0AAIABdzjeeDxYp9OznjBGS+bQswbQN9IK3c65ZknzzGy8pH80szMkrZG0T1KupEck3SFpXbrf2MxWS1otSVOnTu3msAEAAIDjWnvW0eRy8OOPA7GG5HXZWabJQc/6vPLiYDl4oSJhTyX0rAH0g26thXHOHTKzX0la4px7MDhcb2aPSfp68HqvpCkpb5scHGv/WY8oEdZVUVHR1XJ1AAAAoEc96z+ZM5GeNYBBlc7u5WFJjUHgzpd0maT7W3vawW7lH5f0VvCWFyR92cw2KrGB2mH63AAAAEiHc04fHq0PdgQ/Hqw76lmP6aRnXeZ7KqRnDWCISOe3UYmkJ4Jed5akZ5xzPzezXwaB3CS9IemLwfWblLhd2A4lbhl2Y98PGwAAAMNZRz3raPC8s571n7T2rINwXezl0rMGMOSls3v5m5LO7uD4ok6ud5L+vPdDAwAAwHBW1xjcz7qq6551lklTigsU8T2dG6FnDSCzsO4GAAAAPZbas27/2HvoWJtrTxnT2rOeECwFL1TE9zS1mJ41gMxF6AYAAECXuupZ7z4QV2PziT3rcyPF9KwBQIRuAAAABA7HG1VZE4TqdkvCU3vWuaOyFAl5Ou0UetYAcDKEbgAAgBGks551tDqmmi561qmz1pPG5dOzBoA0EboBAAAyTFNzi/YeOpYI1VXp9awvp2cNAP2C0A0AADAMpfasozXBbbeqEkvDd3XUs/Y9faSsSNf7UxQJJ5aD07MGgP7Hb1kAAIAh7PCxxuObl6UsCY9WxxTroGc945QxupyeNQAMGYRuAACAQVbX2Kz3auKqrK49YUl4+5715KJEz/ojZcUqD9OzBoChjtANAAAwALrqWb9/+Jjc8dXgJ/Ssy0KeysOephQXaPSo7MH7IQAA3UboBgAA6CPOOVUdrW+zK3inPevRo1QeTvSsI/SsASBj8RsdAACgm9r0rKvjbTrX7XvWZaECTT+lUJfNnpjoWAdLwkP0rAFgRCB0AwAAdKAnPeuKU9v2rEvG5SubnjUAjGiEbgAAMGI1tzjtPXhMO6tr23Ssd1ad2LMOBz3ry2ZPSIZqetYAgJMhdAMAgIzW2551JOSpzC/QmLycQfwpAADDFaEbAABkhMPHGhVtDdXJgE3PGgAwuAjdAABg2OioZx2tSQTs6trOe9aty8EjvqdJ4+lZAwAGDqEbAAAMKT3pWX/sdHrWAIChidANAAAGXGvPuk2oDr7uqomrobklee2Y0aMUCXuqKCtSxJ+cCNZ+IT1rAMCwQOgGAAD95khdY/JWW+n0rKeFE7PWrT3rspAnv5CeNQBg+CJ0AwCAXqlrbNauA/FgR/AgVFef2LM2kyYX5SviF9KzBgCMGIRuAABwUp31rCurY9p7qPOedVlrz9pP9KzzcuhZAwBGFkI3AACQFPSsa+uTy8HT6VnPP7VIn5hPzxoAgM4QugEAGGFae9bRmljKkvDEo7a+KXldbnaWTg0VqNz3tPj0UxI9a79QEZ+eNQAA6SJ0AwCQgXrSs55/ahE9awAA+thJQ7eZ5Ul6RdLo4PrnnHN3mVlE0kZJIUnbJX3GOddgZqMl/VjSfEk1kj7pnIv20/gBABixmluc3j90LLEEvKq2zXLw9j1rv3B0YsZ61gRFwvSsAQAYKOnMdNdLWuScqzWzHEm/NrMXJX1V0kPOuY1m9iNJN0l6OPh60Dk33cxWSLpf0if7afwAAGS07vSsC0ePUnm7nnXE91TmexpLzxoAgEFx0tDtnHOSaoOXOcHDSVok6Ybg+BOS1ioRuq8JnkvSc5L+1sws+BwAANCBI3WNiraGanrWAABkjLQ63WaWrcQS8umSfiDpfyQdcs61/r+APZJKg+elknZLknOuycwOK7EEvbrdZ66WtFqSpk6d2rufAgCAYSC1Zx2tiSVnr3dWx1RdW5+8zkwqHZ+viO/pT88pTcxYhwtVTs8aAIBhJ63Q7ZxrljTPzMZL+kdJs3r7jZ1zj0h6RJIqKiqYBQcAZISe9axPoWcNAECG6tbu5c65Q2b2K0kXSBpvZqOC2e7JkvYGl+2VNEXSHjMbJWmcEhuqAQCQEZxzqq5tSO4KngjYiWD9Xgc964jv6ZypRfrTcyarPEzPGgCAkSSd3cvDkhqDwJ0v6TIlNkf7laRPKLGD+UpJPwve8kLwektw/pf0uQEAw1FHPevWZeFHO+hZR3xPi04/RZFQcNutsKdw4Wh61gAAjGDpzHSXSHoi6HVnSXrGOfdzM3tH0kYz+7ak1yU9Glz/qKR/MLMdkg5IWtEP4wYAoE/UNzVrV008uQQ8nZ71tfSsAQBAmtLZvfxNSWd3cHynpHM7OF4n6bo+GR0AAH2gfc86mgzZtdp78Jha2vWsI36BFs0KJ3cFLw97mkrPGgAA9EC3Ot0AAAxVPelZnz2lSNeeTc8aAAD0H0I3AGBYOVrXqGh1XDura9vcy7p9zzon23Rq0K1eNOuUxHJwetYAAGCAEboBAENOZz3rypqYqo523bMu8z2V+4UqLaJnDQAABh+hGwAwKFp71qmz1Z33rHMV8T1dOpOeNQAAGF4I3QCAftNRz7r1FlzRmrgamo73rL3cbEXCnuZNKdLysyer3D/esx6XT88aAAAMT4RuAECv9aRnfelMetYAACDzEboBAGmpb2rW7gNx7axqvxz8xJ71pHH5Kg97Wt56P+ugZz1pfJ5GZWcN4k8BAAAwsAjdAICk3vasI76nU0P0rAEAAFoRugFghHHOqSbWkFz+3Rqq6VkDAAD0PUI3AGSo9j3raMrM9dG6E3vWZSFPC1N61uW+p/AYetYAAAC9QegGgGGsRz3rs+lZAwAADBRCNwAMca0962hNEKpTAvaeg/E2PeuQl+hZLzwtrEjYC5aDF9KzBgAAGCSEbgAYAnrSs547Zbw+fnYpPWsAAIAhjNANAAOotr5J0dYl4FXHg3VHPeupxQWK+IX0rAEAAIYxQjcA9LGOetatjw876Vl/fF7Qsw6WhJeOz6dnDQAAkAEI3QDQAy0tTu8fPn4/63R61pfQswYAABhxCN0A0Ik2PevWR2u4rom16VkX5GYr4ns6a/I4fXzeJEXCiWAdCXkaV0DPGgAAYKQidAMY8XrSs75kZpieNQAAAE6K0A1gRGhoatGuA/Fgxrq2zZLw1J61JJWOz1fEp2cNAACA3iN0A8gYvelZR0KJcF0W8uhZAwAAoM8QugEMK845HQh61jvb9ayjNTHV07MGAADAEELoBjAkpfaso60z19UxVVbV6ki7nvWU4gKV+54uPs1PhGrfU3nY0yn0rAEAADDICN0ABk1PetbX0LMGAADAMHLS0G1mUyT9WNIESU7SI8659Wa2VtKfSaoKLv0L59ym4D1rJN0kqVnS/3LO/f/9MHYAw0BLi9MHR+qSu4LvTLn91u4DbXvWxUHP+uLTwsldwSNhT6cWe8rPpWcNAACA4Sedme4mSV9zzr1mZmMkbTezl4JzDznnHky92MxmS1ohaY6kSZJeNrPTnHPNfTlwAENHT3rWZ5aO0zVzJyU3L4v4nsYX5A7iTwEAAAD0vZOGbufcB5I+CJ4fNbM/SCrt4i3XSNronKuXVGlmOySdK2lLH4wXwCCK1TclZ6kru+hZj8oyTQ3RswYAAAC61ek2szJJZ0v6raQFkr5sZp+VtE2J2fCDSgTyV1Petkddh3QAQ0hqzzqanLlO9K33HzmxZ13mF+jqeZMU8QsTy8F9T5OL6FkDAAAAUjdCt5kVSvqppFudc0fM7GFJf6VEz/uvJH1H0ue68XmrJa2WpKlTp3ZnzAB6qSc964tm0LMGAAAAuiut0G1mOUoE7qecc89LknNuf8r5v5P08+DlXklTUt4+OTjWhnPuEUmPSFJFRYVrfx5A77T2rKM1x3cET32k9qzzcxI96zNKx+nquZMSu4P79KwBAACA3kpn93KT9KikPzjnvptyvCToe0vScklvBc9fkPQTM/uuEhupzZC0tU9HDSCpJz3ri2Yc71lHfE8TxtKzBgAAAPpDOjPdCyR9RtJ/mtkbwbG/kPQpM5unxPLyqKQvSJJz7m0ze0bSO0rsfP7n7FwO9E5DU4t2H4wndwTvqmc9aVyeImGPnjUAAAAwBKSze/mvJXU0Bbapi/fcI+meXowLGHHa96wrq+PJYL374DE1pxStW3vWH50eVnn4+FLwshA9awAAAGAo6dbu5QB6xzmng/HGxOZlafas55SO0zJ61gAAAMCwROgG+kFrzzpaE2u3JDymw8cak9eNyjJNLS4IZq19RYJZ63K/kJ41AAAAkAEI3UAP9aRnvWxuSbCBWYEifqEmF+Urh541AAAAkLEI3UAXWlqc9h2pS9kRPNZpz7qoIIeeNQAAAIA2CN0Y8TrqWbfe2zpaE1NdY8c966vOCnrWYU+RkKcij541AAAAgLYI3Rgx4g0p97OmZw0AAABgABC6kVEam1u0+0A8Ga53pgTsfUfq2lxbMi5PEd/TVWeVJEJ12KNnDQAAAKBPEbox7PSkZ71gup/sWZeFPJX5BSrI5Y8/AAAAgP5F6sCQdTDWkFz+3RqqO+pZ5+VkKeIXas4ketYAAAAAhhZCNwZVRz3ryprE10PxjnvWC6b7Qcc6Ea4njMlTVhY9awAAAABDD6Eb/a4nPeulZ9KzBgAAADD8EbrRJ1p71tGUHcFbH7sOxNv0rMcHPesLp4cSs9V+YaJrTc8aAAAAQIYh4aBbutuznl0yNjlrTc8aAAAAwEhD6MYJ4g1NilbHk8E6deY6tWedTc8aAAAAALpE6B6hOutZR2ti+uBw1z3r1seU4gJ61gAAAADQBUJ3Bmtpcdp/tE6VVSfvWY/Lz1F52NMF0+hZAwAAAEBfIU1lgNSedTRl5jpaHdOxxubkdXk5WSoLeTq9ZIyuPHNiMliX+/SsAQAAAKA/ELqHiZ70rC+cFqJnDQAAAACDiNA9hDQ2t2jPwWOJUF3Vdjl4+571xLGJnvWVZ5YEy8HpWQMAAADAUEPoHmDOJe5n3VHPeveBuJq66FmXBcG6LOTJG82/OgAAAAAY6khu/eRQvCG5I3glPWsAAAAAGJEI3f+XvTsPj6q++///emdPJiEkmUDCEjNhUXGXsLiyiNZ9aysUvcW7Wm69sLfaql1ui2ivVitab63WumO/+gM3tLQqbjdUa0U2N0CrNAkKIiRhTcKafH5/zMlkJhsJWSbL83Fdc2VyzmfOfCYC7Svn8zqnDer3rIvLqryvldraSM86PytFJxRkKZDtCy0Jz+lDzxoAAAAAeipCdyt8UFSup1bv0SNfLmm2Z30WPWsAAAAAgAjdrfLv0kp9sHG/hudWB89Ye1cFp2cNAAAAAGjMAVOimQ2W9GdJ/SU5SY845+4zs0xJz0rKl1Qi6RLn3FYzM0n3STpbUpWkK5xzKztm+p1r8qjByq36tyZMOCnaUwEAAAAAdAMtWfO8X9JPnXMjJI2VNMPMRkj6uaS3nXPDJL3tfS9JZ0ka5j2mS3qo3WcdJbExpuDvFAAAAAAAOLADhm7n3MbaM9XOuZ2SPpM0UNIFkp7yhj0l6ULv+QWS/uyClkjqa2a57T5zAAAAAAC6uFZd3cvM8iUdJ+kDSf2dcxu9Xd8quPxcCgbyr8Nett7bBgAAAABAr9Li0G1mqZJelHS9c25H+D7nnFOw791iZjbdzJab2fLS0tLWvBQAAAAAgG6hRaHbzOIVDNzPOOfme5s31S4b975u9rZvkDQ47OWDvG0RnHOPOOcKnXOF2dnZBzt/AAAAAAC6rJZcvdwkPS7pM+fc78N2LZA0TdKd3te/hG2/1szmSRojaXvYMvRGrVixoszM1h3E/KPBL6ks2pMAAAAAgB6uO2WvQ5raYcGV4U0zs5MlvSvpU0k13uZfKtjrfk5SnqR1Ct4ybIsX0h+QdKaCtwz7FG9ccQAAIABJREFUT+fc8rZ+gq7CzJY75wqjPQ8AAAAA6Ml6SvY6YOhGpJ7yHx4AAAAAurKekr1adfVyAAAAAADQcoTu1nsk2hMAAAAAgF6gR2QvlpcDAAAAANBBONMNAAAAAEAHIXS3kJk9YWabzWxVtOcCAAAAAD2RmQ02s0VmtsbMVpvZddGeU1uxvLyFzOxUSRWS/uycOzLa8wEAAACAnsbMciXlOudWmlmapBWSLnTOrYny1A4aZ7pbyDn3jqQt0Z4HAAAAAPRUzrmNzrmV3vOdkj6TNDC6s2obQjcAAAAAoMsxs3xJx0n6ILozaRtCNwAAAACgSzGzVEkvSrreObcj2vNpC0I3AAAAAKDLMLN4BQP3M865+dGeT1sRugEAAAAAXYKZmaTHJX3mnPt9tOfTHgjdLWRmcyW9L+lQM1tvZldGe04AAAAA0MOcJOk/JE00s4+8x9nRnlRbcMswAAAAAAA6CGe6AQAAAADoIIRuAAA6kZn9j5mtNrNPvCVzY7zt15tZShTmk29mqzro2CVm5u+IYwMA0F3ERXsCAAD0FmZ2gqRzJR3vnNvjBdIEb/f1kp6WVBWt+QEAgPbHmW4AADpPrqQy59weSXLOlTnnvjGz/5Y0QNIiM1skSWZ2hpm9b2Yrzex5736ltWeP7zKzT81sqZkN9bZ/38xWmdnHZvZO/Tc2s1Qze9s73qdmdkHY7lgze9Q7A/+GmSV7rxliZgvNbIWZvWtmh3nbzzOzD8zsQzN7y8z6e9uzvNevNrPHJFmH/SQBAOgmuJAaAACdxAvO/5CUIuktSc865/7u7SuRVOicK/POgM+XdJZzrtLMfiYp0Tl3uzfuUefcb8zsckmXOOfONbNPJZ3pnNtgZn2dc9vqvXecpBTn3A7v+EskDZN0iKS13nt/ZGbPSVrgnHvazN6WdLVz7ktvGfwdzrmJZpYhaZtzzpnZVZIOd8791MzuV/CXCreb2TmS/iYp2zlX1oE/VgAAujSWlwMA0EmccxVmNlLSKZImSHrWzH7unJtTb+hYSSMkvRe8XakSFLxtZa25YV/v9Z6/J2mOF5rnN/L2Jum3ZnaqpBpJAyX19/YVO+c+8p6vkJTv/YLgREnPe3OQpETv6yBv7rne3Iq97adKutj7rK+Y2dbmfyIAAPR8hG4AADqRc65a0mJJi72z09Mkzak3zCS96Zz7QVOHqf/cOXe1dzb6HEkrzGykc648bNylkrIljXTO7fPOmCd5+/aEjauWlKxgBW2bc+7YRt7/D5J+75xbYGbjJc1q8gMDANDL0ekGAKCTmNmhZjYsbNOxktZ5z3dKSvOeL5F0Ulhf22dmw8NeNzns6/vemCHOuQ+cczMllUoaXO/t0yVt9gL3BAWXlTfJObdDUrGZfd87vpnZMWHH2uA9nxb2snckTfXGnyUpo7n3AACgN+BMNwAAnSdV0h/MrK+k/Qp2qad7+x6RtNDMvnHOTTCzKyTNNbPaJd23SPrCe55hZp8oeIa69mz4bC/Qm6S3JX1c772fkfRX7+z6ckmft2C+l0p6yMxukRQvaZ533FkKLjvfKun/JAW88bd5c14t6Z+SvmrBewAA0KNxITUAALqR8AuuRXsuAADgwFheDgAAAABAB2l16DazM83sX2a21sx+3sj+PDNb5N278xMzO7t9pgoAAJxz+ZzlBgCg+2jV8nIzi1WwT3a6pPWSlkn6gXNuTdiYRyR96Jx7yMxGSHrVOZff3HH9fr/Lz292SJdRWVkpn88X7WkAAAAAQI/WnbLXihUrypxz2Y3ta+2F1EZLWuucK5IkM5sn6QJJa8LGOEl9vOfpkr450EHz8/O1fPnyVk4lOhYvXqzx48dHexoAAAAA0KN1p+xlZuua2tfa0D1Q0tdh36+XNKbemFmS3jCzH0vySZrUyvcAAAAAAKBH6IgLqf1A0hzn3CBJZ0v6f2bW4H3MbLqZLTez5aWlpR0wDQAAAAAAoqu1oXuDpMFh3w/ytoW7UtJzkuSce19SkiR//QM55x5xzhU65wqzsxtd+g4AAAAAQLfW2uXlyyQNM7OAgmF7iqSp9cZ8Jek0SXPM7HAFQ3ePOJX9zheleviT3fqk+ksF/L7Qw5fY2h8jAAAAAKA3aFVadM7tN7NrJb0uKVbSE8651WZ2u6TlzrkFkn4q6VEzu0HBi6pd4VpzifQubNOO3frXlhq9/+YXEdv790n0AniqCmrDeLZPgzNSlBDHrdABAAAAoLdq9Sla59yrkl6tt21m2PM1kk5q+9S6nu8XDlZ2xb815sRTVFJeqeKy4KOotFLFZRVauGqjtlbtC42PjTENzkgOBfKAPyX4Ndun3D5JiomxKH4aAAAAAEBHY130QUhOiNXhuX10eG6fBvu2Ve0NhfHiskoVlVWquLRSS4q2aNe+6tC4xLiYiCXqAb9PBdnBcJ6REi8zAjkAAAAAdHeE7nbWNyVBx+Ul6Li8jIjtzjlt2rFHRWUVwUBeGgzl//p2p95cs0n7a+pW4KcnxwdDeNhS9YDfp/ws+uMAAAAA0J2Q4DqJmSknPUk56Uk6cUjkxdz3Vddo/dZdKi6rUHFZlfe1UkuKyjX/w8iLw9MfBwAAAIDug9DdBcTH1i01r2/X3uqD649n150pz6E/DgAAAABRQeju4prrj2+t3Kvi8rql6rWP+v3xpPgY5WfVdsZ9Yc/pjwMAAABARyJ0d2MZvgRl+BJ0fAv7459v3Kk3VresPx7w+5SSwB8PAAAAAGiLbp+qZs2apdtuuy30ff/+/VVYWKjf/va3Ovroo6M4s+ip7Y/f/etb9MILL6ikpCS0L7w/XhR2hvz9onI9+af7lJg7XEl5wZ9bTp+kUBAvCLvK+uDMFMXHtq4/ftddd2n06NEaP358O35SAAAAAOjaun3olqT09HQtXLhQklRSUqKZM2fq9NNP12effabMzMwoz65rCe+PTzwscp//nsn67vE/0jmXHh/RH3/t07b3x++66y5de+21hG4AAAAAvUqPCN1xcXEaO3asJGns2LHKz8/XCSecoIULF2rq1KlRnt3B27Vrl5KTkzv1PbPTEnX2UbkNtjfWHy/yzpDv3lcTGle/Px7wpyrg98m5BocEAAAAgB6vR95j6phjjpEkff31102O2bZtm6666ioNGDBASUlJysvL049+9KOIMS+++KKGDx+u5ORknXrqqVq+fLkmTJigOXPmhMaYmR544IGI182aNUt+f91twTZu3Kgf/vCHKigoUHJysoYPH65bbrlFe/fuDY0pKSmRmemZZ57R5Zdfrr59++q8886TJG3ZskXTp09X//79lZSUpBNPPFEffPBBg88zdepUpaamKjc3V7/5zW9a9TPLz89XeXm5brvtNpmZzEyLFy+WJNXU1OjhP/xel0wcpaknDtEjPz5Po/d/qteuO0VrbjtT7/9ion52rFPiwttUcs/39X+/OFv/76bJuudPT+nG5z/WmKMP05Ytkcf+73ue1t8++Uarv9muqr37WzVXAAAAAOguesSZ7vq++uorSVIgEGhyzE9+8hP985//1L333qucnBx9/fXXeuedd0L7V65cqcmTJ+uiiy7Sfffdp1WrVumSSy45qPmUlZUpMzNTv//975WRkaEvvvhCs2bNUmlpqR5++OGIsTfeeKMuvvhiPf/884qNjdWePXs0adIkbdu2TbNnz1a/fv300EMPadKkSfryyy+Vk5MjSfrP//xPLV68OPR57r77bv373/9WXFzL/hO/9NJLmjBhgr73ve/pqquukiSNGDFCkvTjH/9YTz31lGbOnKnjjz9eb775pn74wx8qKytL5557rny2T7+4+jJdcMEFemD2b+Sc06effipfaqq+893xemP0M7ph2sUaPmaS+o06W99s26WX1ydqwf/3Yej927M/DgAAAABdRY8J3fv3B8+Wrlu3Ttdee62OPfZYXXDBBU2OX7p0qWbMmKHJkyeHtl122WWh53feeaeGDx+u5557Tmams846S3v37tUtt9zS6rkdddRRuvvuu0Pfn3TSSfL5fPrhD3+oP/zhD0pISAjtGzt2rB588MHQ948//rhWrVql1atXa9iwYZKkSZMm6dBDD9U999yj2bNna/Xq1Xr55Zc1b9680OeZMGGC8vLy1KdPw1uNNea4445TXFycBg0aFFqqL0lr167VQw89pCeffFLTpk0Lvf/GjRt122236dxzz9UXX3yh7du364EHHlBaWpok6Ywzzggd478unqT/mZ6gC08+WrNmBQN91d79Kimr8paqV6jIW7L+6qcbta1efzwvMyUUwmuvtJ7P/ccBAAAAdAM9InSXl5crPj4+9H1WVpaWLVumxMRE1dTUqKamrnMcExOjmJgYHXvssZo9e7ZiY2M1adIkDR8+POKYS5cu1ZQpUyLuYX3xxRcfVOh2zum+++7TI488ouLiYu3evTu076uvvtLQoUND359zzjkRr33rrbc0cuRIBQKB0C8WJGncuHFavny5JGnZsmWSFPFLhtTUVJ1++ukNlqG31ttvv62YmBhddNFFEe9/2mmnae7cuaqurtaQIUOUmpqqqVOn6qqrrtK4cePUt2/fZo+bkhCnEQP6aMSAlt1/vKisUv/8d1mL+uMFfp8yfAkNjgsAAAAAna1HhO709HS99dZbqq6u1scff6wbb7xRU6dO1Xvvvafbb7894pZit956q2bNmqUHHnhAM2fO1O23364ZM2Zo6NCh+vWvf60pU6ZIkr799lv169cv4n3qf99S//u//6ubbrpJP/vZzzRu3DhlZGRo2bJlmjFjRkQAl4K3PAtXVlamJUuWRPxSodaQIUNCc01LS1NSUlK7zLf++1dXVys9Pb3R/Rs3btSgQYP05ptvatasWbrkkktUU1OjM844Q3/4wx9UUFDQ6vds6v7jNTVOm3buVnFpZejMeHFZpT7buFOvr96k6rD7j/dNiY84M14byPP9Kdx/HAAAAECn6RHpIy4uToWFhZKkMWPGKDk5WZdffrmef/55TZ8+Xeeee25o7IABAyRJffv21f3336/7779fn3zyie666y5deumlOvroozVixAjl5ORo8+bNEe9T/3tJSkxMjLggmiRt3bo14vvnn39e3/ve9yIubrZmzZpGP0v4mXVJyszMVGFhoR566KFG31uScnJytHPnTu3evTsieDc239bKzMxUXFyc3nvvPcXENOxW1wb7sWPHauHChdq1a5feeust/eQnP9HUqVO1ZMmSNs+hVkyMKTc9WbnpyTpxqD9i377qGn29pSoUxEP3H/93ueav3BAxNjc9SflZ9McBAAAAdLweEbrru+yyy/S73/1Ov/vd7zR58uRQ0G7K0UcfrdmzZ+uZZ57R559/rhEjRmjUqFFasGCB7rjjjlAQnj9/foPXDho0SJ999lno+5qaGr399tsRY3bt2hUKyLWeeeaZFn2W0047TW+88Yby8vKaPHM9atQoSdJf/vKXUKe7oqJCb775Zos73ZKUkJDQ4Mz7xIkTVV1dre3bt+v0008/4DGSk5N13nnnadWqVbrjjjuaPXZ7io+NUUF2qgqyUxvsa6o//sonG7V914H744Fsn/qn0R8HAAAA0Ho9MnSbmX75y1/q0ksv1dtvv63TTjutwZiTTz5ZF110kY488kiZmR599FH5fD6NHj1akvSzn/1MY8aM0SWXXKIrr7xSq1at0uOPP97gOBdddJEefPBBHXfccSooKNBjjz2mHTt2RIw5/fTTdf/992vMmDEaMmSInnnmGa1du7ZFn+Xyyy/Xn/70J40fP1433nijCgoKVF5erqVLlyonJ0c33HCDjjjiCJ1//vm65pprtGPHDuXm5mr27NlKSUlp1c/tsMMO0yuvvKIzzzxTqampOvTQQ3XooYfq6quv1pQpU3TzzTersLBQu3fv1urVq/XFF1/oscce0yuvvKInnnhCF154ofLy8rRhwwY9/PDDmjhxYrPHrr3oWkc7UH+8bql6RbA/XtqwP54cH6t8f92Z8fywUE5/HAAAAEBTemTolqTJkydr1qxZuuuuuxoN3SeccILmzJmjkpISxcbG6rjjjtNrr72mQYMGSZIKCws1b948/eIXv9CFF16owsJCPfvss6FQXuvWW2/V5s2bdcsttyghIUHXXnutjjjiiIgrkM+cOVOlpaWhi7BdfPHFuv/++0P34W5OUlKSFi1apJkzZ+rWW2/Vpk2b1K9fP40ePVrnn39+aNycOXN0zTXX6Prrr1dqaqpmzJihUaNG6YUXXmjxz2z27NmaMWOGzjnnHFVVVWnRokUaP368HnzwQQ0fPlyPPvqoZs6cqT59+mjEiBG68sorJUlDhw4N/aJj8+bNys7O1rnnnqvf/va3Bzx2tGX4EjTSl6CRh7SsP75m4w4tXP0t/XEAAAAALWLOuQOP6mCFhYWu9krcXVlFRYXS0tL05JNP6oorroj2dBAl9fvjRWV1V1r/dkfkEvrc9KTI5erZwVA+KCOZ/jgAAADQjMWLF3eJE3UtYWYrnHOFje3jNBzQSs31xyv37FdJeTCAl5TVnSX/W73+eFyMaXAT/fGcPkkNLqgHAAAAoHsidPcS1dXVampVg5kpNja2k2fUM/kS43TEgHQdMaDhLdYOtj8e8Nddab1vCv1xAAAAoDshdLdCampql+kit9aQIUO0bt26RvcdcsghKikp6dwJ9ULN9ce/3bG73lL1Cq3+ZnuD/nhGqD+eqoJsX/DWZ/THAQAAgC6L/5feS/z1r3/Vnj17Gt1X/3Zm6FwxMaYBfZM1oG+yTjrA/cdrQ/l7a8v04sr1EWPpjwMAAABdD6G7lzjqqKOiPQUchJb2x2sv5FZUVqm/fvyNduzeHxoXV//+49m1HfJU9e+TSH8cAAAA6ECEbqCbaqo/7pzT1qp9obPj4f3x9+iPAwAAAJ2K0A30MGamTF+CMtu5P14byvOzfEpO4MJ7AAAAQEsQuoFepLn++N79Nfp6a1XEUvXisopG++MD0pNCy9Tzs+iPAwAAAE0hdAOQJCXExWhIdqqGtKI/vuAj+uMAAABAcwjdAA7owP3xChWVVob1yCv1j7Vl2rO/rj+ekhAbvMVZdr0OOf1xAAAA9GCEbgAHra4/nqmRh2RG7Kupcdq4Y3fwzHh5WH98w3YtXEV/HAAAAL1Dq0O3mZ0p6T5JsZIec87d2ciYSyTNkuQkfeycm9rGeQLoZmJiTAP7Jmtg32SdPKxl/fF/rC1ttj8e8KeGzpIPykhWHP1xAAAAdHGtCt1mFivpQUmnS1ovaZmZLXDOrQkbM0zSLySd5Jzbamb92nPCALq/A/XHw5ep1z4a7Y9npajAOyNOfxwAAABdUWvPdI+WtNY5VyRJZjZP0gWS1oSN+ZGkB51zWyXJObe5PSYKoHfwJcbpyIHpOnJgy/vj737Zsv54gT9V6Snxnf2RAAAA0Iu1NnQPlPR12PfrJY2pN2a4JJnZewouQZ/lnFt40DMEALWiP15W4S1Xr9SqDdv12qcbFVYfV6YvIeIibgXeVdbzs3xKiqc/DgAAgPbVERdSi5M0TNJ4SYMkvWNmRznntoUPMrPpkqZLUl5eXgdMA0BvcaD++FdbqlRSFtkff/fLUr2wgv44AAAAOlZrQ/cGSYPDvh/kbQu3XtIHzrl9korN7AsFQ/iy8EHOuUckPSJJhYWFTgDQARLiYjS0X6qG9mvYH6/Ysz8UxovDQvlfPvpGO5voj9cG8oDfp4Jsn/ql0R8HAABA01obupdJGmZmAQXD9hRJ9a9M/rKkH0h60sz8Ci43L2rrRAGgvaU20x/fUrk37Mx48JZnJeWN98cDfp/y/fTHAQAA0FCrQrdzbr+ZXSvpdQX72k8451ab2e2SljvnFnj7zjCzNZKqJd3knCtv74kDQEcxM2WlJiorNVGF+fTHAQAAcPBa3el2zr0q6dV622aGPXeSfuI9AKBHaUl/vNjrjReXVaqotFLvfNGwPz6wb3JEIA9k+xTIoj8OAADQ03TEhdQAoFeK7I/3j9jXVH/85Y82RPTH42NNgzPpjwMAAPQUhG4A6ASt7Y8Xl1XqnS/LtLeR/nj4UvWAP1WBLB/9cQAAgC6K0A0AUXSg/vg323dFnB0vLqvUpxu269V6/fEsrz+eT38cAACgSyF0A0AXFRNjGpSRokEZKTplWHbEvj37q/X1ll0H7I+bSQPSG/bHC/w+DexLfxwAAKCjEboBoBtKjIs9YH+8KLRUPRjKG+uP52WmKOBPVUF2MJDnZ9EfBwAAaE+EbgDoYQ6uP14a0R/3JcQ2WKpee1G39GT64wAAAC1F6AaAXqI1/fEiL4x/sr7p/nj4UvWAP1WHZKXQHwcAAKiH0A0AaEF/vEpFpZUqKa8L5X//olTP0x8HAABoFqEbANCsYH88TUP7pTXY12R//MMN2rmn+f547dL1bPrjAACgByN0AwAOWnP98XKvP15cWtshr2iyPx7eGQ/4U+iPAwCAHoPQDQBod2Ymf2qi/KmJGlWvP15d47Sxkf74x19v0yuffEN/HAAA9CiEbgBAp4ptYX88FMrLKrW4if54+FL14HL1VA3MSFZsDMvVAQBA10DoBgB0Gc31x3fu3qeSsioVl0f2x19aSX8cAAB0XYRuAEC3kJYUr6MGpeuoQe3XHy/wAnk+/XEAANBBCN0AgG7tQP3xb7bV9cdrH431x/2pwf54fhb9cQAA0H4I3QCAHis2xjQ4M0WDM1N06nD64wAAoPMRugEAvVJL+uNF3jL12kf9/nhCbIzyslIilqrXPuiPAwAAidANAEADzfXHyyr2qqS8YX/871+0rD8eyPapTxL9cQAAegtCNwAALWRmyk5LVHZay/rjRWWV+ujrrfrbJ9/INdIfD/jDQnm2T3mZ9McBAOhpCN0AALSD5vrju/d5/fHaQF5aqeLySi36V6meWx7ZHx/YNzlimTr9cQAAujdCNwAAHSwpPlbD+qdpWP8O6I9n+5SdSn8cAICuitANAEAUHag/Xuz1xotqz5CXVerv/yrV3uq6/nhqYlzkmfHsuluf0R8HACC6CN0AAHRB4f3x0YGW9cc//Hqr/kp/HACALoXQDQBAN9Pq/nhZpf7v81KVVTTeH6+7snqqCvw+DehLfxwAgPZC6AYAoAdprj++Y/c+ldSeGS+tDN76rKxSL67coIp6/fFDvP54gP44AABtQugGAKCX6JMUr6MH9dXRg/pGbG+uP764Bf3xgN+nfD/9cQAAGkPoBgCgl2tJfzwYxCtC/fGVXzXWH08MW6oevJgb/XEAQG9H6AYAAE0K74+Pa6Q//tWWqroLunlnx9/+fLPKlu8JjaM/DgDozQjdAADgoCTFx2p4/zQNb0F/vDaYN9sfz64N5cGrrPtTE+iPAwC6PUI3AABod831x0sr9oTOiheXN90fT0uMCy1Tpz8OAOiuWh26zexMSfdJipX0mHPuzibGfVfSC5JGOeeWt2mWAACgRzAz9UtLUr+0JI0pyIrY15b+eO3S9bysFCXG0R8HAHQdrQrdZhYr6UFJp0taL2mZmS1wzq2pNy5N0nWSPmiviQIAgJ6tJf3xuqXqFV5/fJPKlu8NjYsxaWBGsgL+1LpQ7j3ojwMAoqG1Z7pHS1rrnCuSJDObJ+kCSWvqjfu1pN9JuqnNMwQAAL3ewfTHX1i3lf44ACDqWhu6B0r6Ouz79ZLGhA8ws+MlDXbOvWJmhG4AANChWtwf95arF5VVatG/Nmtfdd169dr+eMQ9yP2pyvenKI3+OACgDdr1QmpmFiPp95KuaMHY6ZKmS1JeXl57TgMAAOCA/fENW3epqKyi7ix5WaVWrNuqBR9H9sez0xIVyKI/DgA4OK0N3RskDQ77fpC3rVaapCMlLfaWaOVIWmBm59e/mJpz7hFJj0hSYWGhEwAAQCeJjTHlZaUoLytFOjRyH/1xAEB7am3oXiZpmJkFFAzbUyRNrd3pnNsuyV/7vZktlnQjVy8HAADdRXP98e279kWcGa8N5StKtqhyb3VoXEJcjPJr++P+VAX8KfTHAaCXalXods7tN7NrJb2u4C3DnnDOrTaz2yUtd84t6IhJAgAAdAXpyfE6ZnBfHTO4Zf3xf5dW6v8+pz8OAL1ZqzvdzrlXJb1ab9vMJsaOP7hpAQAAdB/N9cf3V9fom227VeQtU699LC9poj/u90UsVy/I9mlwJv1xAOiu2vVCagAAAIgUFxsT6o+Pb6Q/vq68KiyMB4P5W59tUlkF/XEA6AkI3QAAAFGSFB+rQ3PSdGhO+/XHC8Kusp7loz8OANFG6AYAAOiCmu2P79wTFsQrVVTaRH88KS50Zjyf/jgARAWhGwAAoBsxM/Xrk6R+fZI0toX98WUlW/UX+uMAEBWEbgAAgB6iZf3xiuBZcu9K62+u2aTyysj++KCMlIggHvD7lJ9FfxwADgahGwAAoBc4mP74cvrjANBmhG4AAIBerrX98bWbK5rtjwf8qQpkB5eu5/t9Sk3k/3IC6L34FxAAAACNOlB/fMO2XRFL1UvKG++P9/P64wH64wB6IUI3AAAAWi0uNkaHZPl0SJZPE9q5Px7w+zQgPVkx9McB9ACEbgAAALSrZvvjVftUXB7sjBeX1nXIl5VsUVW9/nggywvh2ZFnyemPA+hOCN0AAADoNOkp8To2pa+ObWF//MvNO/X255vojwPotvhXCQAAAFHX2v547f3HX/7om4ixtf3xuqXqqQr4fcrLTFFCXExnfiQAkEToBgAAQBd3oP54SbkXxsvrQvkbq+mPA+gaCN0AAADotpLiY3VYTh8dltOnwb6W9scT42KUX68/Xrt8PZP+OIA2InQDAACgR2quP7555x4VhZaqV6i4rFJfNNIf75MUp0B2aliHPPigPw6gpfiXAgAAAL2Kmal/nyT175OkE4a0rD++tHiLXvpwQ8RY+uMAWoLQDQAAAHia64/v2lvnEwXjAAAgAElEQVStdVsqI5aqF5dV6vXVm7SlXn98cGZYfzzsKuu5fZLojwO9DKEbAAAAaIHkhKb749uq9oZCePhjaTH9caC3I3QDAAAAbdQ3JUHH5SXouLyMiO3N9cff+myT9tccuD8e8Pvkoz8OdFv87QUAAAA6yIH64+u37lJxWe1y9Yom++P9+ySGeuMF3oXc6I8D3QOhGwAAAIiCuNgY5XsBekK9fU33x7+lPw50M4RuAAAAoItpTX+89krrHxRt0a59kf3x+svUg1daT1VGSjz9caCTELoBAACAbqS5/vimHXtU5C1TL/FC+b827dSbayL74+nJ8coPu4gb/XGg4/A3CgAAAOgBzEw56UnKSU/SiUP8Efua6o9/UFR+wP547ZXWB2fQHwcOBqEbAAAA6OEO1B8vKQ9brl5aqZLyhv3x2BjT4IzkUCAP+FPojwMtQOgGAAAAerHkhFgdnttHh+e2vD++hP440GKEbgAAAACNaml/vNi7D/m/vm28Px4I749nB7/mZ9EfR+/An3IAAAAArdJcf3xfqD9eoeKyqlB/fElRuebTH0cvROgGAAAA0G7iY+uWmtfXWH+8uKxCC1dt1NaqfaFxDfrj2XVnynPoj6ObIXQDAAAA6BTN9ce3Vu5VcXndUvXaR/3+eFJ8jPKzajvjvrDn9MfRNbU6dJvZmZLukxQr6THn3J319v9E0lWS9ksqlfRD59y6dpgrAAAAgB4qw5egDF+Cjm9hf/zzjTv1xuqW9ccDfp9SEjjfiOho1Z88M4uV9KCk0yWtl7TMzBY459aEDftQUqFzrsrMrpF0l6TJ7TVhAAAAAL1HS/vjRWFnyN9vpD+e0ycpFMQLwq6yPjgzRfGx9MfRcVr7657RktY654okyczmSbpAUih0O+cWhY1fIumytk4SAAAAAOoL749PPCxyX9Xe/Sopqwp1yGv74699Sn8cnau1oXugpK/Dvl8vaUwz46+U9FprJwUAAAAAbZGSEKcRA/poxICW9ceLvDPku/fVhMbV748H/Kmh5esZvoTO/Djoxjqs2GBml0kqlDSuif3TJU2XpLy8vI6aBgAAAABEaKo/XlPjtGnnbhWXBkN4cVmlSproj/dNCfbHA1n0x9G81v5p2CBpcNj3g7xtEcxskqT/kTTOObensQM55x6R9IgkFRYWusbGAAAAAEBniYkx5aYnKzc9WScOpT+O9tHa0L1M0jAzCygYtqdImho+wMyOk/SwpDOdc5vbZZYAAAAAEEUt6Y8Hg3hF6Cz5q59u1LZ6/fG8zJTQcWqXqufTH+/RWhW6nXP7zexaSa8reMuwJ5xzq83sdknLnXMLJM2WlCrpee8eeV85585v53kDAAAAQJdwMP3xf/67jP54L9HqsoFz7lVJr9bbNjPs+aR2mBcAAAAAdHut6Y8Xl1Xqs4079frqTapurD8eugd5MJDn+1Poj3cD/BcCAAAAgE52oP7411uqQkE81B//d7nmr4zsj+emJyk/i/54V0boBgAAAIAuJD42RgXZqSrITm2wr6n++CufbNT2XQfujweyfeqfRn+8MxG6AQAAAKCbOFB/vG6pekWwP17asD+eHB+rfH/dmfH8sFBOf7z9EboBAAAAoAfI8CVopC9BIw9pWX98zcYdWrj6W/rjHYyfGgAAAAD0YK3pjxeVBa+0/s+1jffHI5arZwdD+aCMZPrjzSB0AwAAAEAv1Vx/vHLPfpWUB8N4SVndWfK/1euPx8WYBjfRH8/pkyTvVtK9FqEbAAAAANCALzFORwxI1xED0hvsO9j+eMBfd6X1vim9oz9O6AYAAAAAtEpz/fFvd+yOWKpeXFah1d9sb9Afzwj1x1MV8Kf02P54z/kkAAAAAICoiokxDeibrAF9k3VSC/vj760t04srd0eMzU1P0tmDazS+E+feUQjdAAAAAIAO19L+ePDseKUyYsujMMv2R+gGAAAAAERVY/3xxYsXR29C7YjrugMAAAAA0EEI3QAAAAAAdBBCNwAAAAAAHYTQDQAAAABABzHn3IFHdfQkzEolrYv2PFrIL6ks2pMAAAAAgB6uO2WvQ5xz2Y3t6BKhuzsxs+XOucJozwMAAAAAerKekr1YXg4AAAAAQAchdAMAAAAA0EEI3a33SLQnAAAAAAC9QI/IXnS6AQAAAADoIJzpBgAAAACggxC6W8jMnjCzzWa2KtpzAQAAAICeyMwGm9kiM1tjZqvN7Lpoz6mtWF7eQmZ2qqQKSX92zh0Z7fkAAAAAQE9jZrmScp1zK80sTdIKSRc659ZEeWoHjTPdLeSce0fSlmjPAwAAAAB6KufcRufcSu/5TkmfSRoY3Vm1DaEbAAAAANDlmFm+pOMkfRDdmbQNoRsAAAAA0KWYWaqkFyVd75zbEe35tAWhGwAAAADQZZhZvIKB+xnn3Pxoz6etCN0AAAAAgC7BzEzS45I+c879PtrzaQ+E7hYys7mS3pd0qJmtN7Mroz0nAAAAAOhhTpL0H5ImmtlH3uPsaE+qLbhlGAAAAAAAHYQz3QAAAAAAdBBCNwAAAAAAHYTQDQBAJzKz/zGz1Wb2iddTG+Ntv97MUqIwn3wzW9VBxy4xM39HHBsAgO4iLtoTAACgtzCzEySdK+l459weL5AmeLuvl/S0pKpozQ8AALQ/znQDANB5ciWVOef2SJJzrsw5942Z/bekAZIWmdkiSTKzM8zsfTNbaWbPm1mqt73EzO4ys0/NbKmZDfW2f9/MVpnZx2b2Tv03NrNUM3vbO96nZnZB2O5YM3vUOwP/hpkle68ZYmYLzWyFmb1rZod5288zsw/M7EMze8vM+nvbs7zXrzazxyRZh/0kAQDoJrh6OQAAncQLzv+QlCLpLUnPOuf+7u0rkVTonCvzzoDPl3SWc67SzH4mKdE5d7s37lHn3G/M7HJJlzjnzjWzTyWd6ZzbYGZ9nXPb6r13nKQU59wO7/hLJA2TdIiktd57f2Rmz0la4Jx72szelnS1c+5Lbxn8Hc65iWaWIWmbc86Z2VWSDnfO/dTM7lfwlwq3m9k5kv4mKds5V9aBP1YAALo0lpcDANBJnHMVZjZS0imSJkh61sx+7pybU2/oWEkjJL1nZlJwCfr7Yfvnhn2913v+nqQ5Xmie38jbm6TfmtmpkmokDZTU39tX7Jz7yHu+QlK+9wuCEyU9781BkhK9r4O8ued6cyv2tp8q6WLvs75iZlub/4kAANDzEboBAOhEzrlqSYslLfbOTk+TNKfeMJP0pnPuB00dpv5z59zV3tnocyStMLORzrnysHGXSsqWNNI5t887Y57k7dsTNq5aUrKCFbRtzrljG3n/P0j6vXNugZmNlzSryQ8MAEAvR6cbAIBOYmaHmtmwsE3HSlrnPd8pKc17vkTSSWF9bZ+ZDQ973eSwr+97Y4Y45z5wzs2UVCppcL23T5e02QvcExRcVt4k59wOScVm9n3v+GZmx4Qda4P3fFrYy96RNNUbf5akjObeAwCA3qBNodvMnjCzzeG3GjGzY81siXcblOVmNrrt0wQAoEdIlfSUma0xs08UXEI+y9v3iKSFZrbIOVcq6QpJc71x70s6LOw4Gd726yTd4G2b7V0gbZWkf0r6uN57PyOp0Du7frmkz1sw30slXWlmH0taLan24muzFFx2vkJSeF/7NkmnmtlqBZeZf9WC9wAAoEdr04XUvF5YhaQ/O+eO9La9Iele59xrZna2pJudc+PbY7IAAPR24Rdci/ZcAADAgbXpTLdz7h1JW+pvltTHe54u6Zu2vAcAAAAAAN1Vm28ZZmb5kv4Wdqb7cEmvK3gRmBhJJzrn1jV5AEl+v9/l5+e3aR6dpbKyUj6fL9rTAAAAAIAerTtlrxUrVpQ557Ib29cRVy+/RtINzrkXzewSSY9LmlR/kJlNlzRdkvLy8rR8+fIOmEr7W7x4scaPHx/taQAAAABAj9adspeZNXmiuSOuXj5NdfcHfV5SoxdSc8494pwrdM4VZmc3+gsBAAAAAAC6tY4I3d9IGuc9nyjpyw54DwAAAAAAurw2LS83s7mSxkvym9l6SbdK+pGk+8wsTtJueUvIAQAAAADobdoUup1zP2hi18i2HBcAAAAA0Hs551TTxot+dxUdcSE1AAAAAAAOqHLPfhWXVUY8isoqVVxaoYuHxGhitCfYDgjdAAAAAIAOs3d/jb7aUqWS8FBdVqHiskpt2rEnYuyA9CQFsn06/9gByq3ZHKUZty9CNwAAAACgTWpqnDbu2K3i0mCgLgo7c71+6y5V19QtFc/0JSjg9+mUYdkK+H0q8PsUyPbpkEyfkhNiQ+MWL14chU/S/gjdAAAAAIADcs5pa9W+YKgurWywLHzP/prQ2OT4WAX8Ph05MF3nHzNAAb8v9OibkhDFT9H5CN0AAAAAgJDGeta1j+279oXGxcWY8rJSVOD36ZRhfuV7obrAn6r+fRJlZlH8FF0HoRsAAAAAepm9+2v09dYqbzl4y3rW5x2Tq4A/Nbgc3O/ToIxkxcXGROkTdB+EbgAAAADogWp71iWhK4LXBeuv6/WsM1LiFfD7dPLQbBVk1y0Fz8+K7Fmj9QjdAAAAANBNHUzP+oiB6Tqvl/esO1OvCt2LFy/WhAkTZGZat26dBg8eHLH/qquu0uOPP65x48Y1eqW8K664Qk899ZQeffRRXXXVVQ32h3cWkpKSNHToUF1zzTW6+uqrFRMT02BMuCFDhmjt2rUH/AybN2/WH//4R11xxRXKz88/4PjW6MhjAwAAADh4lXv2q6TcC9MRS8Ib6Vlnpnhnrf0KZNOzjrZeFbpr+Xw+Pfvss7rxxhtD2/bu3av58+crNTW10dfs3r1bL730kiRp7ty5jYZuSfrpT3+q733ve6qqqtLLL7+sGTNmqKamRtdee22DMeGSkpJaNPfNmzfrtttu0/jx4zskdHfUsQEAAAA0ry0964A/RQF/qgZlJCuennWX0itD93nnnad58+ZFhO7XX39d1dXVGj9+vHbu3NngNa+++qp27Nih448/XosXL9bGjRuVm5vbYFx+fr7Gjh0rSZo4caLWrFmjhx56KCJ0h48BAAAA0HvU1Dh9u2N3XaimZ93jdevQvWjRIk2cOFEbNmzQgAEDJEknnHCCli5dqvLycvXt21eSdNRRR+n888/X6aefLkmaMmWKLrjgAq1du1ZDhw6VJM2bN08XXnihKisrGw3dc+fO1cCBA3Xddddp2rRpeu6553TdddcdcI4jR47UAw880C6ft6SkREcddZQkacKECaHtzgX/Ym7ZskU///nP9Ze//EXbt2/X8ccfr3vvvVdjxowJjX388cd1zz33qLi4WD6fT0cccYT++Mc/yufzNXtsAAAAAC0T3rMuLqsKheqi0kqVlFdq977InnW+36cjBqTr3KO9nnW2T4EsnzJ89Kx7gm4duseMGaP4+Hi9++67mjx5sqqqqrRixQolJCTovffe0znnnKMtW7Zo9erVmj17duh1BQUFGj16tObOnatf/epXqqqq0oIFC/T888/rsccea/A+O3fu1CuvvKKrr75aeXl5Ov744zV37twWhe6SkhLl5OREbKupqdH+/fsjtsXExIR6303Jzc3VM888o0svvVQPPvigjj/++NC+PXv2aNKkSdq2bZtmz56tfv366aGHHtKkSZP05ZdfKicnR++8846uvvpq3X777TrhhBO0Y8cOvf/++9q+fbuGDh3a5LEBAAAANFS1N+x+1vSs0YRuHbpTUlI0cuTIUOhesmSJ0tPTddppp+ndd9/VOeeco3/84x8yM5144olauXJl6LVTpkzR448/rl/96lf629/+pqSkJE2aNKnR0P3yyy9r165dmjJliqqqqvSDH/xAN910k4qKilRQUBAxtjZQ79q1Sy+99JJefPFFXX/99RFjrrvuugaBfdq0aZozZ06znzcxMVFHH320JGnEiBERS9SffvpprVq1SqtXr9awYcMkSZMmTdKhhx6qe+65R7Nnz9bSpUt19NFH6xe/+EXodeeff37oeVPHBgAAAHqrfdU1+npLVShcF4UF7G937I4Ym5uepIDfp3OPzg2G6mwfPWt079AtSaeeeqoWLlwoSXrnnXd08skna9y4cXr66adD24455hj16dMn4nWXXHKJbrzxRn366aeaN2+evvvd7yourvEfx9y5c0NnxxcvXqzJkyfr5ptv1rx58/TLX/4yYmx4oDYzXX755Zo1a1bEmJtuukmXXHJJxDa/33/QPwNJeuuttzRy5EgFAoGIs+jjxo3T8uXLJUnHHnusbr75Zt1www266KKLNHbsWCUksGQFAAAAvdvB9KxPGuoPXbws4Pcp35+ilIRuH6/QAbr9n4pTTjlFd999t7Zt2xY6u33KKafo+uuv1+7du/Xuu+/qlFNOafC6gQMH6uSTT9bDDz+s1157Ta+99lqjxy8rK9Obb76pGTNmaNu2baqoqFBaWppGjRqluXPnNgjdtYE6OTlZBQUFSk5ObnDMvLw8FRYWts8PIGyeS5YsUXx8fIN9Q4YMkRQ88/3kk0/q/vvv13333afU1FT9x3/8h+666y75fL52nQ8AAADQ1Wyt3Bta/t1czzopPkYBfyo9a7SLbh+6TzrpJEnBe3AvWbJEv/vd73TEEUcoNTVVb7/9tlauXKmbbrqp0ddOmTJF1157rXJycnTqqac2OuaFF17Q/v37dd999+m+++5rsH/VqlU68sgjQ993RKBuiczMTBUWFuqhhx5qsC8xMTH0fNq0aZo2bZpKS0s1f/583XDDDUpLS9Odd97ZmdMFAAAAOkR4z7okrGNdXFapbVUNe9b5obPWPhV44bp/WpJiYuhZo310+9CdkZGhI488Uvfee69iY2N13HHHycx08skn66677tL+/fsbPdMtSd///vf1+uuva9KkSU1exGzu3Lk6/PDD9cc//lGS9NFHH+nYY4/Vnj17dN5552nu3Ln6zW9+02Gfr77a5eC7d0f2R0477TS98cYbysvLU79+/Q54nOzsbP3Xf/2X5s+frzVr1jR7bAAAAKArOZie9TlH0bNGdHT70C0Fl5g/+OCD+s53vqPY2NjQtptuuknDhg1T//79G32d3+/Xyy+/3ORx169fr3fffVd33HGHxo8fH9pe+/zMM8/UvHnzWh26S0pKtGTJkohtZhZxa6+m5OXlKTk5WU899ZTS09MVHx+vwsJCXX755frTn/6k8ePH68Ybb1RBQYHKy8u1dOlS5eTk6IYbbtCtt96qLVu2aPz48fL7/frwww/197//PXSWu6ljAwAAAJ2tpsZp087dKi6NPFtdXFapr7ZURfSs05PjVZDt04lDs4Jnq+lZowvpEX8Ca0N3+BLx2rPbJ5988kEf99lnn5WZ6dJLL210/2WXXabJkyfrgw8+aFFgrnXPPffonnvuidgWGxvb4DZijUlKStKjjz6q2267TePGjdO+ffvknFNSUpIWLVqkmTNn6tZbb9WmTZvUr18/jR49OnSF8lGjRunee+/VvHnztHPnTh1yyCGaNWtW6MJvTR0bAAAA6ChN9azXlVdp177q0LjanvWI3D4656hc5ft9oSXh9KzRlVlXCFWFhYWu9grbXd3ixYsjznoDAAAAaF7V3v0qKasKBeumetaxYfezDoSFanrWvVN3yl5mtsI51+gy4Tad6TazJySdK2mzc+7IsO0/ljRDUrWkV5xzN7flfQAAAAB0bfV71uGPjdsje9Y5fYI967OPyvWWgwcfgzNT6Fmjx2nr8vI5kh6Q9OfaDWY2QdIFko5xzu0xswNf1QshzS0xj4mJafKCbwAAAEBHO5ie9QlD6Fmjd2vTn3bn3Dtmll9v8zWS7nTO7fHGbG7Le/QmJSUlCgQCTe6fNm2a5syZ03kTAgAAQK+0rWpvxBXBa68QXlJW2aBnnZ/l0+G5aTr7qJxQsKZnDdTpiF8xDZd0ipn9RtJuSTc655Z1wPv0OAMGDNCyZU3/qPx+fyfOBgAAAD3ZwfSsTxySFdG3zulDzxo4kI4I3XGSMiWNlTRK0nNmVuDqXbHNzKZLmi4Fb1WF4H2yuUUXAAAA2su+6hqt37orGKpL6VkD0dARoXu9pPleyF5qZjWS/JJKwwc55x6R9IgUvHp5B8wDAAAA6PGcc/p2R13PuqRez3p/Yz3rAu+MdXYwWOdn+eRLpGcNdISO+Jv1sqQJkhaZ2XBJCZLKOuB9AAAAgF6jtT3rw3LTdBY9ayDq2nrLsLmSxkvym9l6SbdKekLSE2a2StJeSdPqLy0HAAAA0NCuvdUqKQ8L1aXBvnVxWaW21utZD85IVsDvnbXO9oWWhNOzBrqWtl69/AdN7LqsLccFAAAAeqqD6VmfFdazzvf7NDgjRQlx9KyB7oDiBgAAANDOnHPatGOPiryz1OFLwuv3rPskxakgO5WeNdBD8bcYAAAAOEiN9axrH031rM88MifYsc72KeBPVUZKvMxYDg70VIRuAAAAoBkH07MeS88agIfQDQAAgF6vtmdd4l0RvDhsWfg39XrW/fskKuD36cwjw+5nnU3PGkDjCN0AAADoFQ6mZz2WnjWANuJfDAAAAPQo26r2RnSrazvXJeWVqtpb17NOjItRwO/ToTn0rAF0HEI3AAAAup2metYl5VXaUrk3NK5Bz9qfooA/VYFsn3LpWQPoBIRuAAAAdEn7Q/ezbnnP+jtH5NCzBtClELoBAAAQNfV71iVhS8K/Km/Ysw5kp2pMbc867EHPGkBXxb9OAAAA6HDbq/bVXcCsJT3r/mk68wh61gC6P0I3AAAA2sXufV7PurR2OXjdI7xnHWPS4MwUBfw+jSnI9JaD07MG0DMRugEAANBibe1Z5/t9ysukZw2g9yB0AwAAIIJzTpt37vGuCF4XrBvrWad597Ou37PO9/uUSs8aAAjdAAAAvVX9nnX4o37POj/Lp+H90vSd2p61F64zfQn0rAGgGYRuAACAHuxgetajA/SsAaC9ELoBAAC6uf3VNdqwbVfoiuDhwXrDtl0RY/ul1fas+3tLwVMVoGcNAB2G0A0AANANNNez/npLlfZVN+xZjw5k0rMGgCjjX10AAIAuZPuufXWhut6S8PCedUJcjAL0rAGgyyN0AwAAdLL6PeuSsGBd3kjPOj/Lp1H5mSrIrjtrPSA9mZ41AHQDhG4AAIAO0FzP+pvtu+TqVoOHetZn1OtZD85MVmJcbPQ+BACgzQjdAAAAB6m2Zx0eqIOd6wp91VjP2u/TqPwMBfyDFcgOLgenZw0APVub/oU3sycknStps3PuyHr7firpbknZzrmytrwPAABANDXVsy4pq1RlIz3rYf3SdIbXs659ZNGzBoBeqa2/Vp0j6QFJfw7faGaDJZ0h6as2Hh8AAKBT7N5XrXXlVSouq2iwJLx+z3pQRvB+1vSsAQAH0qbQ7Zx7x8zyG9l1r6SbJf2lLccHAABoT431rEvKg0vCm+pZnz6ifyhUF2T7NDgzhZ41AKDF2r1AZGYXSNrgnPuYJVQAAKCzOedUunNPxK22muxZJ8apIJueNQCg47Tr/5qYWYqkXyq4tPxAY6dLmi5JeXl57TkNAADQC2zfte//b+/eo+Ms73PvXz9bPkgjW5Y1Y1s+aUY2YA4GDGrKGZtTCNiBnDgkzSYpvDRt0iRvm0Wy03JqVgIlCd17Q1ZaJziEksqE4G7IZr1JCIcQQkiKKQlQWCTbkm3A2BrJtuyRdf69f8yj8YwOtqTRaA76ftaa5fHMM89zj2ucXrrv635St9o6HLCTnevBPetoTYVWLqjUxScsSt7LOkLPGgAwOSb6R7grJMUkDcxyL5X0kpm9x93fTT/Q3TdK2ihJDQ0NPvhEAAAA4+lZN9Qd7llHa0JaPK9c0+lZAwDyZEJDt7u/ImnBwO/NrFlSA7uXAwCAkfT1u97ee0jb4geH3HprcM86Qs8aAFBksr1lWKOktZLCZvaWpFvd/b6JGBgAACgdI/Wsm1sT2tHaoe6+/tSx6T3raHhpMliHKxUNV2jO7Bl5/BYAAIxdtruXX3uU96PZnB8AABSXsfasV0RCuuj4hfSsAQAli205AQDAmBzuWaeF6uB5/ODhnrWZtLS6XLFwpRrq5qeWg8fC9KwBAFMHoRsAAAwxnp71RcfTswYAYDBCNwAAU5S7q+VgV8aO4ANLwofrWcciITVEqxWjZw0AwKgRugEAKHHtnT2pYD0Qqgd61we7elPHzZw+TdHw4Z51LFyhWLhSsXBI4Up61gAAjAehGwCAEtDZ06cdbR3a1jL6nvXpddX0rAEAyDFCNwAARSK9Zz14h/C392X2rMOVs1QfDunCVQtTu4LXh5M969kz6FkDADBZCN0AABSQ8fSsT6+r1odPp2cNAEAhInQDAJAH7Z1p97NOC9jD9azraiqSs9bHL0jez5qeNQAARYPQDQBAjmTTs44Gy8HpWQMAUNwI3QAAZKGv3/XOvkPJJeAtB+lZAwCADIRuAACOYkjPujWRer59UM+6claZ6iMhnba8Wh86banqg3AdDYc0l541AABTDqEbAIDAWHvWsXBIF9CzBgAAR0DoBgBMKV29fdrR2pFaAj4wY70tnlD8YFfqODNpybxyxcIhfei0Jcl7WUcq6VkDAIAxIXQDAErO+HrWC1I961g4pOX0rAEAwAQgdAMAipK7K36wO7Ur+Lb4kXvWsTA9awAAMPkI3QCAgnagsyfVqx7oWTcHG5kdGKlnvWpBasY6FgkpUjmLnjUAAMgLQjcAIO/G07P+ID1rAABQBAjdAIBJMdCzTt8RfFuwNPztvYfUn9GznhnMWEdSu4LXR+hZAwCA4kPoBgBMmPH0rNcsq9YH19CzBgAApYnQDQAYswOdPWqOd2hb/GDGzPXgnvWM6aa6mhA9awAAMGURugEAwxqpZ93UmlDLgeF71h8Y6FmHQ6oPV2rxvNkqmz4tj98CAAAgv7IK3RZ3jDsAACAASURBVGa2SdJ6SXvc/aTgta9L2iCpW9L/lfRJd9+X7UABABNvPD3rdcfRswYAABitbGe675d0r6QH0l57QtJ/d/deM/tHSf9d0hezvA4AYJzSe9bNaaE6eeutDnX3Hu5Zh2ZOVywS0qnLqvWBNUtVHz7cs64qp2cNAAAwVlmFbnd/1syig177WdpvX5D04WyuAQAYnfH0rNcdR88aAAAgl3Ld6f5zSQ/l+BoAMGV09fZpZ1uHtrUMXg4+tGe9uKpc9RF61gAAAPmUs9BtZn8nqVfSD0Z4/0ZJN0rS8uXLczUMACg6w/WsBx5v7e0YsWcdDYeC5eCVqquhZw0AAFAIchK6zewTSm6wdqG7+3DHuPtGSRslqaGhYdhjAKBUubtaE92p5d+j6VmfsmyerlyzhJ41AABAEZnw0G1ml0q6SdL57t4x0ecHgGKS3rNujnekgvW2eEIHOjN71svnVygWrtTatJ51fTikyBx61gAAAMUq21uGNUpaKylsZm9JulXJ3cpnSXoi+H8SX3D3T2U5TgAoWOPqWa853LOOhUNaMq+cnjUAAEAJynb38muHefm+bM4JAIWov9/1zv7DPev0gD24Z10TSvas1x4bUSxCzxoAAGAqy/Xu5QBQNEbqWTfHO9TUmjhizzoWTi4Nj9WEVFVBzxoAAABJhG4AU87Brl41DywBb0mMqmd9/nERetYAAAAYM0I3gJI00LNuSt+8LFgSvmeYnnUsHNKVpwY962BJOD1rAAAAZIvQDaBojadnfT49awAAAEwiQjeAgubuagt61gM7gjcF4bq5NaGutJ51xczpioVDOnlpla48dbFikRA9awAAAOQVoRtAQRipZ90UT6j9KD3raE1I9ZGQFtCzBgAAQIEhdAOYNN29/drR1hGE6ZF71pK0ZF6yZ30FPWsAAAAUMUI3gAk1uGed/tjZNrRnHQ2HdN6xkdSu4LFIcuaanjUAAABKAaEbwJiNp2e9ekmVrjiFnjUAAACmFkI3gBElunqHzFYnO9cHM3rWZdNMy2sqVB8O6bxjw8lQHaZnDQAAABC6gSku2551rCakpdX0rAEAAIDhELqBKaC/37WrvTO1K/i2I/Ss5wf3sx7cs66bH1L5THrWAAAAwFgQuoESMVzPujktXA/Xsz5pSZXef8ri5Kx18JhXMTOP3wIAAAAoLYRuoMiMp2d97jH0rAEAAIB8IHQDBWigZ92cHqqDvvXu9sye9eKq2YpFQnr/qYsVC1cml4OH6VkDAAAAhYDQDeTJkXrWb+09pL60ovVAz/rcY+hZAwAAAMWE0A3kkLtrb0dPMlS3JIYsC0/vWZfPoGcNAAAAlBpCNzABhutZDzz2H+pJHTe4Zx0NQnV9uFIL59KzBgAAAEoNoRsYpe7efu3c2xEsBx9dz3rDKbX0rAEAAIApjNANpMnoWbcmUn3rpnhCOwf1rKsrZigWDumclRHVRw4vBY/W0LMGAAAAkEToxpQznp71iUuqtIGeNQAAAIAxyip0m9kmSesl7XH3k4LX5kt6SFJUUrOkq9x9b3bDBMYu0dWr5tYgTGcsCR+mZz2/Ipi1DisWoWcNAAAAYGJkO9N9v6R7JT2Q9tqXJD3p7nea2ZeC338xy+sAw8qmZx0LVygWrtTS6nLNoGcNAAAAIAeyCt3u/qyZRQe9fIWktcHz70t6RoRuZKG/3/Vue+fhUE3PGgAAAECRyEWne6G77wqevytpYQ6ugRKT3rNuinekQvW2loSaWxPq7MnsWUfDIZ24uErrTw561pGQYjUhVYfoWQMAAAAoHDndSM3d3cx8uPfM7EZJN0rS8uXLczkMFJCO7rT7WdOzBgAAAFDichG6d5tZrbvvMrNaSXuGO8jdN0raKEkNDQ3DBnMUp56+fu1s60iF621pAfvd9s6MY2urZisWDmn9ybXJUB0J0bMGAAAAUDJyEbofk3SdpDuDXx/NwTWQZ+PpWZ+9MpzavCwWDikarlDFTO5aBwAAAKB0ZXvLsEYlN00Lm9lbkm5VMmz/0Myul7Rd0lXZDhL5szfRnVr+faSe9ewZ0xQLV9KzBgAAAIA02e5efu0Ib12YzXkxudJ71s1pHeumeEL7Oob2rKOpWeuQ6oNwvXDObE2bRs8aAAAAANKxtneKGE/P+vLV9KwBAAAAIBuE7hLS3+/afaBTTS2Zs9VN8YR2tHVk9KyrymeoPhLSWStrkrPV9KwBAAAAYMKRrorQSD3r7a0dOtTTlzpuoGd9Qu1cXb66VtFwKLUknJ41AAAAAOQeobtAdXT3qjnekQrWI/Wsp6fdz5qeNQAAAAAUFkJ3Hg3uWac/du0fvmd92eraYDl48rFsfgU9awAAAAAoUITuHBtPz/rMFfSsAQAAAKAUkOQmyL6O7owdwQd2CG+OJ4b0rKM1IR1fO0eXrV6UCtb0rAEAAACg9BC6x+BQd592tPfp8d/vGnXP+qwVNaml4LFwSIvm0rMGAAAAgKmC0D0GD/y6WXc83yk9/5IkadFcetYAAAAAgJERusfgohMWav87Tbr8/D9RtCak0Cz++AAAAAAAIyM1jsGKSKXeU1umExdX5XsoAAAAAIAiwBpoAAAAAAByhNANAAAAAECOELoBAAAAAMgRQjcAAAAAADli7p7vMcjMWiRtz/c4RiksKZ7vQQAAAABAiSum7FXn7pHh3iiI0F1MzOxFd2/I9zgAAAAAoJSVSvZieTkAAAAAADlC6AYAAAAAIEcI3WO3Md8DAAAAAIApoCSyF51uAAAAAAByhJluAAAAAAByhNA9Sma2ycz2mNmr+R4LAAAAAJQiM1tmZk+b2X+Z2Wtm9rl8jylbLC8fJTM7T9JBSQ+4+0n5Hg8AAAAAlBozq5VU6+4vmdkcSVslXenu/5XnoY0bM92j5O7PSmrL9zgAAAAAoFS5+y53fyl4fkDS65KW5HdU2SF0AwAAAAAKjplFJa2R9Jv8jiQ7hG4AAAAAQEExs0pJj0j6vLu353s82SB0AwAAAAAKhpnNUDJw/8Ddt+R7PNkidAMAAAAACoKZmaT7JL3u7nfnezwTgdA9SmbWKOnXko4zs7fM7Pp8jwkAAAAASszZkj4u6QIzezl4XJbvQWWDW4YBAAAAAJAjzHQDAAAAAJAjhG4AACaRmf2dmb1mZr8Plsz9afD6582sIg/jiZrZqzk6d7OZhXNxbgAAikVZvgcAAMBUYWZnSlov6TR37woC6czg7c9LelBSR77GBwAAJh4z3QAATJ5aSXF375Ikd4+7+ztm9llJiyU9bWZPS5KZXWJmvzazl8zs4eB+pQOzx3eZ2Stm9lszWxm8/hEze9XMfmdmzw6+sJlVmtmTwfleMbMr0t6ebmbfCWbgf2Zm5cFnVpjZT8xsq5n90sxWBa9vMLPfmNl/mtnPzWxh8HpN8PnXzOy7kixnf5IAABQJNlIDAGCSBMH5OUkVkn4u6SF3/0XwXrOkBnePBzPgWyS9z90TZvZFSbPc/R+C477j7l81s/8m6Sp3X29mr0i61N3fNrN57r5v0LXLJFW4e3tw/hckHSOpTtIfg2u/bGY/lPSYuz9oZk9K+pS7/yFYBn+Hu19gZtWS9rm7m9kNko539781s/+l5A8V/sHMLpf0fyRF3D2ewz9WAAAKGsvLAQCYJO5+0MxOl3SupHWSHjKzL7n7/YMOPUPSCZJ+lbxdqWYqedvKAY1pv/5T8PxXku4PQvOWYS5vkr5mZudJ6pe0RNLC4L0md385eL5VUjT4AcFZkh4OxiBJs4JflwZjrw3G1hS8fp6kDwbf9XEz23vkPxEAAEofoRsAgEnk7n2SnpH0TDA7fZ2k+wcdZpKecPdrRzrN4Ofu/qlgNvpySVvN7HR3b0077mOSIpJOd/eeYMZ8dvBeV9pxfZLKlayg7XP3U4e5/j2S7nb3x8xsraTbRvzCAABMcXS6AQCYJGZ2nJkdk/bSqZK2B88PSJoTPH9B0tlpfe2QmR2b9rmr0379dXDMCnf/jbvfIqlF0rJBl6+StCcI3OuUXFY+Indvl9RkZh8Jzm9mdkraud4Onl+X9rFnJX00OP59kqqPdA0AAKYCZroBAJg8lZLuMbN5knqV7FLfGLy3UdJPzOwdd19nZp+Q1GhmA0u6/17Sm8HzajP7vZIz1AOz4V8PAr1JelLS7wZd+weSfhzMrr8o6Y1RjPdjkr5tZn8vaYakzcF5b1Ny2fleSU9JigXH3x6M+TVJz0vaMYprAABQ0thIDQCAIpK+4Vq+xwIAAI6O5eUAAAAAAOQIM90AAAAAAORIQXS6w+GwR6PRfA9jVBKJhEKhUL6HAQAAAAAlrZiy19atW+PuHhnuvYII3dFoVC+++GK+hzEqzzzzjNauXZvvYQAAAABASSum7GVm20d6j043AAAAAAA5QugGAAAAACBHCN0AAAAAAORIQXS6AQAAAABwd7UlutUUT6j1UH++hzMhCN0AAAAAgEmV6OpVUzyR8dgWT6ip5aDaO3slSdeumqkP5XmcE2HcodvMlkl6QNJCSS5po7v/TzObL+khSVFJzZKucve92Q8VAAAAAFAsunv7taOtQ03xhJoHQnX8oJriCe1u78o4dsm8ckXDFXr/qYsVC1eqPhzS/u2v5mnkEyubme5eSX/r7i+Z2RxJW83sCUmfkPSku99pZl+S9CVJX8x+qAAAAACAQtLf79rV3qmmlmSg3pY2c72zrUP9fvjY+aGZioVDOveYiGLhkOrDIcUiIdXND6l85vQh537m3dLYgmzcodvdd0naFTw/YGavS1oi6QpJa4PDvi/pGRG6AQAAAKAoubv2dvQkQ3VLYsiy8K7ew93r8hnTFQuHdNKSKr3/lMWKhUOpx7yKmXn8FvkzIZ1uM4tKWiPpN5IWBoFckt5Vcvk5AAAAAKCAjdSzbo4ntP9QT+q4smmm5TUVqg+HdO4xYUWDUF0frtTCubNkZnn8FoUn69BtZpWSHpH0eXdvT/8Ddnc3Mx/hczdKulGSli9fnu0wAAAAAABH0d3br517O4Ll4EfuWS+umq1YJKQNp9SmetaxcEhLq8tVNr00ln5PhqxCt5nNUDJw/8DdtwQv7zazWnffZWa1kvYM91l33yhpoyQ1NDQMG8wBAAAAAGOT0bNuTaT61k3xhHbuPaS+tKL1QM/6nJUR1UcOLwWP1gzfs8bYZbN7uUm6T9Lr7n532luPSbpO0p3Br49mNUIAAAAAQIbx9KxPXFKlDfSsJ102M91nS/q4pFfM7OXgtS8rGbZ/aGbXS9ou6arshnh0999/v+655x69+eabKisrUzQa1bp163T33Yd/FjCw7P1f//Vf9Wd/9mcZn3/wwQf18Y9/XFLyL+9w5//kJz+pj33sY7rhhhuGvL927Vr94he/kCRNnz5ddXV1ev/736/bb79dc+fOHXLMYDt37tTSpUuP+j3vuusuvec979HatWuPeuxY5fLcAAAAAMYn0dWr5tYgTGcsCR+mZz2/Ipi1DisWoWddKLLZvfw5SSP9X+7C8Z53rO644w7dfPPNuummm3TnnXeqs7NTW7du1YMPPpgRuiWpsrJSmzdvHhK6GxsbVVlZqYMHDw57jcbGRknSo48+mgrng61bt05f+9rX1Nvbq//4j//QzTffrJ07d+pHP/rRkGMGW7Bgwai+61133aXPfOYzOQvduTo3AAAAgJFl07OOhSsUC1dqaXW5ZtCzLkgTsnt5Pt177736i7/4i4wwu2HDBt16661Djt2wYYN+9KMfae/evaqurpYktbW16YknntBHPvIR/du//duQz+zZs0dPPvmkLrzwQj355JN6/vnn9d73vnfIcfPnz9cZZ5whSTrnnHOUSCR08803q6WlRZFIZMgxAAAAAKaO/n7Xu+2dh0P1EXrW1RUz6FmXkKL/Uci+ffu0aNGiIa8Pt3zizDPP1OLFi/XII4+kXnvkkUe0ePFinXnmmcOe/+GHH1ZfX5/uvfdeLVmyRE899dSoxnX66adLkpqbm0d1/NFEo1G1trbq9ttvl5nJzPTMM89Ikvr7+3XnnXdq5cqVmjVrlo499lh9//vfz/j8c889p3PPPVdz587V3Llzdeqpp+rhhx8+6rkBAAAAjI67qy3Rra3b2/Twizv19Z++ob/6wVZd+j+e1Qm3/kRn3fmUPvbd3+jm//2qGn+7Q7vbu3Tikir95fkr9M2PnKItf3WW/vPmi/Wft1yiLX91tr551Sn69LqVumx1rY6vnUvgLlJFP9N92mmn6Z577tHy5cu1fv161dTUjHismenqq69WY2Njqpvd2Nioa665ZsTPNDY2as2aNVq1apWuvvpq3XPPPdq/f7+qqqqOOK6BsJ3+AwF3V29v75AxTZ9+9P94/v3f/13r1q3Thz/84dTYTzjhBEnSX//1X+v73/++brnlFp122ml64okn9Od//ueqqanR+vXr1d7ervXr1+uKK67QLbfcInfXK6+8on379h313AAAAAAydXSn3c+anjWOouhD97e+9S1deeWV+sQnPiEz0/HHH68PfehD+sIXvpDaxCzdNddco29+85vavXu33F2/+MUvdPfdd+u5554bcuyOHTv0/PPP684775QkXXvttbr77ru1ZcsWffKTn8w4diBQ9/X16be//a2++tWvqqGhIWODtC1btmjGjBkZn6urqxvVbPiaNWtUVlampUuXZixR/+Mf/6hvf/vb+t73vqfrrrtOknTRRRdp165duv3227V+/Xq9+eab2r9/v+69917NmTNHknTJJZcc9dwAAADAVNXT16+dbR2pcL0tLWC/296ZcWxt1WzFwiGtP7k2GaojIXrWSCn60H3yySfr9ddf189+9jP99Kc/1VNPPaWvfOUr2rx5s1566SVVVlZmHL9mzRqtXLlSP/zhD+XuOvbYY3XqqacOG7o3b94sSbr66qslSQ0NDVqyZIkaGxuHhO7Bgfrss8/Wpk2bMn56dcEFF+gf//EfMz43a9asrL7/k08+qWnTpukDH/hAxiz6hRdeqMbGRvX19WnFihWqrKzURz/6Ud1www06//zzNW/evKyuCwAAABS78fSsz14ZTvWsozUhRcMVqphZ9LEKOVQSfztmzZqlDRs2aMOGDZKk++67TzfccIPuu+8+fe5znxty/NVXX63NmzfL3VOBejiNjY067bTTVFVVlVqKfdZZZ2nLli3avXu3Fi5cmDp2IFCXlZWprq4utVFbuurqajU0NGT7dTPE43H19fWNuNx9165dWrp0qZ544gnddtttuuqqq9Tf369LLrlE99xzj+rr6yd0PAAAAECh2ZvoTi3/HgjV21oSam5NqLPn8P2sZ8+Ypli4UicurtL6k4P7WUdCitWEVB3iftYYn5II3YNdf/31uummm/TGG28M+/4111yjr3zlK5KkTZs2DXvMG2+8oZdfTt5+fLgA/fDDD+szn/lM6ve5CNSjMX/+fJWVlelXv/qVpk0bunRl4HZkZ5xxhn7yk5/o0KFD+vnPf66/+Zu/0Uc/+lG98MILkz1kAAAAYMKl96yb0zrWTfGE9nUM37M+e2U46Fgnw/XCObM1bRo9a0ysog/de/bsGXKf65aWFu3fvz9jJjrd8ccfrxtvvFGStGrVqmGPaWxs1PTp0/XYY4+poqIi9frLL7+s733ve2psbMwI3ZNh5syZ6uzM7I9ccMEF6uvr0/79+3XxxRcf9Rzl5eXasGGDXn31Vd1xxx1HPDcAAABQSMbTs758NT1r5FfRh+7Vq1friiuu0CWXXKIFCxZo+/bt+sY3vqGKiorUxmLD+ed//ucjnrexsVEXX3yxLrvssiHvXXfddfrCF76g7du3q66ubtRjbWtrG3Zm+cQTT0xtcHYkq1at0uOPP65LL71UlZWVOu6443TcccfpU5/6lK655hrddNNNamhoUGdnp1577TW9+eab+u53v6vHH39cmzZt0pVXXqnly5fr7bff1r/8y7/oggsuOOK5RzMmAAAAYCL197t2H+hUU0vmbHVTPKEdbR0ZPet5Qc/6rJU1ydnqcGWya03PGgWk6P8m3nLLLXr00Uf12c9+Vm1tbVq0aJHOOussPfTQQ4rFYuM659atW/WHP/xBt91227DvX3vttbrpppu0efNmffGLXxz1eZ9++ulh7wf+y1/+Uuecc85RP//1r39dn/70p3X55Zero6NDTz/9tNauXatvfetbOvbYY/Wd73xHt9xyi+bOnasTTjhB119/vSRp5cqVMjN9+ctf1p49exSJRLR+/Xp97WtfO+q5AQAAgFwYqWe9vbVDh3r6UscN9KxPqJ2bmrWmZ41iYu5+9KNyrKGhwV988cV8D2NUnnnmGcIoAAAAMAod3b1qjnekgvVIPevpaT3rgQc9axRT9jKzre4+7CZfRT/TDQAAACB/Bves0x+79h+5Zz3wWDa/gp41Shahu0D09fVppFUHZqbp06dP8ogAAACApLH0rKvKZ6g+EtKZK+hZAxKhu2CsWLFC27dvH/a9uro6NTc3T+6AAAAAMOXs6+jO2BF8YIfw5nhiSM86WhPS8bVzdNnqRalgXR+mZw0MRuguED/+8Y/V1dU17HuzZs2a5NEAAACgVI2nZ33Wihp61sA4EboLxOrVq/M9BAAAAJSInr5+vbX3UDJUtxy5Z71obrJnfdnq2mA5OD1rYCIRugEAAIAi5O56tz3Zs25qzVwSvqOtQ71H6FlHg2AdrQkpNItIAOQS/4UBAAAABWysPetVtXP0PnrWQMEgdAMAAAB5dqi7T82taaG6Jdm3boontHeYnnW0pkJn1tcoFgmlloQvmkvPGihEhG4AAABgEozUs26OJ/TOCD3r99GzBooeoRsAAACYIO6u3e1d2hbMUh+pZz13dpnqI5U6oz65M3gsQs8aKEX81wwAAACM0UDPujmtYz0QsEfTs46FQ6qumCEzloMDpY7QDQAAAAxjLD3rZdXlioVDyVlretYA0hC6AQAAMGX1pnrWwWx12rLw4XrW0XCFLj0prWcdCWlZdYVmltGzBjA8QjcAAABKGj1rAPmU1b8cZrZJ0npJe9z9pOC1UyX9s6TZknol/ZW7/zbbgQIAAABHsr+j53CwTutZN7cm1NF9uGc9q2yaYuGQjls0R5eetCh5L+tISLFwJT1rABMu2x/X3S/pXkkPpL12l6Tb3f3/M7PLgt+vzfI6AAAAwJCedfqjLdGdOo6eNYBCkVXodvdnzSw6+GVJc4PnVZLeyeYaAAAAmFrG0rNeOHeWYuGQ3nviInrWAApSLoopn5f0UzP7hqRpks7KwTUAAABQxNxdew50BTuCHw7W2+IJ7Wgdvmf9pwM967QHPWsAhS4X/0r9paT/190fMbOrJN0n6aLBB5nZjZJulKTly5fnYBgAAADItzH3rBfO0aUn0rMGUDpyEbqvk/S54PnDkr473EHuvlHSRklqaGjw4Y4BAABA4evsCXrWLQPLwYfvWU8zadn8CsXCIf1p/fxgOXilYpGQaulZAyhRuQjd70g6X9Izki6Q9IccXAMAAACTKL1nPfjx9r5DGccO17OOhkNaPp+eNYCpJ9tbhjUquTN52MzeknSrpP9H0v80szJJnQqWkAMAAKCwHalnvbOtQz19hxcnzgl61u+Jzc/oWEfDIVXSswaAlGx3L792hLdOz+a8AAAAyJ39HT1qag1C9aAl4SP1rN870LMOwvX80Ex61gAwCvwYEgAAoASN1LNujifUOkLP+j0xetYAMNEI3QAAAEWqt69fb+87lNoR/Eg96wVzkj3rS05cGCwFr1SMnjUA5ByhGwAAoICl96ybW4PbbrUkl4bvoGcNAAWPf30BAAAKwP5DPYc3L0tbEt4cTyiR1rOeWTZNsZqQjlkwR5fQswaAgkfoBgAAmCSdPX3a3tqhpvjBIUvCj9SzTp+1XlxVTs8aAIoIoRsAAGACHaln/c7+Q/LDq8HpWQPAFEDoBgAAGCN3V8uBroxdwY/Ysw6H9CfRasXCyxSLJJeD07MGgKmBf+kBAABGkNGzjndkdK7pWQMARoPQDQAAprSx9KyXVid71g1181UfoWcNADg6QjcAACh5ff2ut/ce0rb4wYyO9baWo/esozUh1UdCWja/QrPKpufvSwAAihKhGwAAlIQx9axnlak+Qs8aAJB7/K8KAAAoKvsP9ah5IFSnAvbwPetoTYVWLqjUxScsSnasgyXhNfSsAQCThNANAAAKTnrPOrmB2eFl4fGDo+tZ11aVazo9awBAnhG6AQBAXoylZx0JetYXHb8wFarpWQMAigGhGwAA5Iy7q+VgV8aO4ANLwne0dqi7rz917HA961hNSNFwhebMnpHHbwEAwPgRugEAQNbaO3tSwTq9Z90c79DBrt7UcQM96xWR5Kw1PWsAQKkjdAMAgFHp7OnTjraOYEfwxKh71gPLwWPhkBbPo2cNAJhaCN0AACAlvWc9eIfwt/fRswYAYKwI3QAATDFj7VnHIiGdXletD5++NBmsw5X0rAEAGCVCNwAAJaq9M+1+1mkBuymeGFXPOloTUriSnjUAANkgdAMAUMRG27M2k5ZWlysWrtTpddX0rAEAmCSEbgAAClxfv+udfYeSS8BbDo66Zx0d6FmHkz3r2TPoWQMAMNkI3QAAFIAhPevWROr5dnrWAAAULUI3AACTaNQ96+nTVFeTvO3WBccvSPasw5WKhelZAwBQTAjdAABMsK7ePu1o7UgtAR+Ysd4WTyh+sCt1HD1rAABKH6EbAIBxGEvPOlw5S/XhkC5ctUCxCD1rAACmkqxCt5ltkrRe0h53Pynt9b+W9GlJfZIed/ebsholAAB54O6KH+xO7Qq+LT5yz7pyVpnqg571h05bqvogXEfDIc2lZw0AwJSV7Uz3/ZLulfTAwAtmtk7SFZJOcfcuM1uQ5TUAAMipA509Gd3qprRl4QfoWQMAgCxkFbrd/Vkziw56+S8lW+ymuwAADXZJREFU3enuXcExe7K5BgAAE2EsPesl88oVC4f0wdOWJDvWkUrV07MGAADjkItO97GSzjWzr0rqlPQFd/+PHFwHAIAMAz3r9NnqbcHS8Lf3HlI/PWsAADDJchG6yyTNl3SGpD+R9EMzq3dP31JGMrMbJd0oScuXL8/BMAAApeiIPeu2DnX3ZvasY+GQ1iyr1gfX0LMGAACTLxeh+y1JW4KQ/Vsz65cUltSSfpC7b5S0UZIaGhp8yFkAAFPagc4eNcc7tC1+cEw961hNcNutSEiRyln0rAEAQF7lInT/b0nrJD1tZsdKmikpnoPrAACKXHrPujljOXhCLQfoWQMAgOKX7S3DGiWtlRQ2s7ck3Sppk6RNZvaqpG5J1w1eWg4AmDrG2rOOhSu07rhIalfw+khIy+lZAwCAIpXt7uXXjvDWn2VzXgBAcXF3tSa6U8u/B0J1Uzyh5lZ61gAAYOrKxfJyAECJGm3PesZ0U13QrV533ILkcnB61gAAYAoidAMAMnT19mlnW4e2tQxeDn70nnU0HFJ9uFJLqulZAwAASIRuAJiS0nvWza2JjID91t6OQT3rmcGMNT1rAACAsSJ0A0CJGkvPOjRzumKRkE5ZNk9Xrlmi+vDhnnVVOT1rAACA8SJ0A0CRO9jVq+aBJeAth4P1tnhCBzrpWQMAAOQToRsAisBIPevmeEJ7BvWsF1eVqz4S0gfWLEkF6/pwpRbPm62y6dPy+C0AAACmHkI3ABSI/n7XO/sP3896ND3rtWk961g4pLoaetYAAACFhNANAJMoo2eddrutpnhCTa0JetYAAAAlhtANADkw1p51tCak84+LpC0HDykyh541AABAsSN0A8A4dff2a0dbRzBjfTBjSTg9awAAAEiEbgA4orH0rGtCyZ71+cdGFIuEguXglfSsAQAApjBCN4Apz93VFvSstw3qWTe3JtRFzxoAAADjROgGMGWk96yb02671dRyUO2DetbL51coFq6kZw0AAICsELoBlJTx9KyvODXoWQdLwpfMK6dnDQAAgAlB6AZQdPr7XbvaO1O7gm9Lu/3WzjZ61gAAACgchG4ABWksPeuKmdMVC4e0ekmVrjhlsWKRZLCO1YRUVUHPGgAAAPlD6AaQV4mu3tQsdRM9awAAAJQYQjeAnEvvWTenZq6Tfevd7V0Zxy6ZV65YmJ41AAAASgOhG8CEGE/P+rxjkj3rWE0yXEdrQvSsAQAAUFII3QBGzd21t6MnGapbEkOWhdOzBgAAADIRugEMMVLPujme0P5DPanjZkw3LZtfofpwSOceE06G6nBI9ZGQFtCzBgAAAAjdwFTV3duvnXs7UjuCj6Zn/f5TFtOzBgAAAMaA0A2UsIyedWsi1bduiie0c+8h9aUVrecHPetzj4mkdgWPRUKqmx9S+Ux61gAAAMB4ELqBIjeenvVJS6qSs9bB5mWxcEjzKmbm8VsAAAAApYnQDRSJRFevmluDMJ2xJDyzZ102zbS8hp41AAAAUAiyCt1mtknSekl73P2kQe/9raRvSIq4ezyb6wBTxVh71tFwhTacUqtYuDK5HDwc0tJqetYAAABAoch2pvt+SfdKeiD9RTNbJukSSTuyPD9Qcvr7Xe+2dx4O1fSsAQAAgJKVVeh292fNLDrMW/8k6SZJj2ZzfqBYDe5ZDywLH3je2XO4Z10+I9mzPnFJlTYM7A4epmcNAAAAlIIJ73Sb2RWS3nb339EdRanr6E67n/U4etaxcEgL59KzBgAAAErVhIZuM6uQ9GUll5Yf7dgbJd0oScuXL5/IYQATqqevXzvbOlLheltawH63vTPj2MVVsxWLhOhZAwAAAJA08TPdKyTFJA3Mci+V9JKZvcfd300/0N03StooSQ0NDT74RMBkGk/P+uyVYdVHDi8Fj9bQswYAAACQaUJDt7u/ImnBwO/NrFlSA7uXo1DsTXSnln8PhGp61gAAAAByJdtbhjVKWispbGZvSbrV3e+biIEB45Xes25O61g3xRPa1zGoZz2/QrFwSOesDCsWzFrXhyvpWQMAAACYENnuXn7tUd6PZnN+YCTj6VmvP7k22MCsQrFwpZZWl2sGPWsAAAAAOTThu5cDE6W/37X7QKeaWjJnq5viCe1o68joWVdXzKBnDQAAAKDgELqRdyP1rLe3duhQT1/quIGe9QmL5+ry1bXJYB0JKVYTUnWInjUAAACAwkPoxqTo6O5Vc7wjFazpWQMAAACYCgjdmDCDe9bpj137M3vWtVWzFQuHUjPWySXh9KwBAAAAlBZCN8ZkPD3rs1Yc7llHa0KKhitUMZO/egAAAABKH8kHw9rX0Z2xI/jADuHN8URGz3r2jGmKhSt1Qi09awAAAAAYjNA9hY2nZ33WipqgY50M1wvnzNa0afSsAQAAAGA4hO4S19PXr7f2HkqG6hZ61gAAAAAwmQjdJcDd9W57smfd1Jq5JHxHW4d603rW84Ke9ZkrapKz1eHKZNeanjUAAAAATDhSVhEZa8/6+Nq5uoyeNQAAAADkDaG7wBzq7lNza1qobkn2rZviCe1N61lPp2cNAAAAAAWP0J0HI/Wsm+MJvTNCzzo1Yx08ls2voGcNAAAAAAWO0J0j7q7d7V3aFsxSH6lnXVU+Q/WRkM6gZw0AAAAAJYVEl6WBnnVzWsd6IGAP7llHa0JaVTtH71u9KBWs68P0rAEAAACgVBG6x+C1d/brx/+3Wz/e87uj9qzPpGcNAAAAAFMeoXsMXtq+V4/8oUeL5sYVC4f0vtW1wXJwetYAAAAAgKEI3WPwwdOWKpJo0qUXrcv3UAAAAAAARYBp2TEIzSrT7DKWiAMAAAAARofQDQAAAABAjhC6AQAAAADIEUI3AAAAAAA5QugGAAAAACBHzN3zPQaZWYuk7fkexyiFJcXzPQgAAAAAKHHFlL3q3D0y3BsFEbqLiZm96O4N+R4HAAAAAJSyUsleLC8HAAAAACBHCN0AAAAAAOQIoXvsNuZ7AAAAAAAwBZRE9qLTDQAAAABAjjDTDQAAAABAjhC6R8nMNpnZHjN7Nd9jAQAAAIBSZGbLzOxpM/svM3vNzD6X7zFli+Xlo2Rm50k6KOkBdz8p3+MBAAAAgFJjZrWSat39JTObI2mrpCvd/b/yPLRxY6Z7lNz9WUlt+R4HAAAAAJQqd9/l7i8Fzw9Iel3SkvyOKjuEbgAAAABAwTGzqKQ1kn6T35Fkh9ANAAAAACgoZlYp6RFJn3f39nyPJxuEbgAAAABAwTCzGUoG7h+4+5Z8jydbhG4AAAAAQEEwM5N0n6TX3f3ufI9nIhC6R8nMGiX9WtJxZvaWmV2f7zEBAAAAQIk5W9LHJV1gZi8Hj8vyPahscMswAAAAAAByhJluAAAAAAByhNANAMAkMrO/M7PXzOz3wZK5Pw1e/7yZVeRhPFEzezVH5242s3Auzg0AQLEoy/cAAACYKszsTEnrJZ3m7l1BIJ0ZvP15SQ9K6sjX+AAAwMRjphsAgMlTKynu7l2S5O5xd3/HzD4rabGkp83saUkys0vM7Ndm9pKZPRzcr3Rg9vguM3vFzH5rZiuD1z9iZq+a2e/M7NnBFzazSjN7MjjfK2Z2Rdrb083sO8EM/M/MrDz4zAoz+4mZbTWzX5rZquD1DWb2GzP7TzP7uZktDF6vCT7/mpl9V5Ll7E8SAIAiwUZqAABMkiA4PyepQtLPJT3k7r8I3muW1ODu8WAGfIuk97l7wsy+KGmWu/9DcNx33P2rZvbfJF3l7uvN7BVJl7r722Y2z933Dbp2maQKd28Pzv+CpGMk1Un6Y3Dtl83sh5Iec/cHzexJSZ9y9z8Ey+DvcPcLzKxa0j53dzO7QdLx7v63Zva/lPyhwj+Y2eWS/o+kiLvHc/jHCgBAQWN5OQAAk8TdD5rZ6ZLOlbRO0kNm9iV3v3/QoWdIOkHSr5K3K9VMJW9bOaAx7dd/Cp7/StL9QWjeMszlTdLXzOw8Sf2SlkhaGLzX5O4vB8+3SooGPyA4S9LDwRgkaVbw69Jg7LXB2JqC18+T9MHguz5uZnuP/CcCAEDpI3QDADCJ3L1P0jOSnglmp6+TdP+gw0zSE+5+7UinGfzc3T8VzEZfLmmrmZ3u7q1px31MUkTS6e7eE8yYzw7e60o7rk9SuZIVtH3ufuow179H0t3u/piZrZV024hfGACAKY5ONwAAk8TMjjOzY9JeOlXS9uD5AUlzgucvSDo7ra8dMrNj0z53ddqvvw6OWeHuv3H3WyS1SFo26PJVkvYEgXudksvKR+Tu7ZKazOwjwfnNzE5JO9fbwfPr0j72rKSPBse/T1L1ka4BAMBUwEw3AACTp1LSPWY2T1Kvkl3qG4P3Nkr6iZm94+7rzOwTkhrNbGBJ999LejN4Xm1mv1dyhnpgNvzrQaA3SU9K+t2ga/9A0o+D2fUXJb0xivF+TNK3zezvJc2QtDk4721KLjvfK+kpSbHg+NuDMb8m6XlJO0ZxDQAAShobqQEAUETSN1zL91gAAMDRsbwcAAAAAIAcYaYbAAAAAIAcYaYbAAAAAIAcIXQDAAAAAJAjhG4AAAAAAHKE0A0AAAAAQI4QugEAAAAAyBFCNwAAAAAAOfL/A3cOvtyH9umKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the scores for each time step of the multi-step forecast\n",
        "scores = pd.DataFrame({\"rmse_test\":rmse_test, \"MAE_test\":MAE_test, \"R-squared_test\":r2_test, \"wMAPE_test\":wMAPE_test, \"SMAPE_test\":SMAPE_test})\n",
        "\n",
        "# Reset the index, keeping the old index as a column\n",
        "scores = scores.reset_index(drop=False)\n",
        "\n",
        "# Set the 'index' column as the new index\n",
        "scores.index = scores['index'] + 1\n",
        "\n",
        "# Drop the old 'index' column\n",
        "scores = scores.drop(columns='index')\n",
        "\n",
        "data = scores.columns\n",
        "\n",
        "# Creating figure with two rows and one column\n",
        "fig, axs = plt.subplots(nrows=len(data), figsize=(17, 15))\n",
        "\n",
        "axs = axs.ravel()\n",
        "\n",
        "for id, column in enumerate(data):\n",
        "    # Set the x-axis limits\n",
        "    #axs[id].set_xlim(xmin=1, xmax= steps_ahead)\n",
        "    #print the name of the test on plot\n",
        "    axs[id].plot(scores[column])\n",
        "    # Add a title to the x-axis\n",
        "    axs[id].set_xlabel('Steps ahead',fontsize=10, labelpad=0.1)\n",
        "    axs[id].grid(True)\n",
        "    # Remove the horizontal grid lines\n",
        "    axs[id].grid(which='both', axis='y')\n",
        "    axs[id].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "    axs[id].legend([column], loc='upper left', fontsize=15, handlelength=0, handletextpad=0, frameon=False)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doFyZoCCZ-ht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "7e9c5fc3-c49f-4bb3-c64c-ab373a761259"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the last forecasted values on test set\n",
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "# Set the major locator for the x-axis\n",
        "x = list(range(1, len(inv_yhat[-1])+1))\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "ax.plot(x, inv_yhat[-1], label = \"predicted\")\n",
        "ax.plot(x, inv_y[-1], label = \"actual\")\n",
        "ax.set_ylabel('Oil Rate', fontsize=15)\n",
        "ax.set_xlabel('Steps Ahead (Days)',fontsize=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PcMnvDfCdcQlg3ikKWSjWFO9GT6HGhdO",
      "authorship_tag": "ABX9TyPyQdShpnltmYGniOEOIKaJ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}