{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashrafalaghbari/oil-production-forecasting/blob/main/TCN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "x1LrkoSv4cc7",
        "outputId": "539dcd8b-77bc-49c2-875f-c8c224f2cf57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxzUA1Pg4iEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from numpy.random import randint, rand\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import re\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation, Dropout\n",
        "from keras.layers import LSTM, Conv1D\n",
        "from keras.layers import Input, Flatten\n",
        "from keras.models import Model\n",
        "import keras.backend as k\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt, inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6ZrWV9NpfPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417e3aae-4c6d-4e04-e5b8-80c4b1cfb0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu7vsRejtR_4"
      },
      "outputs": [],
      "source": [
        "# # check if GPU is utilized \n",
        "# device_name = tf.config.experimental.list_physical_devices()[-1][-1]\n",
        "# if device_name != 'GPU':\n",
        "#     raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVMp6qZiT9gO"
      },
      "outputs": [],
      "source": [
        "# Select the best features\n",
        "def select_features(df, target, correlation_type, threshold):\n",
        "    if (threshold < -1 ) | (threshold > 1 ) :\n",
        "            raise SystemError('correlation threshold is out of bounds')\n",
        "    features = df.corr(correlation_type).loc[target].drop(target)\n",
        "    best_features = features.where(abs(features) > threshold).dropna()\n",
        "    df = pd.concat([df[target], df[best_features.index]], axis=1)\n",
        "    return df\n",
        "\n",
        "# convert series to supervised learning using a sliding  window approach\n",
        "def series_to_supervised(data, columns, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('%s(t-%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "        # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# scale train and test data to new feature range[0, 1]\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        "\n",
        "\n",
        "\n",
        "# inverse differencing\n",
        "def inverse_difference(history, interval=1):\n",
        "\treturn history[-len(test_scaled)-interval:-interval]\n",
        "\n",
        "#Evaluation metrics\n",
        "# compute RMSPE\n",
        "def RMSPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
        "\tresult /= len(x)\n",
        "\tresult = sqrt(result)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute MAPE\n",
        "def MAPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += abs((x[i]-y[i])/x[i])\n",
        "\tresult /= len(x)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute wMAPE weighted absolute percentage error\n",
        "def wMAPE(actual, predicted): \n",
        "    result_nom = 0\n",
        "    result_deno = 0\n",
        "    for i in range(len(actual)):\n",
        "        result_nom +=  abs(actual[i] - predicted[i])\n",
        "        result_deno +=  abs(actual[i]) \n",
        "    result = result_nom/result_deno\n",
        "    return result *100\n",
        "\n",
        "def SMAPE(actual, predicted): #Symmetric (adjusted) MEAN ABSOLUTE PERCENTAGE ERROR (SMAPE)\n",
        "    result = 0\n",
        "    for i in range(len(actual)):\n",
        "        result += abs(actual[i] - predicted[i])/(abs(actual[i]) + abs(predicted[i]))\n",
        "    result = 2 * result/ len(actual) \n",
        "    return result * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRJsglCpLKHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c714708a-b479-411b-ba3a-f5a7fc944044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1907, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#load dataset\n",
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv', \n",
        "                     parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "days = pd.Series(range(len(series),0, -1 ), index=series.index)\n",
        "series.insert(0, 'days', days)\n",
        "series['days(t)'] = series['days'].shift(-1)\n",
        "series[\"AVG_CHOKE_SIZE_P(t)\"] = series['AVG_CHOKE_SIZE_P'].shift(-1)\n",
        "series[\"ON_STREAM_HRS(t)\"] = series['ON_STREAM_HRS'].shift(-1)\n",
        "series['interaction_effect_onNext_oilRate'] = series[\"AVG_CHOKE_SIZE_P(t)\"]  * series[\"ON_STREAM_HRS(t)\"] * series['days(t)']\n",
        "series.dropna(inplace=True)\n",
        "# # select feature based on correlation\n",
        "# # series = select_features(series, \"BORE_OIL_VOL\", \"spearman\", 0.2)\n",
        "# # select features manually\n",
        "series =series[[\n",
        "                'interaction_effect_onNext_oilRate',\n",
        "                \"BORE_GAS_VOL\", \n",
        "                \"BORE_OIL_VOL\"\n",
        "                ]] \n",
        "series.shape             "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grid search \n",
        "def get_hyper_param(n_epochs, n_filters_1, n_filters_2, n_filters_3, batch_size, window_size):\n",
        "\n",
        "    hyper_param = []\n",
        "    for current_params in itertools.product(n_epochs, n_filters_1, n_filters_2, n_filters_3, batch_size, window_size):\n",
        "        hyper_param.append(list(current_params))\n",
        "    return hyper_param\n",
        "\n",
        "# Seacrh space\n",
        "n_epochs = [500]\n",
        "n_filters_1 = [3, 6, 9]\n",
        "n_filters_2 = [3, 6, 9]\n",
        "n_filters_3 = [3, 6, 9]\n",
        "batch_size = [2, 4]\n",
        "window_size = [2, 4]\n",
        "\n",
        "hyper_param = get_hyper_param(n_epochs, n_filters_1, n_filters_2, n_filters_3, batch_size, window_size)\n",
        "len(hyper_param)# print the number of combinations\n"
      ],
      "metadata": {
        "id": "D0EVoWtzzMsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542e63b0-3587-454e-fca0-c2b6777fc334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the model and repeat the evaluation to reduce the certainty asscoicated with the random initialization of model weights\n",
        "# def run_model(n_repeats = 1):\n",
        "#     scores = [fit_lstm() for _ in range(n_repeats)]\n",
        "#     result = pd.DataFrame(scores)\n",
        "#     result = result.groupby(\"best_params\").mean()\n",
        "#     return result"
      ],
      "metadata": {
        "id": "Zpnlrc0t52h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_ahead = 1  \n",
        "    # Create a new directory in My Drive\n",
        "directory = '/content/drive/My Drive/my_trained_models'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "min_val_loss = inf \n",
        "for n_epochs, n_filters_1, n_filters_2, n_filters_3, batch_size, window_size in hyper_param:\n",
        "    print('n_epochs', n_epochs, 'n_filters_1', n_filters_1, 'n_filters_2',\n",
        "            n_filters_2,\"n_filters_3\", n_filters_3, \"batch_size\", batch_size, 'window_size', window_size)\n",
        "    \n",
        "    # setting the session configurations for reproducibility.\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    np.random.seed(42)\n",
        "    np.random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "    from keras import backend as K\n",
        "    tf.random.set_seed(1234)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                            config=session_conf)\n",
        "    K.set_session(sess)\n",
        "\n",
        "    #feature engineering\n",
        "    # # convert the stationary series to supervise learning\n",
        "    series_supervised = series_to_supervised(series, series.columns, n_in= window_size, n_out= steps_ahead, dropnan=True)   \n",
        "\n",
        "    # drop columns we don't want to predict\n",
        "    pattern = re.compile(r\"(t-)|^BORE_OIL_VOL.*\")\n",
        "    # Extract the column names that match the pattern\n",
        "    matching_columns = [col for col in series_supervised.columns if re.search(pattern, col)]\n",
        "    series_supervised = series_supervised[matching_columns]\n",
        "\n",
        "    # # split into train and test sets\n",
        "    series_supervised = series_supervised.values\n",
        "    train_size = int(series_supervised.shape[0] * 0.8)\n",
        "    test_size = series_supervised.shape[0] - train_size\n",
        "    train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "    # print(\"train.shape:\",train.shape, \"test.shape:\",test.shape)\n",
        "\n",
        "    # scale  the data to a feature range(0,1)\n",
        "    scaler, train_scaled, test_scaled = scale(train, test)\n",
        "    # print('train_scaled.shape:',train_scaled.shape, \"test_scaled.shape:\",test_scaled.shape)\n",
        "\n",
        "    # reshape input to be 3D [samples, window_size, features]\n",
        "    n_features = len(series.columns)\n",
        "    train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "    train_X = train_X.reshape(train_X.shape[0], window_size, n_features)\n",
        "    test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "    test_X = test_X.reshape(test_X.shape[0], window_size, n_features )\n",
        "    # print(\"train_X.shape:\",train_X.shape, \"train_y.shape:\",train_y.shape,\n",
        "    #         \"test_X.shape:\", test_X.shape,\"test_y.shape:\",test_y.shape)\n",
        "\n",
        "\n",
        "    # build the TCN model\n",
        "    input_tensor=Input(shape=(window_size, n_features))\n",
        "\n",
        "    #Feature extraction module\n",
        "    conv1 = Conv1D(filters = n_filters_1, kernel_size = 1, dilation_rate=1 ,padding='same')(input_tensor)\n",
        "    conv2 = Conv1D(filters = n_filters_2 , kernel_size = 1, dilation_rate=1, padding='same')(conv1)\n",
        "    # Time information extraction module\n",
        "    conv3 = Conv1D(filters = n_filters_3, kernel_size= window_size, dilation_rate=1, padding='causal')(conv2) \n",
        "    \n",
        "    conv3 = Flatten()(conv3)  \n",
        "    outputs = Dense(steps_ahead)(conv3)\n",
        "    model = Model(input_tensor, outputs)\n",
        "\n",
        "    model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
        "    #prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0,\n",
        "                                restore_best_weights=True, mode='min')\n",
        "\n",
        "    model.fit(train_X, train_y, epochs=n_epochs, batch_size=batch_size, callbacks = [early_stopping],\n",
        "                validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
        "    \n",
        "    current_val_loss = model.evaluate(test_X, test_y, verbose=2) #lstm_model.history['val_loss'][-1]\n",
        "    if current_val_loss < min_val_loss:\n",
        "        min_val_loss = current_val_loss\n",
        "        best_params = [n_epochs, n_filters_1, n_filters_2, n_filters_3, batch_size, window_size]\n",
        "    \n",
        "print('final best params',\"n_epochs:\",best_params[0],\"n_filters_1:\",\n",
        "        best_params[1], \"n_filters_2:\", best_params[2],\"n_filters_3:\", best_params[3], \"batch_size:\", best_params[4],\n",
        "        \"window_size:\",best_params[5]) \n",
        "print(\"best_params\", str(best_params) , \"MSE:\",str(min_val_loss))#, lstm_model  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lPUZyDQbe4Q",
        "outputId": "1514309a-1541-4f12-8f7c-c1a6b520bc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3949e-04 - 22ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.3626e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5159e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.5147e-04 - 32ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4834e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.3135e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.6128e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.4714e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.5016e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.3993e-04 - 30ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.7310e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 3 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.5338e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.5178e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.4054e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.6065e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.5643e-04 - 22ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4481e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.3212e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5945e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.4366e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3651e-04 - 30ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.4109e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4819e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 6 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.5641e-04 - 32ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4694e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.4682e-04 - 36ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5682e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.5823e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4511e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.4090e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.6155e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.4427e-04 - 29ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4000e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2904e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5241e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 3 n_filters_2 9 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3555e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3507e-04 - 28ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2273e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4493e-04 - 31ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3084e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3370e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.3488e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4558e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3236e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3720e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2531e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5456e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 3 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3127e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.2300e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2813e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.2748e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3500e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4338e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2086e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.6053e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.2168e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3427e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2300e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4748e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 6 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.2377e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4345e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.1774e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4550e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.1930e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4058e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2332e-04 - 28ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4275e-04 - 29ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.2358e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3522e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.1964e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.3707e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 6 n_filters_2 9 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.1703e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4135e-04 - 30ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.7339e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5234e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.6183e-04 - 36ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.4406e-04 - 27ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2986e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.5193e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.4298e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3795e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.4159e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4102e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 3 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.4091e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.2467e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2995e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.3604e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.4522e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3716e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2657e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4823e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.2727e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3364e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.4527e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.3583e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 6 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3381e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 3 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3861e-04 - 23ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 3 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.1360e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 3 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4118e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 3 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.1771e-04 - 22ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 6 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.3978e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 6 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.3677e-04 - 30ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 6 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.4168e-04 - 26ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 6 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.3394e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 9 batch_size 2 window_size 2\n",
            "12/12 - 0s - loss: 1.2838e-04 - 32ms/epoch - 3ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 9 batch_size 2 window_size 4\n",
            "12/12 - 0s - loss: 1.2621e-04 - 25ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 9 batch_size 4 window_size 2\n",
            "12/12 - 0s - loss: 1.3366e-04 - 24ms/epoch - 2ms/step\n",
            "n_epochs 500 n_filters_1 9 n_filters_2 9 n_filters_3 9 batch_size 4 window_size 4\n",
            "12/12 - 0s - loss: 1.1905e-04 - 26ms/epoch - 2ms/step\n",
            "final best params n_epochs: 500 n_filters_1: 9 n_filters_2: 9 n_filters_3: 3 batch_size: 2 window_size: 2\n",
            "best_params [500, 9, 9, 3, 2, 4] MSE: 0.00011360461212461814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # convert series to stationary \n",
        "series_diff = series.copy()\n",
        "# diff_order = 1\n",
        "# series_diff['BORE_OIL_VOL'] = series_diff['BORE_OIL_VOL'].diff(diff_order)\n",
        "steps_ahead = 1\n",
        "# Define window size and number of the steps ahead for forecasting\n",
        "n_epochs = 500\n",
        "n_filters_1 = 9\n",
        "n_filters_2 = 9\n",
        "n_filters_3 = 3\n",
        "batch_size =  2\n",
        "window_size = 4\n",
        "\n",
        "# # convert the stationary series to supervise learning using sliding window approach\n",
        "series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in= window_size, n_out= steps_ahead, dropnan=True)   \n",
        "\n",
        "# drop columns we don't want to predict\n",
        "pattern = re.compile(r\"(t-)|^BORE_OIL_VOL.*\")\n",
        "\n",
        "# Extract the column names that match the pattern\n",
        "matching_columns = [col for col in series_supervised.columns if re.search(pattern, col)]\n",
        "series_supervised = series_supervised[matching_columns]\n",
        "\n",
        "\n",
        "\n",
        "# # split into train and test sets\n",
        "n_features = int((len(series_supervised.columns) -steps_ahead)/window_size)\n",
        "series_supervised = series_supervised.values\n",
        "train_size = int(series_supervised.shape[0] * 0.8)\n",
        "test_size = series_supervised.shape[0] - train_size\n",
        "train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "print(\"train.shape:\",train.shape, \"test.shape:\",test.shape)\n",
        "\n",
        "# scale  the data to a feature range(0,1)\n",
        "scaler, train_scaled, test_scaled = scale(train, test)\n",
        "print('train_scaled.shape:',train_scaled.shape, \"test_scaled.shape:\",test_scaled.shape)\n",
        "\n",
        "# # reshape input to be 3D [samples, window_size, features]\n",
        "train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "train_X = train_X.reshape(train_X.shape[0], window_size, n_features)\n",
        "test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "test_X = test_X.reshape(test_X.shape[0], window_size, n_features )\n",
        "print(\"train_X.shape:\",train_X.shape, \"train_y.shape:\",train_y.shape,\n",
        "        \"test_X.shape:\", test_X.shape,\"test_y.shape:\",test_y.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# setting the session configurations for reproducibility.\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                        inter_op_parallelism_threads=1)\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), \n",
        "                            config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# build the TCN model\n",
        "input_tensor=Input(shape=(window_size, n_features))\n",
        "\n",
        "#Feature extraction module\n",
        "conv1 = Conv1D(filters = n_filters_1, kernel_size = 1, dilation_rate=1 ,padding='same')(input_tensor)\n",
        "conv2 = Conv1D(filters = n_filters_2 , kernel_size = 1, dilation_rate=1, padding='same')(conv1)\n",
        "# Time information extraction module\n",
        "conv3 = Conv1D(filters = n_filters_3, kernel_size= window_size, dilation_rate=1, padding='causal')(conv2) \n",
        "\n",
        "conv3 = Flatten()(conv3)  \n",
        "outputs = Dense(steps_ahead)(conv3)\n",
        "model = Model(input_tensor, outputs)\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
        "#prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0,\n",
        "                            restore_best_weights=True, mode='min')\n",
        "\n",
        "history = model.fit(train_X, train_y, epochs=n_epochs, batch_size=batch_size, callbacks = [early_stopping],\n",
        "            validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5HvpT9fISce",
        "outputId": "ea98baeb-8f0d-4029-de11-8e32c886d524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (1522, 13) test.shape: (381, 13)\n",
            "train_scaled.shape: (1522, 13) test_scaled.shape: (381, 13)\n",
            "train_X.shape: (1522, 4, 3) train_y.shape: (1522, 1) test_X.shape: (381, 4, 3) test_y.shape: (381, 1)\n",
            "Epoch 1/500\n",
            "761/761 - 2s - loss: 0.0468 - val_loss: 0.0019 - 2s/epoch - 3ms/step\n",
            "Epoch 2/500\n",
            "761/761 - 1s - loss: 0.0134 - val_loss: 0.0015 - 1s/epoch - 2ms/step\n",
            "Epoch 3/500\n",
            "761/761 - 1s - loss: 0.0112 - val_loss: 0.0012 - 1s/epoch - 2ms/step\n",
            "Epoch 4/500\n",
            "761/761 - 1s - loss: 0.0095 - val_loss: 9.9437e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 5/500\n",
            "761/761 - 1s - loss: 0.0081 - val_loss: 8.0533e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 6/500\n",
            "761/761 - 1s - loss: 0.0069 - val_loss: 6.4187e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 7/500\n",
            "761/761 - 1s - loss: 0.0059 - val_loss: 5.0605e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 8/500\n",
            "761/761 - 1s - loss: 0.0050 - val_loss: 3.9806e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 9/500\n",
            "761/761 - 1s - loss: 0.0044 - val_loss: 3.1634e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 10/500\n",
            "761/761 - 1s - loss: 0.0039 - val_loss: 2.5748e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 11/500\n",
            "761/761 - 1s - loss: 0.0036 - val_loss: 2.1671e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 12/500\n",
            "761/761 - 1s - loss: 0.0034 - val_loss: 1.8903e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 13/500\n",
            "761/761 - 1s - loss: 0.0032 - val_loss: 1.7024e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 14/500\n",
            "761/761 - 1s - loss: 0.0031 - val_loss: 1.5727e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 15/500\n",
            "761/761 - 1s - loss: 0.0030 - val_loss: 1.4806e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 16/500\n",
            "761/761 - 1s - loss: 0.0029 - val_loss: 1.4131e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 17/500\n",
            "761/761 - 1s - loss: 0.0028 - val_loss: 1.3619e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 18/500\n",
            "761/761 - 1s - loss: 0.0028 - val_loss: 1.3221e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 19/500\n",
            "761/761 - 1s - loss: 0.0027 - val_loss: 1.2903e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 20/500\n",
            "761/761 - 1s - loss: 0.0026 - val_loss: 1.2645e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 21/500\n",
            "761/761 - 1s - loss: 0.0026 - val_loss: 1.2430e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 22/500\n",
            "761/761 - 1s - loss: 0.0026 - val_loss: 1.2250e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 23/500\n",
            "761/761 - 1s - loss: 0.0025 - val_loss: 1.2097e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 24/500\n",
            "761/761 - 1s - loss: 0.0025 - val_loss: 1.1966e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 25/500\n",
            "761/761 - 1s - loss: 0.0024 - val_loss: 1.1854e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 26/500\n",
            "761/761 - 1s - loss: 0.0024 - val_loss: 1.1757e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 27/500\n",
            "761/761 - 1s - loss: 0.0024 - val_loss: 1.1675e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 28/500\n",
            "761/761 - 1s - loss: 0.0024 - val_loss: 1.1604e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 29/500\n",
            "761/761 - 1s - loss: 0.0023 - val_loss: 1.1545e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 30/500\n",
            "761/761 - 1s - loss: 0.0023 - val_loss: 1.1495e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 31/500\n",
            "761/761 - 1s - loss: 0.0023 - val_loss: 1.1455e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 32/500\n",
            "761/761 - 1s - loss: 0.0023 - val_loss: 1.1423e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 33/500\n",
            "761/761 - 1s - loss: 0.0022 - val_loss: 1.1398e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 34/500\n",
            "761/761 - 1s - loss: 0.0022 - val_loss: 1.1380e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 35/500\n",
            "761/761 - 1s - loss: 0.0022 - val_loss: 1.1368e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 36/500\n",
            "761/761 - 2s - loss: 0.0022 - val_loss: 1.1361e-04 - 2s/epoch - 2ms/step\n",
            "Epoch 37/500\n",
            "761/761 - 2s - loss: 0.0022 - val_loss: 1.1359e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 38/500\n",
            "761/761 - 3s - loss: 0.0022 - val_loss: 1.1361e-04 - 3s/epoch - 3ms/step\n",
            "Epoch 39/500\n",
            "761/761 - 3s - loss: 0.0022 - val_loss: 1.1367e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 40/500\n",
            "761/761 - 2s - loss: 0.0021 - val_loss: 1.1376e-04 - 2s/epoch - 2ms/step\n",
            "Epoch 41/500\n",
            "761/761 - 2s - loss: 0.0021 - val_loss: 1.1388e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 42/500\n",
            "761/761 - 2s - loss: 0.0021 - val_loss: 1.1402e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 43/500\n",
            "761/761 - 2s - loss: 0.0021 - val_loss: 1.1418e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 44/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1436e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 45/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1455e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 46/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1476e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 47/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1497e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 48/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1519e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 49/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1542e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 50/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1566e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 51/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1589e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 52/500\n",
            "761/761 - 1s - loss: 0.0021 - val_loss: 1.1613e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 53/500\n",
            "761/761 - 1s - loss: 0.0020 - val_loss: 1.1637e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 54/500\n",
            "761/761 - 1s - loss: 0.0020 - val_loss: 1.1662e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 55/500\n",
            "761/761 - 1s - loss: 0.0020 - val_loss: 1.1686e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 56/500\n",
            "761/761 - 1s - loss: 0.0020 - val_loss: 1.1710e-04 - 1s/epoch - 2ms/step\n",
            "Epoch 57/500\n",
            "761/761 - 1s - loss: 0.0020 - val_loss: 1.1734e-04 - 1s/epoch - 2ms/step\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1359e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00011359177733538672"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Om2PkqgiVjri",
        "outputId": "77070dc7-a5f9-46e5-97b3-80b959a3af7c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(5))\n",
        "plt.plot(history.history['val_loss'], label='test loss')\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHohbk8uYRIh"
      },
      "source": [
        "**MinMax Scaler equation**\n",
        "$$x' = \\frac{(x - min)}{(max - min)} \\times (new\\ max\\ value - new\\ min\\  value) + new\\ min\\ value$$<br/>\n",
        "\n",
        "\n",
        "$$x = \\frac{(max - min)\\times (new\\ min\\ value + x') + (new\\ max\\ value - new\\ min\\ value)\\times min}{new\\ max\\ value - new\\ min\\ value}$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$x$ is the inverse scaled value\n",
        "$x'$ is the scaled value\n",
        "$min$ is the minimum value of the original data\n",
        "$max$ is the maximum value of the original data.<br/>\n",
        "$new\\ max\\ value$ and $new\\ min\\ value$ is the new range that we want to scale the data to. For example: $(1,0)\\ or\\ (1,-1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ3IIvIhvHaz",
        "outputId": "58c49826-b7bb-48d9-a5d8-2b1287531587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# make a prediction \n",
        "# select the number of obersvtions for prediction\n",
        "n_obs = len(test)\n",
        "yhat = model.predict(test_X[-n_obs:], verbose=1)\n",
        "\n",
        "\n",
        "# invert scaling \n",
        "scaled_y = pd.DataFrame(test_y)\n",
        "scaled_yhat = pd.DataFrame(yhat) ## ravel () converting into 1D array\n",
        "#obtain the min and max from the training set\n",
        "unscaled_train = pd.DataFrame(series_supervised[:len(train)])\n",
        "#new feature range\n",
        "new_max_value = 1 \n",
        "new_min_value= 0\n",
        "feature_range = new_max_value - new_min_value\n",
        "\n",
        "def transform_column(column):\n",
        "    min_value = min(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    max_value = max(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    return ((max_value - min_value) * (new_min_value + column) + (feature_range  * min_value)) / feature_range \n",
        "    \n",
        "# invert scaling for actual\n",
        "inv_scale_y = scaled_y.apply(transform_column, axis=0)\n",
        "inv_scale_y = inv_scale_y.values\n",
        "# invert scaling for forecast\n",
        "inv_scale_yhat = scaled_yhat.apply(transform_column, axis=0)\n",
        "inv_scale_yhat = inv_scale_yhat.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance evaluation\n",
        "y = inv_scale_y[np.where(inv_scale_y != 0 )]\n",
        "yhat = inv_scale_yhat[np.where(inv_scale_y != 0 )]\n",
        "\n",
        "rmse_test = sqrt(mean_squared_error(y, yhat))\n",
        "print('Test RMSE: %.5f' % rmse_test)\n",
        "MAE_test = mean_absolute_error(y, yhat)\n",
        "print('Test MAE: %.5f' % MAE_test)\n",
        "r2 = r2_score(y, yhat)\n",
        "print('Test r2: %.5f' % r2)\n",
        "wMAPE_test = wMAPE(y, yhat)\n",
        "print('Test wMAPE: %.5f ' % wMAPE_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ9teVJ-5t17",
        "outputId": "5b3faa51-7fc3-4dc7-f9b0-8af04afc3d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 213.53974\n",
            "Test MAE: 121.81511\n",
            "Test r2: 0.90368\n",
            "Test wMAPE: 5.24057 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "plt.plot(yhat, label = \"TCN-predicted\")\n",
        "plt.plot(y, label = \"TCN-actual\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DN3ol2Wi7hgt",
        "outputId": "7d7d04bc-ba19-47b3-ba74-ae7b5ebe2954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0aedf7e31f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TCN-predicted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TCN-actual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EczoFlfhSIyxs3RdciK8tGvxOxZSFdWn",
      "authorship_tag": "ABX9TyORFypLHNsVAzPILnKwu61Q",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}