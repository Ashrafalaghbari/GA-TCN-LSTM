{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashrafalaghbari/Mutivariate-long-term-forecasting-of-oil-production/blob/main/multivariate_model_multistep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "x1LrkoSv4cc7",
        "outputId": "a18c533d-5142-4253-f44a-b0dbd8a1a39d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxzUA1Pg4iEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6ZrWV9NpfPM",
        "outputId": "eb2b2885-c970-4946-b8d5-eceab1f6d343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Hu7vsRejtR_4",
        "outputId": "757cba3c-454f-4581-a6a0-fe4a6f87deab"
      },
      "outputs": [
        {
          "ename": "SystemError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-69bf60a87da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ],
      "source": [
        "# check if GPU is utilized \n",
        "device_name = tf.config.experimental.list_physical_devices()[-1][-1]\n",
        "if device_name != 'GPU':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVMp6qZiT9gO"
      },
      "outputs": [],
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, columns, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('%s(t-%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "        # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# scale train and test data to [0, 1]\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        "\n",
        "\n",
        "# inverse differencing\n",
        "def inverse_difference(history, interval=1):\n",
        "\treturn history[-len(test_scaled)-interval:-interval]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX-FCHP3Hy7E"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics\n",
        "# compute RMSPE\n",
        "def RMSPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
        "\tresult /= len(x)\n",
        "\tresult = sqrt(result)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute MAPE\n",
        "def MAPE(x,y):\n",
        "\tresult=0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tresult += abs((x[i]-y[i])/x[i])\n",
        "\tresult /= len(x)\n",
        "\tresult *= 100\n",
        "\treturn result\n",
        "\n",
        "# compute wMAPE weighted absolute percentage error\n",
        "def wMAPE(actual, predicted): \n",
        "    result_nom = 0\n",
        "    result_deno = 0\n",
        "    for i in range(len(actual)):\n",
        "        result_nom +=  abs(actual[i] - predicted[i])\n",
        "        result_deno +=  abs(actual[i]) \n",
        "    result = result_nom/result_deno\n",
        "    return result *100\n",
        "\n",
        "def SMAPE(actual, predicted): #adjusted MEAN ABSOLUTE PERCENTAGE ERROR (SMAPE)\n",
        "    result = 0\n",
        "    for i in range(len(actual)):\n",
        "        result += abs(actual[i] - predicted[i])/(abs(actual[i]) + abs(predicted[i]))\n",
        "    result = 2* result/ len(actual) \n",
        "    return result * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNb6b1BBNzD9"
      },
      "outputs": [],
      "source": [
        "colum = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv')\n",
        "colum.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu0tOwl84Xln"
      },
      "outputs": [],
      "source": [
        "#load dataset\n",
        "series = pd.read_csv('/content/drive/MyDrive/volve_production_data/model.csv',\n",
        "                     usecols=[\"DATEPRD\",'AVG_CHOKE_SIZE_P','AVG_DOWNHOLE_PRESSURE','AVG_DOWNHOLE_TEMPERATURE',\n",
        "                              'ON_STREAM_HRS','AVG_WHP_P','AVG_WHT_P','F_4_BORE_WI_VOL','F_5_BORE_WI_VOL',\n",
        "                              'DP_CHOKE_SIZE', 'BORE_GAS_VOL', 'BORE_WAT_VOL',\n",
        "                              \"BORE_OIL_VOL\"],\n",
        "                  parse_dates=[\"DATEPRD\"], index_col=\"DATEPRD\")\n",
        "#change the order of BORE_OIL_VOL\n",
        "# series =series[[\"ON_STREAM_HRS\",'BORE_GAS_VOL', 'BORE_WAT_VOL','AVG_CHOKE_SIZE_P','F_4_BORE_WI_VOL','F_5_BORE_WI_VOL',\n",
        "                # \"BORE_OIL_VOL\"]] # chan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-eyECzKBiWE"
      },
      "outputs": [],
      "source": [
        "recovery_time  = pd.Series(series.index.values).diff()\n",
        "recovery_time = recovery_time.fillna(pd.Timedelta(days=1))\n",
        "recovery_time = recovery_time.astype('string')\n",
        "recovery_time  = recovery_time.str.extract(r'(\\d+)')\n",
        "recovery_time.index = series.index.values\n",
        "series['recovery_time']  = recovery_time.astype('int')\n",
        "series['recovery_time'] = series['recovery_time'] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd4HfCJBzSDp"
      },
      "outputs": [],
      "source": [
        "series[\"next_choke_size\"] = series['AVG_CHOKE_SIZE_P'].shift(-1).fillna(0)\n",
        "series[\"next_on_stream\"] = series['ON_STREAM_HRS'].shift(-1).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEvzyzwpkkLr"
      },
      "outputs": [],
      "source": [
        "column_to_move = series.pop(\"BORE_OIL_VOL\")\n",
        "\n",
        "# insert column with insert(location, column_name, column_value)\n",
        "\n",
        "series.insert(len(series.columns), \"BORE_OIL_VOL\", column_to_move)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKimF-JdZSUV",
        "outputId": "abe02894-019a-46d5-ae79-d641223dc797"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1844, 12)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "VF2uUo--zlXC",
        "outputId": "970492e9-a941-4b94-d7ed-e35562a6e080"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a96deb42-5b1b-41b0-b6ae-db93b1bbdbc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS</th>\n",
              "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
              "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>AVG_WHP_P</th>\n",
              "      <th>AVG_WHT_P</th>\n",
              "      <th>DP_CHOKE_SIZE</th>\n",
              "      <th>BORE_GAS_VOL</th>\n",
              "      <th>BORE_WAT_VOL</th>\n",
              "      <th>F_4_BORE_WI_VOL</th>\n",
              "      <th>F_5_BORE_WI_VOL</th>\n",
              "      <th>BORE_OIL_VOL</th>\n",
              "      <th>choke_size(t+1)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-01</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3378.643673</td>\n",
              "      <td>223.079164</td>\n",
              "      <td>50.150825</td>\n",
              "      <td>749.568621</td>\n",
              "      <td>190.264943</td>\n",
              "      <td>271.390953</td>\n",
              "      <td>1.462166e+07</td>\n",
              "      <td>15304.241356</td>\n",
              "      <td>44109.287732</td>\n",
              "      <td>49054.221066</td>\n",
              "      <td>18593.749401</td>\n",
              "      <td>50.694654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-02</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3377.769461</td>\n",
              "      <td>223.095696</td>\n",
              "      <td>50.694654</td>\n",
              "      <td>744.664780</td>\n",
              "      <td>190.708397</td>\n",
              "      <td>266.368677</td>\n",
              "      <td>1.469266e+07</td>\n",
              "      <td>16519.118273</td>\n",
              "      <td>41936.969541</td>\n",
              "      <td>51515.296516</td>\n",
              "      <td>18701.242265</td>\n",
              "      <td>47.665676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-03</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3408.561097</td>\n",
              "      <td>223.074953</td>\n",
              "      <td>47.665676</td>\n",
              "      <td>774.827418</td>\n",
              "      <td>192.268341</td>\n",
              "      <td>299.398157</td>\n",
              "      <td>1.400904e+07</td>\n",
              "      <td>14796.150455</td>\n",
              "      <td>41114.572918</td>\n",
              "      <td>51717.286427</td>\n",
              "      <td>17799.912406</td>\n",
              "      <td>44.706230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3439.266918</td>\n",
              "      <td>223.022721</td>\n",
              "      <td>44.706230</td>\n",
              "      <td>806.160543</td>\n",
              "      <td>191.994925</td>\n",
              "      <td>333.246980</td>\n",
              "      <td>1.341015e+07</td>\n",
              "      <td>13428.619835</td>\n",
              "      <td>40267.292699</td>\n",
              "      <td>51948.640243</td>\n",
              "      <td>17002.616014</td>\n",
              "      <td>45.743761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3429.064568</td>\n",
              "      <td>223.035833</td>\n",
              "      <td>45.743761</td>\n",
              "      <td>792.735696</td>\n",
              "      <td>191.503603</td>\n",
              "      <td>318.470614</td>\n",
              "      <td>1.361768e+07</td>\n",
              "      <td>9839.905499</td>\n",
              "      <td>40524.238503</td>\n",
              "      <td>52129.744099</td>\n",
              "      <td>17270.939334</td>\n",
              "      <td>46.053981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-19</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3847.013385</td>\n",
              "      <td>211.367931</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>446.876829</td>\n",
              "      <td>190.761010</td>\n",
              "      <td>32.394472</td>\n",
              "      <td>1.366424e+06</td>\n",
              "      <td>21779.601368</td>\n",
              "      <td>27765.068530</td>\n",
              "      <td>26704.126695</td>\n",
              "      <td>1662.711432</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-20</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3846.666639</td>\n",
              "      <td>211.352287</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>446.242576</td>\n",
              "      <td>190.577844</td>\n",
              "      <td>31.563179</td>\n",
              "      <td>1.397308e+06</td>\n",
              "      <td>23586.538158</td>\n",
              "      <td>26112.632371</td>\n",
              "      <td>27951.162219</td>\n",
              "      <td>1707.494884</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-21</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3846.286199</td>\n",
              "      <td>211.349048</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>446.048129</td>\n",
              "      <td>191.111429</td>\n",
              "      <td>31.526865</td>\n",
              "      <td>1.408435e+06</td>\n",
              "      <td>22172.777429</td>\n",
              "      <td>26281.191015</td>\n",
              "      <td>27980.731217</td>\n",
              "      <td>1725.420844</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-22</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3846.975554</td>\n",
              "      <td>211.346014</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>446.057118</td>\n",
              "      <td>187.425980</td>\n",
              "      <td>30.547996</td>\n",
              "      <td>1.379366e+06</td>\n",
              "      <td>21863.570340</td>\n",
              "      <td>26104.671114</td>\n",
              "      <td>27500.440270</td>\n",
              "      <td>1620.632599</td>\n",
              "      <td>99.994093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-23</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3845.523524</td>\n",
              "      <td>211.353157</td>\n",
              "      <td>99.994093</td>\n",
              "      <td>445.599409</td>\n",
              "      <td>189.479519</td>\n",
              "      <td>31.267625</td>\n",
              "      <td>1.263109e+06</td>\n",
              "      <td>20106.134360</td>\n",
              "      <td>26485.606927</td>\n",
              "      <td>27009.713398</td>\n",
              "      <td>1443.511533</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1844 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a96deb42-5b1b-41b0-b6ae-db93b1bbdbc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a96deb42-5b1b-41b0-b6ae-db93b1bbdbc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a96deb42-5b1b-41b0-b6ae-db93b1bbdbc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ON_STREAM_HRS  AVG_DOWNHOLE_PRESSURE  AVG_DOWNHOLE_TEMPERATURE  \\\n",
              "DATEPRD                                                                      \n",
              "2010-01-01           24.0            3378.643673                223.079164   \n",
              "2010-01-02           24.0            3377.769461                223.095696   \n",
              "2010-01-03           24.0            3408.561097                223.074953   \n",
              "2010-01-04           24.0            3439.266918                223.022721   \n",
              "2010-01-05           24.0            3429.064568                223.035833   \n",
              "...                   ...                    ...                       ...   \n",
              "2015-03-19           24.0            3847.013385                211.367931   \n",
              "2015-03-20           24.0            3846.666639                211.352287   \n",
              "2015-03-21           24.0            3846.286199                211.349048   \n",
              "2015-03-22           24.0            3846.975554                211.346014   \n",
              "2015-03-23           24.0            3845.523524                211.353157   \n",
              "\n",
              "            AVG_CHOKE_SIZE_P   AVG_WHP_P   AVG_WHT_P  DP_CHOKE_SIZE  \\\n",
              "DATEPRD                                                               \n",
              "2010-01-01         50.150825  749.568621  190.264943     271.390953   \n",
              "2010-01-02         50.694654  744.664780  190.708397     266.368677   \n",
              "2010-01-03         47.665676  774.827418  192.268341     299.398157   \n",
              "2010-01-04         44.706230  806.160543  191.994925     333.246980   \n",
              "2010-01-05         45.743761  792.735696  191.503603     318.470614   \n",
              "...                      ...         ...         ...            ...   \n",
              "2015-03-19        100.000000  446.876829  190.761010      32.394472   \n",
              "2015-03-20        100.000000  446.242576  190.577844      31.563179   \n",
              "2015-03-21        100.000000  446.048129  191.111429      31.526865   \n",
              "2015-03-22        100.000000  446.057118  187.425980      30.547996   \n",
              "2015-03-23         99.994093  445.599409  189.479519      31.267625   \n",
              "\n",
              "            BORE_GAS_VOL  BORE_WAT_VOL  F_4_BORE_WI_VOL  F_5_BORE_WI_VOL  \\\n",
              "DATEPRD                                                                    \n",
              "2010-01-01  1.462166e+07  15304.241356     44109.287732     49054.221066   \n",
              "2010-01-02  1.469266e+07  16519.118273     41936.969541     51515.296516   \n",
              "2010-01-03  1.400904e+07  14796.150455     41114.572918     51717.286427   \n",
              "2010-01-04  1.341015e+07  13428.619835     40267.292699     51948.640243   \n",
              "2010-01-05  1.361768e+07   9839.905499     40524.238503     52129.744099   \n",
              "...                  ...           ...              ...              ...   \n",
              "2015-03-19  1.366424e+06  21779.601368     27765.068530     26704.126695   \n",
              "2015-03-20  1.397308e+06  23586.538158     26112.632371     27951.162219   \n",
              "2015-03-21  1.408435e+06  22172.777429     26281.191015     27980.731217   \n",
              "2015-03-22  1.379366e+06  21863.570340     26104.671114     27500.440270   \n",
              "2015-03-23  1.263109e+06  20106.134360     26485.606927     27009.713398   \n",
              "\n",
              "            BORE_OIL_VOL  choke_size(t+1)  \n",
              "DATEPRD                                    \n",
              "2010-01-01  18593.749401        50.694654  \n",
              "2010-01-02  18701.242265        47.665676  \n",
              "2010-01-03  17799.912406        44.706230  \n",
              "2010-01-04  17002.616014        45.743761  \n",
              "2010-01-05  17270.939334        46.053981  \n",
              "...                  ...              ...  \n",
              "2015-03-19   1662.711432       100.000000  \n",
              "2015-03-20   1707.494884       100.000000  \n",
              "2015-03-21   1725.420844       100.000000  \n",
              "2015-03-22   1620.632599        99.994093  \n",
              "2015-03-23   1443.511533         0.000000  \n",
              "\n",
              "[1844 rows x 13 columns]"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bHnnyU0E1T2",
        "outputId": "ba2138cc-a464-47b1-875a-2acf38cc4975"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ON_STREAM_HRS               0.429017\n",
              "AVG_DOWNHOLE_PRESSURE      -0.514724\n",
              "AVG_DOWNHOLE_TEMPERATURE    0.918395\n",
              "AVG_CHOKE_SIZE_P           -0.067340\n",
              "AVG_WHP_P                   0.247035\n",
              "AVG_WHT_P                   0.426416\n",
              "DP_CHOKE_SIZE               0.048679\n",
              "BORE_GAS_VOL                0.996707\n",
              "BORE_WAT_VOL                0.290599\n",
              "F_4_BORE_WI_VOL             0.516457\n",
              "F_5_BORE_WI_VOL             0.582626\n",
              "BORE_OIL_VOL                1.000000\n",
              "Name: BORE_OIL_VOL, dtype: float64"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.corr().iloc[:,-1] #200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLBz9GX14-Wi"
      },
      "outputs": [],
      "source": [
        "# Data visulaization and disribution plots for well F-14 after including the injectors\n",
        "data = series.columns\n",
        "\n",
        "# Creating figure with two rows and one column\n",
        "fig, axs = plt.subplots(nrows=len(data), figsize=(17, 28))\n",
        "\n",
        "axs = axs.ravel()\n",
        "\n",
        "for id, column in enumerate(data):\n",
        "\n",
        "    axs[id].plot(series[column])\n",
        "    axs[id].grid(True)\n",
        "    axs[id].legend([column], loc='lower left', fontsize=9, handlelength=0, handletextpad=0, frameon=False)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuC_Qoqiaq_i"
      },
      "source": [
        "**Multi-output forecasting strategy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq2GI1a0NKYT"
      },
      "outputs": [],
      "source": [
        "# # # convert series to stationary \n",
        "series_diff = series.copy()\n",
        "# diff_order = 1\n",
        "# series_diff['BORE_OIL_VOL'] = series_diff['BORE_OIL_VOL'].diff(diff_order)\n",
        "# # convert the stationary series to supervise learning\n",
        "timesteps = 9 # lag features\n",
        "steps_ahead = 1\n",
        "series_supervised = series_to_supervised(series_diff, series_diff.columns, n_in=timesteps, n_out=steps_ahead, dropnan=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "D4BWZUJr0tkO",
        "outputId": "8cbb294b-9a58-4771-8f78-2bd002c60824"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9199152-2717-44d8-b0d1-6388d63710e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS</th>\n",
              "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
              "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>AVG_WHP_P</th>\n",
              "      <th>AVG_WHT_P</th>\n",
              "      <th>DP_CHOKE_SIZE</th>\n",
              "      <th>BORE_GAS_VOL</th>\n",
              "      <th>BORE_WAT_VOL</th>\n",
              "      <th>F_4_BORE_WI_VOL</th>\n",
              "      <th>F_5_BORE_WI_VOL</th>\n",
              "      <th>next_choke_size</th>\n",
              "      <th>next_on_stream</th>\n",
              "      <th>BORE_OIL_VOL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-03</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3408.561097</td>\n",
              "      <td>223.074953</td>\n",
              "      <td>47.665676</td>\n",
              "      <td>774.827418</td>\n",
              "      <td>192.268341</td>\n",
              "      <td>299.398157</td>\n",
              "      <td>1.400904e+07</td>\n",
              "      <td>14796.150455</td>\n",
              "      <td>41114.572918</td>\n",
              "      <td>51717.286427</td>\n",
              "      <td>44.706230</td>\n",
              "      <td>24.0</td>\n",
              "      <td>17799.912406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>24.0</td>\n",
              "      <td>3439.266918</td>\n",
              "      <td>223.022721</td>\n",
              "      <td>44.706230</td>\n",
              "      <td>806.160543</td>\n",
              "      <td>191.994925</td>\n",
              "      <td>333.246980</td>\n",
              "      <td>1.341015e+07</td>\n",
              "      <td>13428.619835</td>\n",
              "      <td>40267.292699</td>\n",
              "      <td>51948.640243</td>\n",
              "      <td>45.743761</td>\n",
              "      <td>24.0</td>\n",
              "      <td>17002.616014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9199152-2717-44d8-b0d1-6388d63710e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9199152-2717-44d8-b0d1-6388d63710e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9199152-2717-44d8-b0d1-6388d63710e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ON_STREAM_HRS  AVG_DOWNHOLE_PRESSURE  AVG_DOWNHOLE_TEMPERATURE  \\\n",
              "DATEPRD                                                                      \n",
              "2010-01-03           24.0            3408.561097                223.074953   \n",
              "2010-01-04           24.0            3439.266918                223.022721   \n",
              "\n",
              "            AVG_CHOKE_SIZE_P   AVG_WHP_P   AVG_WHT_P  DP_CHOKE_SIZE  \\\n",
              "DATEPRD                                                               \n",
              "2010-01-03         47.665676  774.827418  192.268341     299.398157   \n",
              "2010-01-04         44.706230  806.160543  191.994925     333.246980   \n",
              "\n",
              "            BORE_GAS_VOL  BORE_WAT_VOL  F_4_BORE_WI_VOL  F_5_BORE_WI_VOL  \\\n",
              "DATEPRD                                                                    \n",
              "2010-01-03  1.400904e+07  14796.150455     41114.572918     51717.286427   \n",
              "2010-01-04  1.341015e+07  13428.619835     40267.292699     51948.640243   \n",
              "\n",
              "            next_choke_size  next_on_stream  BORE_OIL_VOL  \n",
              "DATEPRD                                                    \n",
              "2010-01-03        44.706230            24.0  17799.912406  \n",
              "2010-01-04        45.743761            24.0  17002.616014  "
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.iloc[2:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "55DCrOd95fXj",
        "outputId": "1908a1a3-a8bb-4a7c-e41c-9c74d506596d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a5ffd1f3-3221-4799-944b-3811a7a6e1cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS</th>\n",
              "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
              "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
              "      <th>AVG_CHOKE_SIZE_P</th>\n",
              "      <th>AVG_WHP_P</th>\n",
              "      <th>AVG_WHT_P</th>\n",
              "      <th>DP_CHOKE_SIZE</th>\n",
              "      <th>BORE_GAS_VOL</th>\n",
              "      <th>BORE_WAT_VOL</th>\n",
              "      <th>F_4_BORE_WI_VOL</th>\n",
              "      <th>F_5_BORE_WI_VOL</th>\n",
              "      <th>next_choke_size</th>\n",
              "      <th>next_on_stream</th>\n",
              "      <th>BORE_OIL_VOL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-04-01</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3927.602959</td>\n",
              "      <td>218.937457</td>\n",
              "      <td>0.0</td>\n",
              "      <td>805.302507</td>\n",
              "      <td>109.717783</td>\n",
              "      <td>278.732567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15655.338583</td>\n",
              "      <td>9717.757377</td>\n",
              "      <td>35.256447</td>\n",
              "      <td>9.14166</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4254.753548</td>\n",
              "      <td>216.167018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.365014</td>\n",
              "      <td>82.606262</td>\n",
              "      <td>17.506635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24883.763848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4315.500139</td>\n",
              "      <td>213.801260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.442416</td>\n",
              "      <td>59.311400</td>\n",
              "      <td>43.355841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4379.142263</td>\n",
              "      <td>213.661328</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.440178</td>\n",
              "      <td>60.809594</td>\n",
              "      <td>33.551870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4378.296838</td>\n",
              "      <td>213.412298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.060337</td>\n",
              "      <td>60.046358</td>\n",
              "      <td>21.511562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4381.566569</td>\n",
              "      <td>209.783804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.962176</td>\n",
              "      <td>57.901712</td>\n",
              "      <td>3.597226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4386.874080</td>\n",
              "      <td>210.091874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.142458</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4386.874080</td>\n",
              "      <td>210.091874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.142458</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4386.874080</td>\n",
              "      <td>210.091874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.142458</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4386.874080</td>\n",
              "      <td>210.091874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.142458</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51.866619</td>\n",
              "      <td>22.62500</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5ffd1f3-3221-4799-944b-3811a7a6e1cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5ffd1f3-3221-4799-944b-3811a7a6e1cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5ffd1f3-3221-4799-944b-3811a7a6e1cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ON_STREAM_HRS  AVG_DOWNHOLE_PRESSURE  AVG_DOWNHOLE_TEMPERATURE  \\\n",
              "DATEPRD                                                                      \n",
              "2010-04-01            0.0            3927.602959                218.937457   \n",
              "2010-08-17            0.0            4254.753548                216.167018   \n",
              "2010-08-20            0.0            4315.500139                213.801260   \n",
              "2010-08-21            0.0            4379.142263                213.661328   \n",
              "2010-08-22            0.0            4378.296838                213.412298   \n",
              "...                   ...                    ...                       ...   \n",
              "2014-08-20            0.0            4381.566569                209.783804   \n",
              "2014-08-21            0.0            4386.874080                210.091874   \n",
              "2014-08-22            0.0            4386.874080                210.091874   \n",
              "2014-08-23            0.0            4386.874080                210.091874   \n",
              "2014-08-24            0.0            4386.874080                210.091874   \n",
              "\n",
              "            AVG_CHOKE_SIZE_P   AVG_WHP_P   AVG_WHT_P  DP_CHOKE_SIZE  \\\n",
              "DATEPRD                                                               \n",
              "2010-04-01               0.0  805.302507  109.717783     278.732567   \n",
              "2010-08-17               0.0   44.365014   82.606262      17.506635   \n",
              "2010-08-20               0.0   55.442416   59.311400      43.355841   \n",
              "2010-08-21               0.0   45.440178   60.809594      33.551870   \n",
              "2010-08-22               0.0   33.060337   60.046358      21.511562   \n",
              "...                      ...         ...         ...            ...   \n",
              "2014-08-20               0.0    4.962176   57.901712       3.597226   \n",
              "2014-08-21               0.0    5.142458   67.619282       0.914898   \n",
              "2014-08-22               0.0    5.142458   67.619282       0.914898   \n",
              "2014-08-23               0.0    5.142458   67.619282       0.914898   \n",
              "2014-08-24               0.0    5.142458   67.619282       0.914898   \n",
              "\n",
              "            BORE_GAS_VOL  BORE_WAT_VOL  F_4_BORE_WI_VOL  F_5_BORE_WI_VOL  \\\n",
              "DATEPRD                                                                    \n",
              "2010-04-01           0.0           0.0     15655.338583      9717.757377   \n",
              "2010-08-17           0.0           0.0         0.000000     24883.763848   \n",
              "2010-08-20           0.0           0.0         0.000000         0.000000   \n",
              "2010-08-21           0.0           0.0         0.000000         0.000000   \n",
              "2010-08-22           0.0           0.0         0.000000         0.000000   \n",
              "...                  ...           ...              ...              ...   \n",
              "2014-08-20           0.0           0.0         0.000000         0.000000   \n",
              "2014-08-21           0.0           0.0         0.000000         0.000000   \n",
              "2014-08-22           0.0           0.0         0.000000         0.000000   \n",
              "2014-08-23           0.0           0.0         0.000000         0.000000   \n",
              "2014-08-24           0.0           0.0         0.000000         0.000000   \n",
              "\n",
              "            next_choke_size  next_on_stream  BORE_OIL_VOL  \n",
              "DATEPRD                                                    \n",
              "2010-04-01        35.256447         9.14166           0.0  \n",
              "2010-08-17         0.000000         0.00000           0.0  \n",
              "2010-08-20         0.000000         0.00000           0.0  \n",
              "2010-08-21         0.000000         0.00000           0.0  \n",
              "2010-08-22         0.000000         0.00000           0.0  \n",
              "...                     ...             ...           ...  \n",
              "2014-08-20         0.000000         0.00000           0.0  \n",
              "2014-08-21         0.000000         0.00000           0.0  \n",
              "2014-08-22         0.000000         0.00000           0.0  \n",
              "2014-08-23         0.000000         0.00000           0.0  \n",
              "2014-08-24        51.866619        22.62500           0.0  \n",
              "\n",
              "[103 rows x 14 columns]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.loc[series['ON_STREAM_HRS']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "wtoOYzWMSlDL",
        "outputId": "87dc7c4d-b765-4b12-ba28-94ecde78e041"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b2f07404-d94e-4af4-b163-92398ec53585\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ON_STREAM_HRS(t-2)</th>\n",
              "      <th>AVG_DOWNHOLE_PRESSURE(t-2)</th>\n",
              "      <th>AVG_DOWNHOLE_TEMPERATURE(t-2)</th>\n",
              "      <th>AVG_CHOKE_SIZE_P(t-2)</th>\n",
              "      <th>AVG_WHP_P(t-2)</th>\n",
              "      <th>AVG_WHT_P(t-2)</th>\n",
              "      <th>DP_CHOKE_SIZE(t-2)</th>\n",
              "      <th>BORE_GAS_VOL(t-2)</th>\n",
              "      <th>BORE_WAT_VOL(t-2)</th>\n",
              "      <th>F_4_BORE_WI_VOL(t-2)</th>\n",
              "      <th>...</th>\n",
              "      <th>AVG_WHT_P(t-1)</th>\n",
              "      <th>DP_CHOKE_SIZE(t-1)</th>\n",
              "      <th>BORE_GAS_VOL(t-1)</th>\n",
              "      <th>BORE_WAT_VOL(t-1)</th>\n",
              "      <th>F_4_BORE_WI_VOL(t-1)</th>\n",
              "      <th>F_5_BORE_WI_VOL(t-1)</th>\n",
              "      <th>next_choke_size(t-1)</th>\n",
              "      <th>next_on_stream(t-1)</th>\n",
              "      <th>BORE_OIL_VOL(t-1)</th>\n",
              "      <th>BORE_OIL_VOL(t)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATEPRD</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-04-01</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3512.480745</td>\n",
              "      <td>223.447836</td>\n",
              "      <td>45.174481</td>\n",
              "      <td>808.542996</td>\n",
              "      <td>190.219326</td>\n",
              "      <td>324.428882</td>\n",
              "      <td>1.285337e+07</td>\n",
              "      <td>16082.794112</td>\n",
              "      <td>52979.604853</td>\n",
              "      <td>...</td>\n",
              "      <td>189.350904</td>\n",
              "      <td>324.138434</td>\n",
              "      <td>1.272020e+07</td>\n",
              "      <td>17399.754655</td>\n",
              "      <td>53364.146204</td>\n",
              "      <td>50889.352678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15913.598207</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-17</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3647.527407</td>\n",
              "      <td>223.675728</td>\n",
              "      <td>59.231621</td>\n",
              "      <td>694.322526</td>\n",
              "      <td>200.317251</td>\n",
              "      <td>221.464081</td>\n",
              "      <td>1.186412e+07</td>\n",
              "      <td>22003.770218</td>\n",
              "      <td>40563.073975</td>\n",
              "      <td>...</td>\n",
              "      <td>199.962925</td>\n",
              "      <td>239.155016</td>\n",
              "      <td>1.155754e+07</td>\n",
              "      <td>21382.777218</td>\n",
              "      <td>39495.791300</td>\n",
              "      <td>41199.828827</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14332.528516</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-20</th>\n",
              "      <td>23.75833</td>\n",
              "      <td>3661.351033</td>\n",
              "      <td>223.661588</td>\n",
              "      <td>57.292090</td>\n",
              "      <td>708.182515</td>\n",
              "      <td>199.962925</td>\n",
              "      <td>239.155016</td>\n",
              "      <td>1.155754e+07</td>\n",
              "      <td>21382.777218</td>\n",
              "      <td>39495.791300</td>\n",
              "      <td>...</td>\n",
              "      <td>82.606262</td>\n",
              "      <td>17.506635</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24883.763848</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-21</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>4254.753548</td>\n",
              "      <td>216.167018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.365014</td>\n",
              "      <td>82.606262</td>\n",
              "      <td>17.506635</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>59.311400</td>\n",
              "      <td>43.355841</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-22</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>4315.500139</td>\n",
              "      <td>213.801260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.442416</td>\n",
              "      <td>59.311400</td>\n",
              "      <td>43.355841</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>60.809594</td>\n",
              "      <td>33.551870</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-20</th>\n",
              "      <td>24.00000</td>\n",
              "      <td>3781.168805</td>\n",
              "      <td>211.778591</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>449.919210</td>\n",
              "      <td>191.795590</td>\n",
              "      <td>30.343765</td>\n",
              "      <td>1.795857e+06</td>\n",
              "      <td>22139.881720</td>\n",
              "      <td>44470.398313</td>\n",
              "      <td>...</td>\n",
              "      <td>190.334435</td>\n",
              "      <td>88.045730</td>\n",
              "      <td>3.637729e+04</td>\n",
              "      <td>350.342450</td>\n",
              "      <td>8189.321139</td>\n",
              "      <td>9637.788218</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.046186</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-21</th>\n",
              "      <td>1.65833</td>\n",
              "      <td>3853.902665</td>\n",
              "      <td>211.796573</td>\n",
              "      <td>11.011189</td>\n",
              "      <td>455.527347</td>\n",
              "      <td>190.334435</td>\n",
              "      <td>88.045730</td>\n",
              "      <td>3.637729e+04</td>\n",
              "      <td>350.342450</td>\n",
              "      <td>8189.321139</td>\n",
              "      <td>...</td>\n",
              "      <td>57.901712</td>\n",
              "      <td>3.597226</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-22</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>4381.566569</td>\n",
              "      <td>209.783804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.962176</td>\n",
              "      <td>57.901712</td>\n",
              "      <td>3.597226</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-23</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>4386.874080</td>\n",
              "      <td>210.091874</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.142458</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-08-24</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>4386.874080</td>\n",
              "      <td>210.091874</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.142458</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>67.619282</td>\n",
              "      <td>0.914898</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2f07404-d94e-4af4-b163-92398ec53585')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2f07404-d94e-4af4-b163-92398ec53585 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2f07404-d94e-4af4-b163-92398ec53585');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ON_STREAM_HRS(t-2)  AVG_DOWNHOLE_PRESSURE(t-2)  \\\n",
              "DATEPRD                                                      \n",
              "2010-04-01            24.00000                 3512.480745   \n",
              "2010-08-17            24.00000                 3647.527407   \n",
              "2010-08-20            23.75833                 3661.351033   \n",
              "2010-08-21             0.00000                 4254.753548   \n",
              "2010-08-22             0.00000                 4315.500139   \n",
              "...                        ...                         ...   \n",
              "2014-08-20            24.00000                 3781.168805   \n",
              "2014-08-21             1.65833                 3853.902665   \n",
              "2014-08-22             0.00000                 4381.566569   \n",
              "2014-08-23             0.00000                 4386.874080   \n",
              "2014-08-24             0.00000                 4386.874080   \n",
              "\n",
              "            AVG_DOWNHOLE_TEMPERATURE(t-2)  AVG_CHOKE_SIZE_P(t-2)  \\\n",
              "DATEPRD                                                            \n",
              "2010-04-01                     223.447836              45.174481   \n",
              "2010-08-17                     223.675728              59.231621   \n",
              "2010-08-20                     223.661588              57.292090   \n",
              "2010-08-21                     216.167018               0.000000   \n",
              "2010-08-22                     213.801260               0.000000   \n",
              "...                                   ...                    ...   \n",
              "2014-08-20                     211.778591             100.000000   \n",
              "2014-08-21                     211.796573              11.011189   \n",
              "2014-08-22                     209.783804               0.000000   \n",
              "2014-08-23                     210.091874               0.000000   \n",
              "2014-08-24                     210.091874               0.000000   \n",
              "\n",
              "            AVG_WHP_P(t-2)  AVG_WHT_P(t-2)  DP_CHOKE_SIZE(t-2)  \\\n",
              "DATEPRD                                                          \n",
              "2010-04-01      808.542996      190.219326          324.428882   \n",
              "2010-08-17      694.322526      200.317251          221.464081   \n",
              "2010-08-20      708.182515      199.962925          239.155016   \n",
              "2010-08-21       44.365014       82.606262           17.506635   \n",
              "2010-08-22       55.442416       59.311400           43.355841   \n",
              "...                    ...             ...                 ...   \n",
              "2014-08-20      449.919210      191.795590           30.343765   \n",
              "2014-08-21      455.527347      190.334435           88.045730   \n",
              "2014-08-22        4.962176       57.901712            3.597226   \n",
              "2014-08-23        5.142458       67.619282            0.914898   \n",
              "2014-08-24        5.142458       67.619282            0.914898   \n",
              "\n",
              "            BORE_GAS_VOL(t-2)  BORE_WAT_VOL(t-2)  F_4_BORE_WI_VOL(t-2)  ...  \\\n",
              "DATEPRD                                                                 ...   \n",
              "2010-04-01       1.285337e+07       16082.794112          52979.604853  ...   \n",
              "2010-08-17       1.186412e+07       22003.770218          40563.073975  ...   \n",
              "2010-08-20       1.155754e+07       21382.777218          39495.791300  ...   \n",
              "2010-08-21       0.000000e+00           0.000000              0.000000  ...   \n",
              "2010-08-22       0.000000e+00           0.000000              0.000000  ...   \n",
              "...                       ...                ...                   ...  ...   \n",
              "2014-08-20       1.795857e+06       22139.881720          44470.398313  ...   \n",
              "2014-08-21       3.637729e+04         350.342450           8189.321139  ...   \n",
              "2014-08-22       0.000000e+00           0.000000              0.000000  ...   \n",
              "2014-08-23       0.000000e+00           0.000000              0.000000  ...   \n",
              "2014-08-24       0.000000e+00           0.000000              0.000000  ...   \n",
              "\n",
              "            AVG_WHT_P(t-1)  DP_CHOKE_SIZE(t-1)  BORE_GAS_VOL(t-1)  \\\n",
              "DATEPRD                                                             \n",
              "2010-04-01      189.350904          324.138434       1.272020e+07   \n",
              "2010-08-17      199.962925          239.155016       1.155754e+07   \n",
              "2010-08-20       82.606262           17.506635       0.000000e+00   \n",
              "2010-08-21       59.311400           43.355841       0.000000e+00   \n",
              "2010-08-22       60.809594           33.551870       0.000000e+00   \n",
              "...                    ...                 ...                ...   \n",
              "2014-08-20      190.334435           88.045730       3.637729e+04   \n",
              "2014-08-21       57.901712            3.597226       0.000000e+00   \n",
              "2014-08-22       67.619282            0.914898       0.000000e+00   \n",
              "2014-08-23       67.619282            0.914898       0.000000e+00   \n",
              "2014-08-24       67.619282            0.914898       0.000000e+00   \n",
              "\n",
              "            BORE_WAT_VOL(t-1)  F_4_BORE_WI_VOL(t-1)  F_5_BORE_WI_VOL(t-1)  \\\n",
              "DATEPRD                                                                     \n",
              "2010-04-01       17399.754655          53364.146204          50889.352678   \n",
              "2010-08-17       21382.777218          39495.791300          41199.828827   \n",
              "2010-08-20           0.000000              0.000000          24883.763848   \n",
              "2010-08-21           0.000000              0.000000              0.000000   \n",
              "2010-08-22           0.000000              0.000000              0.000000   \n",
              "...                       ...                   ...                   ...   \n",
              "2014-08-20         350.342450           8189.321139           9637.788218   \n",
              "2014-08-21           0.000000              0.000000              0.000000   \n",
              "2014-08-22           0.000000              0.000000              0.000000   \n",
              "2014-08-23           0.000000              0.000000              0.000000   \n",
              "2014-08-24           0.000000              0.000000              0.000000   \n",
              "\n",
              "            next_choke_size(t-1)  next_on_stream(t-1)  BORE_OIL_VOL(t-1)  \\\n",
              "DATEPRD                                                                    \n",
              "2010-04-01                   0.0                  0.0       15913.598207   \n",
              "2010-08-17                   0.0                  0.0       14332.528516   \n",
              "2010-08-20                   0.0                  0.0           0.000000   \n",
              "2010-08-21                   0.0                  0.0           0.000000   \n",
              "2010-08-22                   0.0                  0.0           0.000000   \n",
              "...                          ...                  ...                ...   \n",
              "2014-08-20                   0.0                  0.0          27.046186   \n",
              "2014-08-21                   0.0                  0.0           0.000000   \n",
              "2014-08-22                   0.0                  0.0           0.000000   \n",
              "2014-08-23                   0.0                  0.0           0.000000   \n",
              "2014-08-24                   0.0                  0.0           0.000000   \n",
              "\n",
              "            BORE_OIL_VOL(t)  \n",
              "DATEPRD                      \n",
              "2010-04-01              0.0  \n",
              "2010-08-17              0.0  \n",
              "2010-08-20              0.0  \n",
              "2010-08-21              0.0  \n",
              "2010-08-22              0.0  \n",
              "...                     ...  \n",
              "2014-08-20              0.0  \n",
              "2014-08-21              0.0  \n",
              "2014-08-22              0.0  \n",
              "2014-08-23              0.0  \n",
              "2014-08-24              0.0  \n",
              "\n",
              "[103 rows x 29 columns]"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pd.set_option('display.max_columns', None)\n",
        "series_supervised.loc[series_supervised['next_on_stream(t-1)']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO0Xcq-8ZF6Q"
      },
      "outputs": [],
      "source": [
        "# # time-dependent variables \n",
        "# shifted_ON_STREAM_HRS = series_diff[\"ON_STREAM_HRS\"].shift(-(timesteps + diff_order)).dropna()\n",
        "# shifted_ON_STREAM_HRS.index = series_supervised.index.values \n",
        "# shifted_AVG_CHOKE_SIZE_P = series_diff['AVG_CHOKE_SIZE_P'].shift(-(timesteps + diff_order)).dropna()\n",
        "# shifted_AVG_CHOKE_SIZE_P.index = series_supervised.index.values\n",
        "# series_supervised = pd.concat([shifted_ON_STREAM_HRS,shifted_AVG_CHOKE_SIZE_P, series_supervised], axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH-2wA_ySOOX"
      },
      "outputs": [],
      "source": [
        "# #drop all the variables that we don't want to predict\n",
        "# vars_y = series_supervised.columns[-steps_ahead*len(series.columns):]\n",
        "# vars_name_to_drop = ['ON_STREAM_HRS(t+)']\n",
        "# vars_to_drop = vars_to_drop = [col for col in vars_y if col.startswith(vars_name_to_drop[0])]\n",
        "# series_supervised.drop(columns=vars_to_drop, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_XXkH3W_Rac"
      },
      "outputs": [],
      "source": [
        "# # bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "# ON_STREAM_HRS_t = series_supervised.pop('ON_STREAM_HRS(t)')\n",
        "# series_supervised.insert(len(series_supervised.columns)-1, 'ON_STREAM_HRS(t)', ON_STREAM_HRS_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfg1jvYuTH5a"
      },
      "outputs": [],
      "source": [
        "merged_onStreams = series_supervised[\"ON_STREAM_HRS(t-1)\"] + (series_supervised[\"ON_STREAM_HRS(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_onStreams', merged_onStreams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnwN9F7S42a7"
      },
      "outputs": [],
      "source": [
        "merged_choke = series_supervised[\"AVG_CHOKE_SIZE_P(t-1)\"] + (series_supervised[\"AVG_CHOKE_SIZE_P(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_choke', merged_choke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBZ5zwBYLyFU"
      },
      "outputs": [],
      "source": [
        "merged_WI_F_4 = series_supervised[\"F_4_BORE_WI_VOL(t-1)\"] + (series_supervised[\"F_4_BORE_WI_VOL(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_WI_F_4', merged_WI_F_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfAy8D4PLyyi"
      },
      "outputs": [],
      "source": [
        "merged_WI_F_5 = series_supervised[\"F_5_BORE_WI_VOL(t-1)\"] + (series_supervised[\"F_5_BORE_WI_VOL(t)\"] ) #\n",
        "# bring the ON_STREAM_HRS(t) variable forward one step and place it before the target variable\n",
        "series_supervised.insert(len(series_supervised.columns)-3, 'merged_WI_F_5', merged_WI_F_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfWyvX8TI7WB"
      },
      "outputs": [],
      "source": [
        "series_supervised.drop(['ON_STREAM_HRS(t-1)', 'AVG_CHOKE_SIZE_P(t-1)',\"F_4_BORE_WI_VOL(t-1)\",\n",
        "                        \"F_5_BORE_WI_VOL(t-1)\"], axis=1, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pKtD-x--GNV"
      },
      "outputs": [],
      "source": [
        "series_supervised.drop(['AVG_CHOKE_SIZE_P(t)','ON_STREAM_HRS(t)','AVG_DOWNHOLE_PRESSURE(t)', 'AVG_DOWNHOLE_TEMPERATURE(t)',\n",
        "                        'F_4_BORE_WI_VOL(t)','AVG_WHP_P(t)', 'AVG_WHT_P(t)', 'DP_CHOKE_SIZE(t)', \"next_on_stream(t)\", \"next_choke_size(t)\",\n",
        "                        'F_5_BORE_WI_VOL(t)', 'BORE_GAS_VOL(t)', 'BORE_WAT_VOL(t)'], axis=1, inplace= True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmbQinIh7Gnp",
        "outputId": "bb52bf6d-c07f-47ec-c0a2-862cdfa4dd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1468, 127) (367, 127)\n"
          ]
        }
      ],
      "source": [
        "# # split into train and test sets\n",
        "series_supervised = series_supervised.values\n",
        "train_size = int(series_supervised.shape[0] * 0.8)\n",
        "test_size = series_supervised.shape[0] - train_size\n",
        "train, test = series_supervised[0:train_size], series_supervised[train_size:]\n",
        "print(train.shape, test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvaAPiiS7y4v",
        "outputId": "e1e7b879-a253-466c-8f12-893ab13b0890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1468, 127) (367, 127)\n"
          ]
        }
      ],
      "source": [
        "# transform the scale of the data\n",
        "scaler, train_scaled, test_scaled = scale(train, test)\n",
        "print(train_scaled.shape, test_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjDT7Ud5l522",
        "outputId": "e60b1816-ecce-4e9c-9bbd-2ce42bf59a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1468, 9, 14) (1468, 1) (367, 9, 14) (367, 1)\n"
          ]
        }
      ],
      "source": [
        "# # reshape input to be 3D [samples, timesteps, features]\n",
        "n_features = len(series.columns) \n",
        "\n",
        "train_X, train_y = train_scaled[:, 0:-steps_ahead], train_scaled[:, -steps_ahead:]\n",
        "train_X = train_X.reshape(train_X.shape[0], timesteps, n_features)\n",
        "test_X, test_y = test_scaled[:, 0:-steps_ahead], test_scaled[:, -steps_ahead:]\n",
        "test_X = test_X.reshape(test_X.shape[0], timesteps, n_features )\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpoQJ7P7lmyb"
      },
      "outputs": [],
      "source": [
        "# Create a new directory in My Drive\n",
        "directory = '/content/drive/My Drive/my_trained_models'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EvEswvoTXy5",
        "outputId": "5bf38440-4764-4456-f033-2eae5327bcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/700\n",
            "734/734 - 5s - loss: 0.0204 - val_loss: 0.0073 - 5s/epoch - 6ms/step\n",
            "Epoch 2/700\n",
            "734/734 - 3s - loss: 0.0266 - val_loss: 0.0063 - 3s/epoch - 4ms/step\n",
            "Epoch 3/700\n",
            "734/734 - 3s - loss: 0.0227 - val_loss: 0.0054 - 3s/epoch - 4ms/step\n",
            "Epoch 4/700\n",
            "734/734 - 3s - loss: 0.0194 - val_loss: 0.0047 - 3s/epoch - 4ms/step\n",
            "Epoch 5/700\n",
            "734/734 - 3s - loss: 0.0166 - val_loss: 0.0043 - 3s/epoch - 4ms/step\n",
            "Epoch 6/700\n",
            "734/734 - 3s - loss: 0.0143 - val_loss: 0.0041 - 3s/epoch - 4ms/step\n",
            "Epoch 7/700\n",
            "734/734 - 3s - loss: 0.0123 - val_loss: 0.0041 - 3s/epoch - 4ms/step\n",
            "Epoch 8/700\n",
            "734/734 - 3s - loss: 0.0106 - val_loss: 0.0041 - 3s/epoch - 4ms/step\n",
            "Epoch 9/700\n",
            "734/734 - 3s - loss: 0.0091 - val_loss: 0.0043 - 3s/epoch - 4ms/step\n",
            "Epoch 10/700\n",
            "734/734 - 3s - loss: 0.0079 - val_loss: 0.0045 - 3s/epoch - 4ms/step\n",
            "Epoch 11/700\n",
            "734/734 - 3s - loss: 0.0069 - val_loss: 0.0048 - 3s/epoch - 4ms/step\n",
            "Epoch 12/700\n",
            "734/734 - 3s - loss: 0.0062 - val_loss: 0.0051 - 3s/epoch - 4ms/step\n",
            "Epoch 13/700\n",
            "734/734 - 3s - loss: 0.0056 - val_loss: 0.0053 - 3s/epoch - 3ms/step\n",
            "Epoch 14/700\n",
            "734/734 - 3s - loss: 0.0051 - val_loss: 0.0055 - 3s/epoch - 4ms/step\n",
            "Epoch 15/700\n",
            "734/734 - 3s - loss: 0.0047 - val_loss: 0.0056 - 3s/epoch - 4ms/step\n",
            "Epoch 16/700\n",
            "734/734 - 3s - loss: 0.0044 - val_loss: 0.0057 - 3s/epoch - 4ms/step\n",
            "Epoch 17/700\n",
            "734/734 - 3s - loss: 0.0042 - val_loss: 0.0058 - 3s/epoch - 4ms/step\n",
            "Epoch 18/700\n",
            "734/734 - 3s - loss: 0.0039 - val_loss: 0.0058 - 3s/epoch - 4ms/step\n",
            "Epoch 19/700\n",
            "734/734 - 3s - loss: 0.0037 - val_loss: 0.0057 - 3s/epoch - 4ms/step\n",
            "Epoch 20/700\n",
            "734/734 - 3s - loss: 0.0036 - val_loss: 0.0057 - 3s/epoch - 4ms/step\n",
            "Epoch 21/700\n",
            "734/734 - 3s - loss: 0.0034 - val_loss: 0.0056 - 3s/epoch - 4ms/step\n",
            "Epoch 22/700\n",
            "734/734 - 3s - loss: 0.0033 - val_loss: 0.0055 - 3s/epoch - 4ms/step\n",
            "Epoch 23/700\n",
            "734/734 - 3s - loss: 0.0032 - val_loss: 0.0054 - 3s/epoch - 4ms/step\n",
            "Epoch 24/700\n",
            "734/734 - 3s - loss: 0.0031 - val_loss: 0.0053 - 3s/epoch - 4ms/step\n",
            "Epoch 25/700\n",
            "734/734 - 3s - loss: 0.0030 - val_loss: 0.0051 - 3s/epoch - 4ms/step\n",
            "Epoch 26/700\n",
            "734/734 - 3s - loss: 0.0029 - val_loss: 0.0050 - 3s/epoch - 4ms/step\n",
            "Epoch 27/700\n",
            "734/734 - 3s - loss: 0.0028 - val_loss: 0.0049 - 3s/epoch - 4ms/step\n",
            "Epoch 28/700\n",
            "734/734 - 3s - loss: 0.0027 - val_loss: 0.0047 - 3s/epoch - 4ms/step\n",
            "Epoch 29/700\n",
            "734/734 - 3s - loss: 0.0026 - val_loss: 0.0046 - 3s/epoch - 4ms/step\n",
            "Epoch 30/700\n",
            "734/734 - 3s - loss: 0.0025 - val_loss: 0.0045 - 3s/epoch - 4ms/step\n",
            "Epoch 31/700\n",
            "734/734 - 3s - loss: 0.0025 - val_loss: 0.0043 - 3s/epoch - 4ms/step\n",
            "Epoch 32/700\n",
            "734/734 - 3s - loss: 0.0024 - val_loss: 0.0042 - 3s/epoch - 5ms/step\n",
            "Epoch 33/700\n",
            "734/734 - 3s - loss: 0.0023 - val_loss: 0.0041 - 3s/epoch - 4ms/step\n",
            "Epoch 34/700\n",
            "734/734 - 3s - loss: 0.0023 - val_loss: 0.0039 - 3s/epoch - 4ms/step\n",
            "Epoch 35/700\n",
            "734/734 - 3s - loss: 0.0022 - val_loss: 0.0038 - 3s/epoch - 4ms/step\n",
            "Epoch 36/700\n",
            "734/734 - 3s - loss: 0.0021 - val_loss: 0.0037 - 3s/epoch - 4ms/step\n",
            "Epoch 37/700\n",
            "734/734 - 3s - loss: 0.0021 - val_loss: 0.0036 - 3s/epoch - 4ms/step\n",
            "Epoch 38/700\n",
            "734/734 - 3s - loss: 0.0020 - val_loss: 0.0035 - 3s/epoch - 4ms/step\n",
            "Epoch 39/700\n",
            "734/734 - 3s - loss: 0.0020 - val_loss: 0.0034 - 3s/epoch - 4ms/step\n",
            "Epoch 40/700\n",
            "734/734 - 3s - loss: 0.0019 - val_loss: 0.0032 - 3s/epoch - 4ms/step\n",
            "Epoch 41/700\n",
            "734/734 - 3s - loss: 0.0018 - val_loss: 0.0031 - 3s/epoch - 4ms/step\n",
            "Epoch 42/700\n",
            "734/734 - 3s - loss: 0.0018 - val_loss: 0.0030 - 3s/epoch - 4ms/step\n",
            "Epoch 43/700\n",
            "734/734 - 3s - loss: 0.0017 - val_loss: 0.0029 - 3s/epoch - 4ms/step\n",
            "Epoch 44/700\n",
            "734/734 - 3s - loss: 0.0017 - val_loss: 0.0028 - 3s/epoch - 4ms/step\n",
            "Epoch 45/700\n",
            "734/734 - 3s - loss: 0.0016 - val_loss: 0.0027 - 3s/epoch - 4ms/step\n",
            "Epoch 46/700\n",
            "734/734 - 3s - loss: 0.0016 - val_loss: 0.0026 - 3s/epoch - 4ms/step\n",
            "Epoch 47/700\n",
            "734/734 - 3s - loss: 0.0016 - val_loss: 0.0025 - 3s/epoch - 4ms/step\n",
            "Epoch 48/700\n",
            "734/734 - 3s - loss: 0.0015 - val_loss: 0.0024 - 3s/epoch - 4ms/step\n",
            "Epoch 49/700\n",
            "734/734 - 3s - loss: 0.0015 - val_loss: 0.0023 - 3s/epoch - 4ms/step\n",
            "Epoch 50/700\n",
            "734/734 - 3s - loss: 0.0014 - val_loss: 0.0022 - 3s/epoch - 4ms/step\n",
            "Epoch 51/700\n",
            "734/734 - 3s - loss: 0.0014 - val_loss: 0.0021 - 3s/epoch - 4ms/step\n",
            "Epoch 52/700\n",
            "734/734 - 3s - loss: 0.0014 - val_loss: 0.0020 - 3s/epoch - 4ms/step\n",
            "Epoch 53/700\n",
            "734/734 - 3s - loss: 0.0014 - val_loss: 0.0020 - 3s/epoch - 4ms/step\n",
            "Epoch 54/700\n",
            "734/734 - 3s - loss: 0.0013 - val_loss: 0.0019 - 3s/epoch - 4ms/step\n",
            "Epoch 55/700\n",
            "734/734 - 4s - loss: 0.0013 - val_loss: 0.0018 - 4s/epoch - 5ms/step\n",
            "Epoch 56/700\n",
            "734/734 - 3s - loss: 0.0013 - val_loss: 0.0017 - 3s/epoch - 4ms/step\n",
            "Epoch 57/700\n",
            "734/734 - 3s - loss: 0.0013 - val_loss: 0.0017 - 3s/epoch - 4ms/step\n",
            "Epoch 58/700\n",
            "734/734 - 3s - loss: 0.0012 - val_loss: 0.0016 - 3s/epoch - 4ms/step\n",
            "Epoch 59/700\n",
            "734/734 - 3s - loss: 0.0012 - val_loss: 0.0015 - 3s/epoch - 4ms/step\n",
            "Epoch 60/700\n",
            "734/734 - 3s - loss: 0.0012 - val_loss: 0.0015 - 3s/epoch - 4ms/step\n",
            "Epoch 61/700\n",
            "734/734 - 3s - loss: 0.0012 - val_loss: 0.0014 - 3s/epoch - 4ms/step\n",
            "Epoch 62/700\n",
            "734/734 - 3s - loss: 0.0012 - val_loss: 0.0013 - 3s/epoch - 4ms/step\n",
            "Epoch 63/700\n",
            "734/734 - 3s - loss: 0.0012 - val_loss: 0.0013 - 3s/epoch - 4ms/step\n",
            "Epoch 64/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 0.0012 - 3s/epoch - 4ms/step\n",
            "Epoch 65/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 0.0012 - 3s/epoch - 4ms/step\n",
            "Epoch 66/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 0.0011 - 3s/epoch - 4ms/step\n",
            "Epoch 67/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 0.0011 - 3s/epoch - 4ms/step\n",
            "Epoch 68/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 0.0011 - 3s/epoch - 4ms/step\n",
            "Epoch 69/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 0.0010 - 3s/epoch - 4ms/step\n",
            "Epoch 70/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 9.8783e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 71/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 9.5373e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 72/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 9.2166e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 73/700\n",
            "734/734 - 3s - loss: 0.0011 - val_loss: 8.9148e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 74/700\n",
            "734/734 - 3s - loss: 0.0010 - val_loss: 8.6308e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 75/700\n",
            "734/734 - 3s - loss: 0.0010 - val_loss: 8.3636e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 76/700\n",
            "734/734 - 3s - loss: 0.0010 - val_loss: 8.1120e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 77/700\n",
            "734/734 - 3s - loss: 0.0010 - val_loss: 7.8752e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 78/700\n",
            "734/734 - 3s - loss: 0.0010 - val_loss: 7.6521e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 79/700\n",
            "734/734 - 3s - loss: 0.0010 - val_loss: 7.4419e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 80/700\n",
            "734/734 - 3s - loss: 9.9480e-04 - val_loss: 7.2437e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 81/700\n",
            "734/734 - 3s - loss: 9.8711e-04 - val_loss: 7.0568e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 82/700\n",
            "734/734 - 3s - loss: 9.7957e-04 - val_loss: 6.8804e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 83/700\n",
            "734/734 - 3s - loss: 9.7216e-04 - val_loss: 6.7138e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 84/700\n",
            "734/734 - 3s - loss: 9.6488e-04 - val_loss: 6.5564e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 85/700\n",
            "734/734 - 3s - loss: 9.5772e-04 - val_loss: 6.4075e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 86/700\n",
            "734/734 - 3s - loss: 9.5069e-04 - val_loss: 6.2666e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 87/700\n",
            "734/734 - 3s - loss: 9.4378e-04 - val_loss: 6.1333e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 88/700\n",
            "734/734 - 3s - loss: 9.3698e-04 - val_loss: 6.0069e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 89/700\n",
            "734/734 - 3s - loss: 9.3029e-04 - val_loss: 5.8871e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 90/700\n",
            "734/734 - 3s - loss: 9.2370e-04 - val_loss: 5.7734e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 91/700\n",
            "734/734 - 3s - loss: 9.1722e-04 - val_loss: 5.6655e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 92/700\n",
            "734/734 - 3s - loss: 9.1085e-04 - val_loss: 5.5629e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 93/700\n",
            "734/734 - 3s - loss: 9.0458e-04 - val_loss: 5.4654e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 94/700\n",
            "734/734 - 3s - loss: 8.9840e-04 - val_loss: 5.3726e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 95/700\n",
            "734/734 - 3s - loss: 8.9232e-04 - val_loss: 5.2842e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 96/700\n",
            "734/734 - 3s - loss: 8.8634e-04 - val_loss: 5.2000e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 97/700\n",
            "734/734 - 3s - loss: 8.8045e-04 - val_loss: 5.1197e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 98/700\n",
            "734/734 - 3s - loss: 8.7465e-04 - val_loss: 5.0430e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 99/700\n",
            "734/734 - 3s - loss: 8.6894e-04 - val_loss: 4.9697e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 100/700\n",
            "734/734 - 3s - loss: 8.6332e-04 - val_loss: 4.8997e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 101/700\n",
            "734/734 - 3s - loss: 8.5779e-04 - val_loss: 4.8328e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 102/700\n",
            "734/734 - 3s - loss: 8.5235e-04 - val_loss: 4.7687e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 103/700\n",
            "734/734 - 3s - loss: 8.4700e-04 - val_loss: 4.7072e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 104/700\n",
            "734/734 - 3s - loss: 8.4173e-04 - val_loss: 4.6484e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 105/700\n",
            "734/734 - 3s - loss: 8.3654e-04 - val_loss: 4.5918e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 106/700\n",
            "734/734 - 3s - loss: 8.3144e-04 - val_loss: 4.5375e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 107/700\n",
            "734/734 - 3s - loss: 8.2642e-04 - val_loss: 4.4854e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 108/700\n",
            "734/734 - 3s - loss: 8.2148e-04 - val_loss: 4.4352e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 109/700\n",
            "734/734 - 3s - loss: 8.1662e-04 - val_loss: 4.3870e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 110/700\n",
            "734/734 - 3s - loss: 8.1184e-04 - val_loss: 4.3405e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 111/700\n",
            "734/734 - 3s - loss: 8.0714e-04 - val_loss: 4.2957e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 112/700\n",
            "734/734 - 3s - loss: 8.0251e-04 - val_loss: 4.2525e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 113/700\n",
            "734/734 - 3s - loss: 7.9797e-04 - val_loss: 4.2109e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 114/700\n",
            "734/734 - 3s - loss: 7.9350e-04 - val_loss: 4.1707e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 115/700\n",
            "734/734 - 3s - loss: 7.8910e-04 - val_loss: 4.1319e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 116/700\n",
            "734/734 - 3s - loss: 7.8478e-04 - val_loss: 4.0944e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 117/700\n",
            "734/734 - 3s - loss: 7.8053e-04 - val_loss: 4.0582e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 118/700\n",
            "734/734 - 3s - loss: 7.7635e-04 - val_loss: 4.0232e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 119/700\n",
            "734/734 - 3s - loss: 7.7224e-04 - val_loss: 3.9893e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 120/700\n",
            "734/734 - 3s - loss: 7.6821e-04 - val_loss: 3.9566e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 121/700\n",
            "734/734 - 3s - loss: 7.6424e-04 - val_loss: 3.9249e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 122/700\n",
            "734/734 - 3s - loss: 7.6034e-04 - val_loss: 3.8943e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 123/700\n",
            "734/734 - 3s - loss: 7.5651e-04 - val_loss: 3.8647e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 124/700\n",
            "734/734 - 3s - loss: 7.5274e-04 - val_loss: 3.8360e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 125/700\n",
            "734/734 - 3s - loss: 7.4905e-04 - val_loss: 3.8084e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 126/700\n",
            "734/734 - 3s - loss: 7.4541e-04 - val_loss: 3.7816e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 127/700\n",
            "734/734 - 3s - loss: 7.4184e-04 - val_loss: 3.7557e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 128/700\n",
            "734/734 - 4s - loss: 7.3833e-04 - val_loss: 3.7307e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 129/700\n",
            "734/734 - 3s - loss: 7.3488e-04 - val_loss: 3.7066e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 130/700\n",
            "734/734 - 3s - loss: 7.3150e-04 - val_loss: 3.6834e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 131/700\n",
            "734/734 - 3s - loss: 7.2817e-04 - val_loss: 3.6609e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 132/700\n",
            "734/734 - 3s - loss: 7.2490e-04 - val_loss: 3.6393e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 133/700\n",
            "734/734 - 3s - loss: 7.2169e-04 - val_loss: 3.6184e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 134/700\n",
            "734/734 - 3s - loss: 7.1854e-04 - val_loss: 3.5984e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 135/700\n",
            "734/734 - 3s - loss: 7.1544e-04 - val_loss: 3.5791e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 136/700\n",
            "734/734 - 3s - loss: 7.1240e-04 - val_loss: 3.5607e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 137/700\n",
            "734/734 - 3s - loss: 7.0941e-04 - val_loss: 3.5429e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 138/700\n",
            "734/734 - 3s - loss: 7.0647e-04 - val_loss: 3.5259e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 139/700\n",
            "734/734 - 3s - loss: 7.0359e-04 - val_loss: 3.5097e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 140/700\n",
            "734/734 - 3s - loss: 7.0075e-04 - val_loss: 3.4942e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 141/700\n",
            "734/734 - 3s - loss: 6.9797e-04 - val_loss: 3.4794e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 142/700\n",
            "734/734 - 3s - loss: 6.9523e-04 - val_loss: 3.4654e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 143/700\n",
            "734/734 - 3s - loss: 6.9255e-04 - val_loss: 3.4521e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 144/700\n",
            "734/734 - 3s - loss: 6.8991e-04 - val_loss: 3.4394e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 145/700\n",
            "734/734 - 3s - loss: 6.8731e-04 - val_loss: 3.4275e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 146/700\n",
            "734/734 - 3s - loss: 6.8476e-04 - val_loss: 3.4163e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 147/700\n",
            "734/734 - 3s - loss: 6.8225e-04 - val_loss: 3.4057e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 148/700\n",
            "734/734 - 3s - loss: 6.7979e-04 - val_loss: 3.3959e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 149/700\n",
            "734/734 - 3s - loss: 6.7737e-04 - val_loss: 3.3867e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 150/700\n",
            "734/734 - 3s - loss: 6.7499e-04 - val_loss: 3.3781e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 151/700\n",
            "734/734 - 3s - loss: 6.7265e-04 - val_loss: 3.3702e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 152/700\n",
            "734/734 - 3s - loss: 6.7034e-04 - val_loss: 3.3629e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 153/700\n",
            "734/734 - 3s - loss: 6.6808e-04 - val_loss: 3.3563e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 154/700\n",
            "734/734 - 3s - loss: 6.6585e-04 - val_loss: 3.3503e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 155/700\n",
            "734/734 - 3s - loss: 6.6366e-04 - val_loss: 3.3449e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 156/700\n",
            "734/734 - 3s - loss: 6.6150e-04 - val_loss: 3.3401e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 157/700\n",
            "734/734 - 3s - loss: 6.5938e-04 - val_loss: 3.3359e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 158/700\n",
            "734/734 - 3s - loss: 6.5729e-04 - val_loss: 3.3323e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 159/700\n",
            "734/734 - 3s - loss: 6.5524e-04 - val_loss: 3.3293e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 160/700\n",
            "734/734 - 3s - loss: 6.5321e-04 - val_loss: 3.3268e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 161/700\n",
            "734/734 - 3s - loss: 6.5122e-04 - val_loss: 3.3249e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 162/700\n",
            "734/734 - 3s - loss: 6.4925e-04 - val_loss: 3.3235e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 163/700\n",
            "734/734 - 3s - loss: 6.4732e-04 - val_loss: 3.3226e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 164/700\n",
            "734/734 - 3s - loss: 6.4541e-04 - val_loss: 3.3223e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 165/700\n",
            "734/734 - 3s - loss: 6.4353e-04 - val_loss: 3.3224e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 166/700\n",
            "734/734 - 3s - loss: 6.4168e-04 - val_loss: 3.3231e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 167/700\n",
            "734/734 - 3s - loss: 6.3985e-04 - val_loss: 3.3242e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 168/700\n",
            "734/734 - 3s - loss: 6.3804e-04 - val_loss: 3.3258e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 169/700\n",
            "734/734 - 3s - loss: 6.3626e-04 - val_loss: 3.3278e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 170/700\n",
            "734/734 - 3s - loss: 6.3450e-04 - val_loss: 3.3302e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 171/700\n",
            "734/734 - 3s - loss: 6.3277e-04 - val_loss: 3.3331e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 172/700\n",
            "734/734 - 3s - loss: 6.3106e-04 - val_loss: 3.3364e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 173/700\n",
            "734/734 - 3s - loss: 6.2936e-04 - val_loss: 3.3401e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 174/700\n",
            "734/734 - 4s - loss: 6.2769e-04 - val_loss: 3.3443e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 175/700\n",
            "734/734 - 3s - loss: 6.2604e-04 - val_loss: 3.3487e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 176/700\n",
            "734/734 - 3s - loss: 6.2440e-04 - val_loss: 3.3536e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 177/700\n",
            "734/734 - 3s - loss: 6.2279e-04 - val_loss: 3.3587e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 178/700\n",
            "734/734 - 3s - loss: 6.2119e-04 - val_loss: 3.3642e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 179/700\n",
            "734/734 - 3s - loss: 6.1961e-04 - val_loss: 3.3701e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 180/700\n",
            "734/734 - 3s - loss: 6.1804e-04 - val_loss: 3.3762e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 181/700\n",
            "734/734 - 3s - loss: 6.1649e-04 - val_loss: 3.3827e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 182/700\n",
            "734/734 - 3s - loss: 6.1496e-04 - val_loss: 3.3895e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 183/700\n",
            "734/734 - 3s - loss: 6.1344e-04 - val_loss: 3.3965e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 184/700\n",
            "734/734 - 3s - loss: 6.1193e-04 - val_loss: 3.4038e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 185/700\n",
            "734/734 - 3s - loss: 6.1044e-04 - val_loss: 3.4113e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 186/700\n",
            "734/734 - 3s - loss: 6.0896e-04 - val_loss: 3.4190e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 187/700\n",
            "734/734 - 3s - loss: 6.0749e-04 - val_loss: 3.4271e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 188/700\n",
            "734/734 - 3s - loss: 6.0604e-04 - val_loss: 3.4353e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 189/700\n",
            "734/734 - 3s - loss: 6.0459e-04 - val_loss: 3.4437e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 190/700\n",
            "734/734 - 3s - loss: 6.0316e-04 - val_loss: 3.4524e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 191/700\n",
            "734/734 - 3s - loss: 6.0174e-04 - val_loss: 3.4612e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 192/700\n",
            "734/734 - 3s - loss: 6.0033e-04 - val_loss: 3.4701e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 193/700\n",
            "734/734 - 3s - loss: 5.9893e-04 - val_loss: 3.4793e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 194/700\n",
            "734/734 - 3s - loss: 5.9754e-04 - val_loss: 3.4886e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 195/700\n",
            "734/734 - 3s - loss: 5.9616e-04 - val_loss: 3.4980e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 196/700\n",
            "734/734 - 3s - loss: 5.9479e-04 - val_loss: 3.5075e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 197/700\n",
            "734/734 - 3s - loss: 5.9343e-04 - val_loss: 3.5172e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 198/700\n",
            "734/734 - 4s - loss: 5.9207e-04 - val_loss: 3.5270e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 199/700\n",
            "734/734 - 3s - loss: 5.9073e-04 - val_loss: 3.5369e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 200/700\n",
            "734/734 - 3s - loss: 5.8939e-04 - val_loss: 3.5469e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 201/700\n",
            "734/734 - 3s - loss: 5.8806e-04 - val_loss: 3.5569e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 202/700\n",
            "734/734 - 3s - loss: 5.8674e-04 - val_loss: 3.5671e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 203/700\n",
            "734/734 - 3s - loss: 5.8542e-04 - val_loss: 3.5773e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 204/700\n",
            "734/734 - 3s - loss: 5.8411e-04 - val_loss: 3.5875e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 205/700\n",
            "734/734 - 3s - loss: 5.8281e-04 - val_loss: 3.5979e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 206/700\n",
            "734/734 - 3s - loss: 5.8152e-04 - val_loss: 3.6082e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 207/700\n",
            "734/734 - 3s - loss: 5.8023e-04 - val_loss: 3.6185e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 208/700\n",
            "734/734 - 3s - loss: 5.7894e-04 - val_loss: 3.6290e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 209/700\n",
            "734/734 - 3s - loss: 5.7767e-04 - val_loss: 3.6394e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 210/700\n",
            "734/734 - 3s - loss: 5.7640e-04 - val_loss: 3.6498e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 211/700\n",
            "734/734 - 4s - loss: 5.7513e-04 - val_loss: 3.6602e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 212/700\n",
            "734/734 - 4s - loss: 5.7388e-04 - val_loss: 3.6706e-04 - 4s/epoch - 6ms/step\n",
            "Epoch 213/700\n",
            "734/734 - 3s - loss: 5.7262e-04 - val_loss: 3.6810e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 214/700\n",
            "734/734 - 3s - loss: 5.7138e-04 - val_loss: 3.6914e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 215/700\n",
            "734/734 - 3s - loss: 5.7013e-04 - val_loss: 3.7018e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 216/700\n",
            "734/734 - 3s - loss: 5.6890e-04 - val_loss: 3.7121e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 217/700\n",
            "734/734 - 3s - loss: 5.6767e-04 - val_loss: 3.7224e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 218/700\n",
            "734/734 - 3s - loss: 5.6644e-04 - val_loss: 3.7326e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 219/700\n",
            "734/734 - 3s - loss: 5.6522e-04 - val_loss: 3.7428e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 220/700\n",
            "734/734 - 3s - loss: 5.6400e-04 - val_loss: 3.7529e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 221/700\n",
            "734/734 - 4s - loss: 5.6279e-04 - val_loss: 3.7630e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 222/700\n",
            "734/734 - 3s - loss: 5.6158e-04 - val_loss: 3.7730e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 223/700\n",
            "734/734 - 3s - loss: 5.6038e-04 - val_loss: 3.7829e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 224/700\n",
            "734/734 - 4s - loss: 5.5918e-04 - val_loss: 3.7928e-04 - 4s/epoch - 6ms/step\n",
            "Epoch 225/700\n",
            "734/734 - 3s - loss: 5.5799e-04 - val_loss: 3.8025e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 226/700\n",
            "734/734 - 4s - loss: 5.5680e-04 - val_loss: 3.8122e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 227/700\n",
            "734/734 - 3s - loss: 5.5562e-04 - val_loss: 3.8218e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 228/700\n",
            "734/734 - 3s - loss: 5.5444e-04 - val_loss: 3.8313e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 229/700\n",
            "734/734 - 3s - loss: 5.5327e-04 - val_loss: 3.8407e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 230/700\n",
            "734/734 - 3s - loss: 5.5210e-04 - val_loss: 3.8499e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 231/700\n",
            "734/734 - 3s - loss: 5.5093e-04 - val_loss: 3.8591e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 232/700\n",
            "734/734 - 4s - loss: 5.4977e-04 - val_loss: 3.8682e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 233/700\n",
            "734/734 - 3s - loss: 5.4861e-04 - val_loss: 3.8771e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 234/700\n",
            "734/734 - 3s - loss: 5.4746e-04 - val_loss: 3.8859e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 235/700\n",
            "734/734 - 3s - loss: 5.4632e-04 - val_loss: 3.8946e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 236/700\n",
            "734/734 - 3s - loss: 5.4517e-04 - val_loss: 3.9032e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 237/700\n",
            "734/734 - 4s - loss: 5.4403e-04 - val_loss: 3.9116e-04 - 4s/epoch - 6ms/step\n",
            "Epoch 238/700\n",
            "734/734 - 4s - loss: 5.4290e-04 - val_loss: 3.9199e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 239/700\n",
            "734/734 - 4s - loss: 5.4177e-04 - val_loss: 3.9281e-04 - 4s/epoch - 6ms/step\n",
            "Epoch 240/700\n",
            "734/734 - 5s - loss: 5.4064e-04 - val_loss: 3.9361e-04 - 5s/epoch - 6ms/step\n",
            "Epoch 241/700\n",
            "734/734 - 3s - loss: 5.3952e-04 - val_loss: 3.9440e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 242/700\n",
            "734/734 - 3s - loss: 5.3840e-04 - val_loss: 3.9517e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 243/700\n",
            "734/734 - 3s - loss: 5.3729e-04 - val_loss: 3.9593e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 244/700\n",
            "734/734 - 3s - loss: 5.3618e-04 - val_loss: 3.9667e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 245/700\n",
            "734/734 - 3s - loss: 5.3508e-04 - val_loss: 3.9740e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 246/700\n",
            "734/734 - 3s - loss: 5.3398e-04 - val_loss: 3.9812e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 247/700\n",
            "734/734 - 3s - loss: 5.3288e-04 - val_loss: 3.9881e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 248/700\n",
            "734/734 - 3s - loss: 5.3179e-04 - val_loss: 3.9950e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 249/700\n",
            "734/734 - 3s - loss: 5.3071e-04 - val_loss: 4.0016e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 250/700\n",
            "734/734 - 3s - loss: 5.2962e-04 - val_loss: 4.0081e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 251/700\n",
            "734/734 - 3s - loss: 5.2855e-04 - val_loss: 4.0145e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 252/700\n",
            "734/734 - 3s - loss: 5.2747e-04 - val_loss: 4.0207e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 253/700\n",
            "734/734 - 3s - loss: 5.2640e-04 - val_loss: 4.0267e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 254/700\n",
            "734/734 - 3s - loss: 5.2534e-04 - val_loss: 4.0325e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 255/700\n",
            "734/734 - 3s - loss: 5.2428e-04 - val_loss: 4.0382e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 256/700\n",
            "734/734 - 3s - loss: 5.2322e-04 - val_loss: 4.0438e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 257/700\n",
            "734/734 - 3s - loss: 5.2217e-04 - val_loss: 4.0491e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 258/700\n",
            "734/734 - 3s - loss: 5.2112e-04 - val_loss: 4.0543e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 259/700\n",
            "734/734 - 3s - loss: 5.2008e-04 - val_loss: 4.0594e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 260/700\n",
            "734/734 - 3s - loss: 5.1904e-04 - val_loss: 4.0643e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 261/700\n",
            "734/734 - 3s - loss: 5.1801e-04 - val_loss: 4.0690e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 262/700\n",
            "734/734 - 3s - loss: 5.1698e-04 - val_loss: 4.0735e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 263/700\n",
            "734/734 - 4s - loss: 5.1596e-04 - val_loss: 4.0779e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 264/700\n",
            "734/734 - 3s - loss: 5.1494e-04 - val_loss: 4.0821e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 265/700\n",
            "734/734 - 3s - loss: 5.1392e-04 - val_loss: 4.0862e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 266/700\n",
            "734/734 - 3s - loss: 5.1291e-04 - val_loss: 4.0900e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 267/700\n",
            "734/734 - 3s - loss: 5.1190e-04 - val_loss: 4.0938e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 268/700\n",
            "734/734 - 3s - loss: 5.1090e-04 - val_loss: 4.0974e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 269/700\n",
            "734/734 - 3s - loss: 5.0990e-04 - val_loss: 4.1008e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 270/700\n",
            "734/734 - 3s - loss: 5.0891e-04 - val_loss: 4.1040e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 271/700\n",
            "734/734 - 3s - loss: 5.0792e-04 - val_loss: 4.1071e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 272/700\n",
            "734/734 - 3s - loss: 5.0693e-04 - val_loss: 4.1101e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 273/700\n",
            "734/734 - 3s - loss: 5.0595e-04 - val_loss: 4.1129e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 274/700\n",
            "734/734 - 3s - loss: 5.0498e-04 - val_loss: 4.1155e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 275/700\n",
            "734/734 - 3s - loss: 5.0400e-04 - val_loss: 4.1180e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 276/700\n",
            "734/734 - 3s - loss: 5.0304e-04 - val_loss: 4.1204e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 277/700\n",
            "734/734 - 3s - loss: 5.0207e-04 - val_loss: 4.1226e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 278/700\n",
            "734/734 - 3s - loss: 5.0111e-04 - val_loss: 4.1246e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 279/700\n",
            "734/734 - 3s - loss: 5.0016e-04 - val_loss: 4.1265e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 280/700\n",
            "734/734 - 3s - loss: 4.9921e-04 - val_loss: 4.1282e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 281/700\n",
            "734/734 - 3s - loss: 4.9827e-04 - val_loss: 4.1299e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 282/700\n",
            "734/734 - 3s - loss: 4.9732e-04 - val_loss: 4.1313e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 283/700\n",
            "734/734 - 3s - loss: 4.9639e-04 - val_loss: 4.1327e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 284/700\n",
            "734/734 - 4s - loss: 4.9546e-04 - val_loss: 4.1340e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 285/700\n",
            "734/734 - 3s - loss: 4.9453e-04 - val_loss: 4.1351e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 286/700\n",
            "734/734 - 3s - loss: 4.9360e-04 - val_loss: 4.1360e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 287/700\n",
            "734/734 - 3s - loss: 4.9268e-04 - val_loss: 4.1369e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 288/700\n",
            "734/734 - 3s - loss: 4.9177e-04 - val_loss: 4.1376e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 289/700\n",
            "734/734 - 3s - loss: 4.9086e-04 - val_loss: 4.1382e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 290/700\n",
            "734/734 - 3s - loss: 4.8995e-04 - val_loss: 4.1387e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 291/700\n",
            "734/734 - 3s - loss: 4.8905e-04 - val_loss: 4.1391e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 292/700\n",
            "734/734 - 3s - loss: 4.8815e-04 - val_loss: 4.1393e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 293/700\n",
            "734/734 - 3s - loss: 4.8726e-04 - val_loss: 4.1395e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 294/700\n",
            "734/734 - 3s - loss: 4.8637e-04 - val_loss: 4.1396e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 295/700\n",
            "734/734 - 3s - loss: 4.8548e-04 - val_loss: 4.1395e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 296/700\n",
            "734/734 - 3s - loss: 4.8460e-04 - val_loss: 4.1394e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 297/700\n",
            "734/734 - 3s - loss: 4.8372e-04 - val_loss: 4.1391e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 298/700\n",
            "734/734 - 3s - loss: 4.8284e-04 - val_loss: 4.1388e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 299/700\n",
            "734/734 - 3s - loss: 4.8197e-04 - val_loss: 4.1383e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 300/700\n",
            "734/734 - 3s - loss: 4.8111e-04 - val_loss: 4.1378e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 301/700\n",
            "734/734 - 3s - loss: 4.8024e-04 - val_loss: 4.1372e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 302/700\n",
            "734/734 - 3s - loss: 4.7939e-04 - val_loss: 4.1365e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 303/700\n",
            "734/734 - 3s - loss: 4.7853e-04 - val_loss: 4.1357e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 304/700\n",
            "734/734 - 3s - loss: 4.7768e-04 - val_loss: 4.1349e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 305/700\n",
            "734/734 - 3s - loss: 4.7683e-04 - val_loss: 4.1340e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 306/700\n",
            "734/734 - 3s - loss: 4.7599e-04 - val_loss: 4.1330e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 307/700\n",
            "734/734 - 3s - loss: 4.7515e-04 - val_loss: 4.1320e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 308/700\n",
            "734/734 - 3s - loss: 4.7431e-04 - val_loss: 4.1309e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 309/700\n",
            "734/734 - 3s - loss: 4.7348e-04 - val_loss: 4.1297e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 310/700\n",
            "734/734 - 3s - loss: 4.7265e-04 - val_loss: 4.1285e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 311/700\n",
            "734/734 - 3s - loss: 4.7183e-04 - val_loss: 4.1272e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 312/700\n",
            "734/734 - 3s - loss: 4.7100e-04 - val_loss: 4.1259e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 313/700\n",
            "734/734 - 3s - loss: 4.7018e-04 - val_loss: 4.1245e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 314/700\n",
            "734/734 - 3s - loss: 4.6937e-04 - val_loss: 4.1231e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 315/700\n",
            "734/734 - 3s - loss: 4.6856e-04 - val_loss: 4.1216e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 316/700\n",
            "734/734 - 3s - loss: 4.6775e-04 - val_loss: 4.1201e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 317/700\n",
            "734/734 - 3s - loss: 4.6694e-04 - val_loss: 4.1186e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 318/700\n",
            "734/734 - 3s - loss: 4.6614e-04 - val_loss: 4.1171e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 319/700\n",
            "734/734 - 3s - loss: 4.6534e-04 - val_loss: 4.1155e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 320/700\n",
            "734/734 - 3s - loss: 4.6454e-04 - val_loss: 4.1138e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 321/700\n",
            "734/734 - 3s - loss: 4.6375e-04 - val_loss: 4.1122e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 322/700\n",
            "734/734 - 3s - loss: 4.6296e-04 - val_loss: 4.1105e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 323/700\n",
            "734/734 - 3s - loss: 4.6217e-04 - val_loss: 4.1089e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 324/700\n",
            "734/734 - 3s - loss: 4.6139e-04 - val_loss: 4.1072e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 325/700\n",
            "734/734 - 3s - loss: 4.6061e-04 - val_loss: 4.1055e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 326/700\n",
            "734/734 - 3s - loss: 4.5983e-04 - val_loss: 4.1038e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 327/700\n",
            "734/734 - 3s - loss: 4.5905e-04 - val_loss: 4.1021e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 328/700\n",
            "734/734 - 4s - loss: 4.5828e-04 - val_loss: 4.1004e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 329/700\n",
            "734/734 - 3s - loss: 4.5751e-04 - val_loss: 4.0987e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 330/700\n",
            "734/734 - 3s - loss: 4.5674e-04 - val_loss: 4.0970e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 331/700\n",
            "734/734 - 3s - loss: 4.5597e-04 - val_loss: 4.0953e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 332/700\n",
            "734/734 - 3s - loss: 4.5521e-04 - val_loss: 4.0937e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 333/700\n",
            "734/734 - 3s - loss: 4.5445e-04 - val_loss: 4.0920e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 334/700\n",
            "734/734 - 3s - loss: 4.5369e-04 - val_loss: 4.0904e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 335/700\n",
            "734/734 - 3s - loss: 4.5294e-04 - val_loss: 4.0888e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 336/700\n",
            "734/734 - 3s - loss: 4.5218e-04 - val_loss: 4.0872e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 337/700\n",
            "734/734 - 3s - loss: 4.5143e-04 - val_loss: 4.0857e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 338/700\n",
            "734/734 - 3s - loss: 4.5068e-04 - val_loss: 4.0842e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 339/700\n",
            "734/734 - 3s - loss: 4.4993e-04 - val_loss: 4.0827e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 340/700\n",
            "734/734 - 3s - loss: 4.4919e-04 - val_loss: 4.0812e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 341/700\n",
            "734/734 - 3s - loss: 4.4844e-04 - val_loss: 4.0798e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 342/700\n",
            "734/734 - 3s - loss: 4.4770e-04 - val_loss: 4.0784e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 343/700\n",
            "734/734 - 3s - loss: 4.4696e-04 - val_loss: 4.0771e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 344/700\n",
            "734/734 - 3s - loss: 4.4623e-04 - val_loss: 4.0758e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 345/700\n",
            "734/734 - 3s - loss: 4.4549e-04 - val_loss: 4.0745e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 346/700\n",
            "734/734 - 3s - loss: 4.4476e-04 - val_loss: 4.0734e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 347/700\n",
            "734/734 - 3s - loss: 4.4402e-04 - val_loss: 4.0722e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 348/700\n",
            "734/734 - 3s - loss: 4.4329e-04 - val_loss: 4.0711e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 349/700\n",
            "734/734 - 3s - loss: 4.4256e-04 - val_loss: 4.0700e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 350/700\n",
            "734/734 - 3s - loss: 4.4184e-04 - val_loss: 4.0691e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 351/700\n",
            "734/734 - 3s - loss: 4.4111e-04 - val_loss: 4.0681e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 352/700\n",
            "734/734 - 3s - loss: 4.4039e-04 - val_loss: 4.0673e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 353/700\n",
            "734/734 - 3s - loss: 4.3966e-04 - val_loss: 4.0664e-04 - 3s/epoch - 3ms/step\n",
            "Epoch 354/700\n",
            "734/734 - 4s - loss: 4.3894e-04 - val_loss: 4.0657e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 355/700\n",
            "734/734 - 3s - loss: 4.3822e-04 - val_loss: 4.0650e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 356/700\n",
            "734/734 - 3s - loss: 4.3750e-04 - val_loss: 4.0644e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 357/700\n",
            "734/734 - 3s - loss: 4.3679e-04 - val_loss: 4.0638e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 358/700\n",
            "734/734 - 3s - loss: 4.3607e-04 - val_loss: 4.0633e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 359/700\n",
            "734/734 - 3s - loss: 4.3536e-04 - val_loss: 4.0629e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 360/700\n",
            "734/734 - 3s - loss: 4.3465e-04 - val_loss: 4.0626e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 361/700\n",
            "734/734 - 3s - loss: 4.3394e-04 - val_loss: 4.0622e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 362/700\n",
            "734/734 - 3s - loss: 4.3323e-04 - val_loss: 4.0620e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 363/700\n",
            "734/734 - 3s - loss: 4.3252e-04 - val_loss: 4.0618e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 364/700\n",
            "734/734 - 3s - loss: 4.3181e-04 - val_loss: 4.0618e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 365/700\n",
            "734/734 - 3s - loss: 4.3111e-04 - val_loss: 4.0617e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 366/700\n",
            "734/734 - 3s - loss: 4.3040e-04 - val_loss: 4.0618e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 367/700\n",
            "734/734 - 3s - loss: 4.2970e-04 - val_loss: 4.0619e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 368/700\n",
            "734/734 - 3s - loss: 4.2900e-04 - val_loss: 4.0621e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 369/700\n",
            "734/734 - 3s - loss: 4.2831e-04 - val_loss: 4.0623e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 370/700\n",
            "734/734 - 3s - loss: 4.2761e-04 - val_loss: 4.0626e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 371/700\n",
            "734/734 - 3s - loss: 4.2691e-04 - val_loss: 4.0630e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 372/700\n",
            "734/734 - 3s - loss: 4.2622e-04 - val_loss: 4.0634e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 373/700\n",
            "734/734 - 3s - loss: 4.2553e-04 - val_loss: 4.0639e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 374/700\n",
            "734/734 - 3s - loss: 4.2484e-04 - val_loss: 4.0645e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 375/700\n",
            "734/734 - 3s - loss: 4.2415e-04 - val_loss: 4.0652e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 376/700\n",
            "734/734 - 3s - loss: 4.2346e-04 - val_loss: 4.0659e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 377/700\n",
            "734/734 - 3s - loss: 4.2278e-04 - val_loss: 4.0666e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 378/700\n",
            "734/734 - 3s - loss: 4.2210e-04 - val_loss: 4.0675e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 379/700\n",
            "734/734 - 3s - loss: 4.2142e-04 - val_loss: 4.0684e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 380/700\n",
            "734/734 - 3s - loss: 4.2074e-04 - val_loss: 4.0693e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 381/700\n",
            "734/734 - 3s - loss: 4.2006e-04 - val_loss: 4.0703e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 382/700\n",
            "734/734 - 3s - loss: 4.1939e-04 - val_loss: 4.0714e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 383/700\n",
            "734/734 - 3s - loss: 4.1872e-04 - val_loss: 4.0726e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 384/700\n",
            "734/734 - 3s - loss: 4.1804e-04 - val_loss: 4.0738e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 385/700\n",
            "734/734 - 3s - loss: 4.1738e-04 - val_loss: 4.0751e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 386/700\n",
            "734/734 - 3s - loss: 4.1671e-04 - val_loss: 4.0764e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 387/700\n",
            "734/734 - 3s - loss: 4.1604e-04 - val_loss: 4.0778e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 388/700\n",
            "734/734 - 3s - loss: 4.1538e-04 - val_loss: 4.0792e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 389/700\n",
            "734/734 - 3s - loss: 4.1472e-04 - val_loss: 4.0807e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 390/700\n",
            "734/734 - 3s - loss: 4.1406e-04 - val_loss: 4.0823e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 391/700\n",
            "734/734 - 3s - loss: 4.1340e-04 - val_loss: 4.0840e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 392/700\n",
            "734/734 - 3s - loss: 4.1275e-04 - val_loss: 4.0857e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 393/700\n",
            "734/734 - 3s - loss: 4.1209e-04 - val_loss: 4.0874e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 394/700\n",
            "734/734 - 3s - loss: 4.1144e-04 - val_loss: 4.0892e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 395/700\n",
            "734/734 - 3s - loss: 4.1079e-04 - val_loss: 4.0911e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 396/700\n",
            "734/734 - 3s - loss: 4.1014e-04 - val_loss: 4.0931e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 397/700\n",
            "734/734 - 3s - loss: 4.0950e-04 - val_loss: 4.0951e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 398/700\n",
            "734/734 - 3s - loss: 4.0885e-04 - val_loss: 4.0972e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 399/700\n",
            "734/734 - 3s - loss: 4.0821e-04 - val_loss: 4.0994e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 400/700\n",
            "734/734 - 4s - loss: 4.0757e-04 - val_loss: 4.1016e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 401/700\n",
            "734/734 - 3s - loss: 4.0693e-04 - val_loss: 4.1039e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 402/700\n",
            "734/734 - 3s - loss: 4.0629e-04 - val_loss: 4.1062e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 403/700\n",
            "734/734 - 3s - loss: 4.0566e-04 - val_loss: 4.1086e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 404/700\n",
            "734/734 - 3s - loss: 4.0503e-04 - val_loss: 4.1111e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 405/700\n",
            "734/734 - 3s - loss: 4.0440e-04 - val_loss: 4.1137e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 406/700\n",
            "734/734 - 3s - loss: 4.0377e-04 - val_loss: 4.1163e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 407/700\n",
            "734/734 - 3s - loss: 4.0314e-04 - val_loss: 4.1190e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 408/700\n",
            "734/734 - 3s - loss: 4.0251e-04 - val_loss: 4.1217e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 409/700\n",
            "734/734 - 3s - loss: 4.0189e-04 - val_loss: 4.1246e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 410/700\n",
            "734/734 - 3s - loss: 4.0127e-04 - val_loss: 4.1275e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 411/700\n",
            "734/734 - 3s - loss: 4.0065e-04 - val_loss: 4.1305e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 412/700\n",
            "734/734 - 3s - loss: 4.0003e-04 - val_loss: 4.1335e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 413/700\n",
            "734/734 - 3s - loss: 3.9941e-04 - val_loss: 4.1367e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 414/700\n",
            "734/734 - 3s - loss: 3.9880e-04 - val_loss: 4.1399e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 415/700\n",
            "734/734 - 3s - loss: 3.9819e-04 - val_loss: 4.1431e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 416/700\n",
            "734/734 - 3s - loss: 3.9758e-04 - val_loss: 4.1466e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 417/700\n",
            "734/734 - 3s - loss: 3.9697e-04 - val_loss: 4.1500e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 418/700\n",
            "734/734 - 3s - loss: 3.9636e-04 - val_loss: 4.1535e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 419/700\n",
            "734/734 - 3s - loss: 3.9576e-04 - val_loss: 4.1571e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 420/700\n",
            "734/734 - 3s - loss: 3.9516e-04 - val_loss: 4.1608e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 421/700\n",
            "734/734 - 3s - loss: 3.9456e-04 - val_loss: 4.1645e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 422/700\n",
            "734/734 - 3s - loss: 3.9396e-04 - val_loss: 4.1683e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 423/700\n",
            "734/734 - 3s - loss: 3.9337e-04 - val_loss: 4.1722e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 424/700\n",
            "734/734 - 3s - loss: 3.9278e-04 - val_loss: 4.1762e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 425/700\n",
            "734/734 - 3s - loss: 3.9219e-04 - val_loss: 4.1802e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 426/700\n",
            "734/734 - 3s - loss: 3.9160e-04 - val_loss: 4.1843e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 427/700\n",
            "734/734 - 3s - loss: 3.9101e-04 - val_loss: 4.1884e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 428/700\n",
            "734/734 - 3s - loss: 3.9043e-04 - val_loss: 4.1927e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 429/700\n",
            "734/734 - 3s - loss: 3.8985e-04 - val_loss: 4.1969e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 430/700\n",
            "734/734 - 3s - loss: 3.8927e-04 - val_loss: 4.2013e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 431/700\n",
            "734/734 - 3s - loss: 3.8870e-04 - val_loss: 4.2057e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 432/700\n",
            "734/734 - 3s - loss: 3.8813e-04 - val_loss: 4.2101e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 433/700\n",
            "734/734 - 3s - loss: 3.8756e-04 - val_loss: 4.2146e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 434/700\n",
            "734/734 - 3s - loss: 3.8699e-04 - val_loss: 4.2192e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 435/700\n",
            "734/734 - 3s - loss: 3.8643e-04 - val_loss: 4.2238e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 436/700\n",
            "734/734 - 3s - loss: 3.8587e-04 - val_loss: 4.2284e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 437/700\n",
            "734/734 - 3s - loss: 3.8531e-04 - val_loss: 4.2331e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 438/700\n",
            "734/734 - 3s - loss: 3.8476e-04 - val_loss: 4.2378e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 439/700\n",
            "734/734 - 3s - loss: 3.8421e-04 - val_loss: 4.2425e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 440/700\n",
            "734/734 - 3s - loss: 3.8366e-04 - val_loss: 4.2472e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 441/700\n",
            "734/734 - 3s - loss: 3.8311e-04 - val_loss: 4.2519e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 442/700\n",
            "734/734 - 3s - loss: 3.8257e-04 - val_loss: 4.2567e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 443/700\n",
            "734/734 - 3s - loss: 3.8203e-04 - val_loss: 4.2614e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 444/700\n",
            "734/734 - 3s - loss: 3.8149e-04 - val_loss: 4.2661e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 445/700\n",
            "734/734 - 3s - loss: 3.8096e-04 - val_loss: 4.2709e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 446/700\n",
            "734/734 - 3s - loss: 3.8043e-04 - val_loss: 4.2756e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 447/700\n",
            "734/734 - 3s - loss: 3.7991e-04 - val_loss: 4.2803e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 448/700\n",
            "734/734 - 3s - loss: 3.7938e-04 - val_loss: 4.2849e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 449/700\n",
            "734/734 - 3s - loss: 3.7886e-04 - val_loss: 4.2896e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 450/700\n",
            "734/734 - 3s - loss: 3.7835e-04 - val_loss: 4.2942e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 451/700\n",
            "734/734 - 3s - loss: 3.7784e-04 - val_loss: 4.2987e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 452/700\n",
            "734/734 - 4s - loss: 3.7733e-04 - val_loss: 4.3033e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 453/700\n",
            "734/734 - 3s - loss: 3.7682e-04 - val_loss: 4.3077e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 454/700\n",
            "734/734 - 3s - loss: 3.7632e-04 - val_loss: 4.3121e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 455/700\n",
            "734/734 - 3s - loss: 3.7582e-04 - val_loss: 4.3164e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 456/700\n",
            "734/734 - 3s - loss: 3.7532e-04 - val_loss: 4.3207e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 457/700\n",
            "734/734 - 3s - loss: 3.7483e-04 - val_loss: 4.3249e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 458/700\n",
            "734/734 - 3s - loss: 3.7434e-04 - val_loss: 4.3290e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 459/700\n",
            "734/734 - 3s - loss: 3.7385e-04 - val_loss: 4.3331e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 460/700\n",
            "734/734 - 3s - loss: 3.7336e-04 - val_loss: 4.3370e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 461/700\n",
            "734/734 - 3s - loss: 3.7288e-04 - val_loss: 4.3409e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 462/700\n",
            "734/734 - 3s - loss: 3.7241e-04 - val_loss: 4.3446e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 463/700\n",
            "734/734 - 3s - loss: 3.7193e-04 - val_loss: 4.3483e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 464/700\n",
            "734/734 - 3s - loss: 3.7146e-04 - val_loss: 4.3519e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 465/700\n",
            "734/734 - 3s - loss: 3.7099e-04 - val_loss: 4.3554e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 466/700\n",
            "734/734 - 3s - loss: 3.7053e-04 - val_loss: 4.3588e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 467/700\n",
            "734/734 - 3s - loss: 3.7006e-04 - val_loss: 4.3621e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 468/700\n",
            "734/734 - 3s - loss: 3.6960e-04 - val_loss: 4.3653e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 469/700\n",
            "734/734 - 3s - loss: 3.6915e-04 - val_loss: 4.3684e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 470/700\n",
            "734/734 - 3s - loss: 3.6869e-04 - val_loss: 4.3713e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 471/700\n",
            "734/734 - 3s - loss: 3.6824e-04 - val_loss: 4.3742e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 472/700\n",
            "734/734 - 3s - loss: 3.6779e-04 - val_loss: 4.3769e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 473/700\n",
            "734/734 - 3s - loss: 3.6735e-04 - val_loss: 4.3796e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 474/700\n",
            "734/734 - 3s - loss: 3.6690e-04 - val_loss: 4.3821e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 475/700\n",
            "734/734 - 3s - loss: 3.6646e-04 - val_loss: 4.3845e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 476/700\n",
            "734/734 - 3s - loss: 3.6603e-04 - val_loss: 4.3868e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 477/700\n",
            "734/734 - 3s - loss: 3.6559e-04 - val_loss: 4.3890e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 478/700\n",
            "734/734 - 3s - loss: 3.6516e-04 - val_loss: 4.3910e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 479/700\n",
            "734/734 - 3s - loss: 3.6473e-04 - val_loss: 4.3929e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 480/700\n",
            "734/734 - 3s - loss: 3.6430e-04 - val_loss: 4.3948e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 481/700\n",
            "734/734 - 3s - loss: 3.6388e-04 - val_loss: 4.3965e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 482/700\n",
            "734/734 - 3s - loss: 3.6346e-04 - val_loss: 4.3981e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 483/700\n",
            "734/734 - 3s - loss: 3.6304e-04 - val_loss: 4.3995e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 484/700\n",
            "734/734 - 3s - loss: 3.6262e-04 - val_loss: 4.4009e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 485/700\n",
            "734/734 - 3s - loss: 3.6221e-04 - val_loss: 4.4022e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 486/700\n",
            "734/734 - 3s - loss: 3.6179e-04 - val_loss: 4.4032e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 487/700\n",
            "734/734 - 3s - loss: 3.6138e-04 - val_loss: 4.4043e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 488/700\n",
            "734/734 - 3s - loss: 3.6097e-04 - val_loss: 4.4052e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 489/700\n",
            "734/734 - 3s - loss: 3.6057e-04 - val_loss: 4.4060e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 490/700\n",
            "734/734 - 3s - loss: 3.6017e-04 - val_loss: 4.4066e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 491/700\n",
            "734/734 - 3s - loss: 3.5976e-04 - val_loss: 4.4072e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 492/700\n",
            "734/734 - 3s - loss: 3.5937e-04 - val_loss: 4.4077e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 493/700\n",
            "734/734 - 3s - loss: 3.5897e-04 - val_loss: 4.4080e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 494/700\n",
            "734/734 - 3s - loss: 3.5857e-04 - val_loss: 4.4082e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 495/700\n",
            "734/734 - 3s - loss: 3.5818e-04 - val_loss: 4.4083e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 496/700\n",
            "734/734 - 3s - loss: 3.5779e-04 - val_loss: 4.4084e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 497/700\n",
            "734/734 - 3s - loss: 3.5740e-04 - val_loss: 4.4083e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 498/700\n",
            "734/734 - 3s - loss: 3.5702e-04 - val_loss: 4.4081e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 499/700\n",
            "734/734 - 3s - loss: 3.5663e-04 - val_loss: 4.4079e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 500/700\n",
            "734/734 - 3s - loss: 3.5625e-04 - val_loss: 4.4075e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 501/700\n",
            "734/734 - 3s - loss: 3.5587e-04 - val_loss: 4.4070e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 502/700\n",
            "734/734 - 3s - loss: 3.5549e-04 - val_loss: 4.4064e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 503/700\n",
            "734/734 - 3s - loss: 3.5511e-04 - val_loss: 4.4058e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 504/700\n",
            "734/734 - 3s - loss: 3.5474e-04 - val_loss: 4.4051e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 505/700\n",
            "734/734 - 3s - loss: 3.5436e-04 - val_loss: 4.4042e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 506/700\n",
            "734/734 - 3s - loss: 3.5399e-04 - val_loss: 4.4033e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 507/700\n",
            "734/734 - 3s - loss: 3.5362e-04 - val_loss: 4.4023e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 508/700\n",
            "734/734 - 3s - loss: 3.5325e-04 - val_loss: 4.4012e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 509/700\n",
            "734/734 - 3s - loss: 3.5289e-04 - val_loss: 4.4000e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 510/700\n",
            "734/734 - 3s - loss: 3.5252e-04 - val_loss: 4.3988e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 511/700\n",
            "734/734 - 3s - loss: 3.5216e-04 - val_loss: 4.3974e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 512/700\n",
            "734/734 - 3s - loss: 3.5180e-04 - val_loss: 4.3960e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 513/700\n",
            "734/734 - 3s - loss: 3.5143e-04 - val_loss: 4.3945e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 514/700\n",
            "734/734 - 3s - loss: 3.5108e-04 - val_loss: 4.3930e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 515/700\n",
            "734/734 - 3s - loss: 3.5072e-04 - val_loss: 4.3914e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 516/700\n",
            "734/734 - 3s - loss: 3.5036e-04 - val_loss: 4.3897e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 517/700\n",
            "734/734 - 3s - loss: 3.5001e-04 - val_loss: 4.3879e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 518/700\n",
            "734/734 - 3s - loss: 3.4966e-04 - val_loss: 4.3861e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 519/700\n",
            "734/734 - 3s - loss: 3.4931e-04 - val_loss: 4.3842e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 520/700\n",
            "734/734 - 3s - loss: 3.4896e-04 - val_loss: 4.3822e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 521/700\n",
            "734/734 - 3s - loss: 3.4861e-04 - val_loss: 4.3802e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 522/700\n",
            "734/734 - 3s - loss: 3.4826e-04 - val_loss: 4.3782e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 523/700\n",
            "734/734 - 3s - loss: 3.4791e-04 - val_loss: 4.3761e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 524/700\n",
            "734/734 - 3s - loss: 3.4757e-04 - val_loss: 4.3739e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 525/700\n",
            "734/734 - 3s - loss: 3.4723e-04 - val_loss: 4.3716e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 526/700\n",
            "734/734 - 3s - loss: 3.4689e-04 - val_loss: 4.3694e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 527/700\n",
            "734/734 - 3s - loss: 3.4655e-04 - val_loss: 4.3671e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 528/700\n",
            "734/734 - 3s - loss: 3.4621e-04 - val_loss: 4.3647e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 529/700\n",
            "734/734 - 3s - loss: 3.4587e-04 - val_loss: 4.3623e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 530/700\n",
            "734/734 - 3s - loss: 3.4553e-04 - val_loss: 4.3598e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 531/700\n",
            "734/734 - 3s - loss: 3.4520e-04 - val_loss: 4.3573e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 532/700\n",
            "734/734 - 3s - loss: 3.4486e-04 - val_loss: 4.3547e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 533/700\n",
            "734/734 - 3s - loss: 3.4453e-04 - val_loss: 4.3522e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 534/700\n",
            "734/734 - 3s - loss: 3.4420e-04 - val_loss: 4.3496e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 535/700\n",
            "734/734 - 3s - loss: 3.4387e-04 - val_loss: 4.3469e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 536/700\n",
            "734/734 - 3s - loss: 3.4354e-04 - val_loss: 4.3442e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 537/700\n",
            "734/734 - 3s - loss: 3.4321e-04 - val_loss: 4.3415e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 538/700\n",
            "734/734 - 3s - loss: 3.4288e-04 - val_loss: 4.3387e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 539/700\n",
            "734/734 - 3s - loss: 3.4256e-04 - val_loss: 4.3360e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 540/700\n",
            "734/734 - 3s - loss: 3.4223e-04 - val_loss: 4.3332e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 541/700\n",
            "734/734 - 3s - loss: 3.4191e-04 - val_loss: 4.3303e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 542/700\n",
            "734/734 - 3s - loss: 3.4158e-04 - val_loss: 4.3275e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 543/700\n",
            "734/734 - 3s - loss: 3.4126e-04 - val_loss: 4.3246e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 544/700\n",
            "734/734 - 3s - loss: 3.4094e-04 - val_loss: 4.3217e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 545/700\n",
            "734/734 - 3s - loss: 3.4062e-04 - val_loss: 4.3188e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 546/700\n",
            "734/734 - 4s - loss: 3.4031e-04 - val_loss: 4.3158e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 547/700\n",
            "734/734 - 3s - loss: 3.3999e-04 - val_loss: 4.3128e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 548/700\n",
            "734/734 - 3s - loss: 3.3967e-04 - val_loss: 4.3099e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 549/700\n",
            "734/734 - 3s - loss: 3.3936e-04 - val_loss: 4.3068e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 550/700\n",
            "734/734 - 3s - loss: 3.3904e-04 - val_loss: 4.3038e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 551/700\n",
            "734/734 - 3s - loss: 3.3873e-04 - val_loss: 4.3007e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 552/700\n",
            "734/734 - 3s - loss: 3.3842e-04 - val_loss: 4.2977e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 553/700\n",
            "734/734 - 3s - loss: 3.3810e-04 - val_loss: 4.2946e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 554/700\n",
            "734/734 - 3s - loss: 3.3779e-04 - val_loss: 4.2916e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 555/700\n",
            "734/734 - 3s - loss: 3.3749e-04 - val_loss: 4.2885e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 556/700\n",
            "734/734 - 3s - loss: 3.3718e-04 - val_loss: 4.2854e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 557/700\n",
            "734/734 - 3s - loss: 3.3687e-04 - val_loss: 4.2823e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 558/700\n",
            "734/734 - 3s - loss: 3.3656e-04 - val_loss: 4.2791e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 559/700\n",
            "734/734 - 3s - loss: 3.3626e-04 - val_loss: 4.2760e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 560/700\n",
            "734/734 - 3s - loss: 3.3595e-04 - val_loss: 4.2729e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 561/700\n",
            "734/734 - 3s - loss: 3.3565e-04 - val_loss: 4.2697e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 562/700\n",
            "734/734 - 3s - loss: 3.3535e-04 - val_loss: 4.2666e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 563/700\n",
            "734/734 - 3s - loss: 3.3504e-04 - val_loss: 4.2634e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 564/700\n",
            "734/734 - 3s - loss: 3.3474e-04 - val_loss: 4.2602e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 565/700\n",
            "734/734 - 3s - loss: 3.3444e-04 - val_loss: 4.2571e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 566/700\n",
            "734/734 - 3s - loss: 3.3415e-04 - val_loss: 4.2539e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 567/700\n",
            "734/734 - 3s - loss: 3.3385e-04 - val_loss: 4.2507e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 568/700\n",
            "734/734 - 3s - loss: 3.3355e-04 - val_loss: 4.2475e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 569/700\n",
            "734/734 - 3s - loss: 3.3325e-04 - val_loss: 4.2443e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 570/700\n",
            "734/734 - 4s - loss: 3.3296e-04 - val_loss: 4.2411e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 571/700\n",
            "734/734 - 3s - loss: 3.3267e-04 - val_loss: 4.2379e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 572/700\n",
            "734/734 - 3s - loss: 3.3237e-04 - val_loss: 4.2347e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 573/700\n",
            "734/734 - 3s - loss: 3.3208e-04 - val_loss: 4.2315e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 574/700\n",
            "734/734 - 3s - loss: 3.3179e-04 - val_loss: 4.2283e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 575/700\n",
            "734/734 - 3s - loss: 3.3150e-04 - val_loss: 4.2251e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 576/700\n",
            "734/734 - 3s - loss: 3.3121e-04 - val_loss: 4.2219e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 577/700\n",
            "734/734 - 3s - loss: 3.3092e-04 - val_loss: 4.2187e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 578/700\n",
            "734/734 - 3s - loss: 3.3064e-04 - val_loss: 4.2155e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 579/700\n",
            "734/734 - 3s - loss: 3.3035e-04 - val_loss: 4.2123e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 580/700\n",
            "734/734 - 3s - loss: 3.3007e-04 - val_loss: 4.2090e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 581/700\n",
            "734/734 - 3s - loss: 3.2978e-04 - val_loss: 4.2058e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 582/700\n",
            "734/734 - 3s - loss: 3.2950e-04 - val_loss: 4.2025e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 583/700\n",
            "734/734 - 3s - loss: 3.2922e-04 - val_loss: 4.1993e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 584/700\n",
            "734/734 - 3s - loss: 3.2893e-04 - val_loss: 4.1961e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 585/700\n",
            "734/734 - 3s - loss: 3.2865e-04 - val_loss: 4.1928e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 586/700\n",
            "734/734 - 3s - loss: 3.2837e-04 - val_loss: 4.1895e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 587/700\n",
            "734/734 - 3s - loss: 3.2809e-04 - val_loss: 4.1863e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 588/700\n",
            "734/734 - 3s - loss: 3.2781e-04 - val_loss: 4.1830e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 589/700\n",
            "734/734 - 3s - loss: 3.2753e-04 - val_loss: 4.1797e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 590/700\n",
            "734/734 - 3s - loss: 3.2725e-04 - val_loss: 4.1764e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 591/700\n",
            "734/734 - 3s - loss: 3.2697e-04 - val_loss: 4.1731e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 592/700\n",
            "734/734 - 3s - loss: 3.2669e-04 - val_loss: 4.1698e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 593/700\n",
            "734/734 - 4s - loss: 3.2641e-04 - val_loss: 4.1665e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 594/700\n",
            "734/734 - 3s - loss: 3.2613e-04 - val_loss: 4.1632e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 595/700\n",
            "734/734 - 3s - loss: 3.2584e-04 - val_loss: 4.1599e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 596/700\n",
            "734/734 - 3s - loss: 3.2556e-04 - val_loss: 4.1566e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 597/700\n",
            "734/734 - 3s - loss: 3.2527e-04 - val_loss: 4.1533e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 598/700\n",
            "734/734 - 3s - loss: 3.2499e-04 - val_loss: 4.1500e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 599/700\n",
            "734/734 - 3s - loss: 3.2470e-04 - val_loss: 4.1466e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 600/700\n",
            "734/734 - 3s - loss: 3.2443e-04 - val_loss: 4.1433e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 601/700\n",
            "734/734 - 3s - loss: 3.2419e-04 - val_loss: 4.1400e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 602/700\n",
            "734/734 - 3s - loss: 3.2399e-04 - val_loss: 4.1370e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 603/700\n",
            "734/734 - 3s - loss: 3.2390e-04 - val_loss: 4.1348e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 604/700\n",
            "734/734 - 3s - loss: 3.2393e-04 - val_loss: 4.1342e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 605/700\n",
            "734/734 - 3s - loss: 3.2407e-04 - val_loss: 4.1366e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 606/700\n",
            "734/734 - 3s - loss: 3.2418e-04 - val_loss: 4.1420e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 607/700\n",
            "734/734 - 3s - loss: 3.2410e-04 - val_loss: 4.1492e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 608/700\n",
            "734/734 - 3s - loss: 3.2382e-04 - val_loss: 4.1557e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 609/700\n",
            "734/734 - 3s - loss: 3.2342e-04 - val_loss: 4.1600e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 610/700\n",
            "734/734 - 3s - loss: 3.2296e-04 - val_loss: 4.1616e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 611/700\n",
            "734/734 - 3s - loss: 3.2249e-04 - val_loss: 4.1606e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 612/700\n",
            "734/734 - 3s - loss: 3.2204e-04 - val_loss: 4.1575e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 613/700\n",
            "734/734 - 3s - loss: 3.2165e-04 - val_loss: 4.1534e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 614/700\n",
            "734/734 - 3s - loss: 3.2144e-04 - val_loss: 4.1494e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 615/700\n",
            "734/734 - 3s - loss: 3.2172e-04 - val_loss: 4.1475e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 616/700\n",
            "734/734 - 3s - loss: 3.2338e-04 - val_loss: 4.1480e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 617/700\n",
            "734/734 - 3s - loss: 3.2676e-04 - val_loss: 4.1370e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 618/700\n",
            "734/734 - 3s - loss: 3.2867e-04 - val_loss: 4.1055e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 619/700\n",
            "734/734 - 3s - loss: 3.2752e-04 - val_loss: 4.0820e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 620/700\n",
            "734/734 - 3s - loss: 3.2568e-04 - val_loss: 4.0691e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 621/700\n",
            "734/734 - 3s - loss: 3.2398e-04 - val_loss: 4.0621e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 622/700\n",
            "734/734 - 3s - loss: 3.2244e-04 - val_loss: 4.0585e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 623/700\n",
            "734/734 - 3s - loss: 3.2112e-04 - val_loss: 4.0565e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 624/700\n",
            "734/734 - 3s - loss: 3.2004e-04 - val_loss: 4.0552e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 625/700\n",
            "734/734 - 3s - loss: 3.1917e-04 - val_loss: 4.0540e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 626/700\n",
            "734/734 - 3s - loss: 3.1847e-04 - val_loss: 4.0526e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 627/700\n",
            "734/734 - 3s - loss: 3.1791e-04 - val_loss: 4.0508e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 628/700\n",
            "734/734 - 3s - loss: 3.1754e-04 - val_loss: 4.0485e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 629/700\n",
            "734/734 - 3s - loss: 3.1748e-04 - val_loss: 4.0461e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 630/700\n",
            "734/734 - 3s - loss: 3.1808e-04 - val_loss: 4.0458e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 631/700\n",
            "734/734 - 3s - loss: 3.1951e-04 - val_loss: 4.0536e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 632/700\n",
            "734/734 - 3s - loss: 3.2071e-04 - val_loss: 4.0722e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 633/700\n",
            "734/734 - 3s - loss: 3.2079e-04 - val_loss: 4.0920e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 634/700\n",
            "734/734 - 3s - loss: 3.2028e-04 - val_loss: 4.1056e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 635/700\n",
            "734/734 - 3s - loss: 3.1966e-04 - val_loss: 4.1120e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 636/700\n",
            "734/734 - 3s - loss: 3.1900e-04 - val_loss: 4.1127e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 637/700\n",
            "734/734 - 3s - loss: 3.1836e-04 - val_loss: 4.1094e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 638/700\n",
            "734/734 - 3s - loss: 3.1774e-04 - val_loss: 4.1036e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 639/700\n",
            "734/734 - 3s - loss: 3.1716e-04 - val_loss: 4.0963e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 640/700\n",
            "734/734 - 3s - loss: 3.1661e-04 - val_loss: 4.0883e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 641/700\n",
            "734/734 - 3s - loss: 3.1607e-04 - val_loss: 4.0800e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 642/700\n",
            "734/734 - 4s - loss: 3.1556e-04 - val_loss: 4.0718e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 643/700\n",
            "734/734 - 3s - loss: 3.1507e-04 - val_loss: 4.0639e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 644/700\n",
            "734/734 - 3s - loss: 3.1464e-04 - val_loss: 4.0565e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 645/700\n",
            "734/734 - 3s - loss: 3.1434e-04 - val_loss: 4.0502e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 646/700\n",
            "734/734 - 3s - loss: 3.1439e-04 - val_loss: 4.0462e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 647/700\n",
            "734/734 - 3s - loss: 3.1541e-04 - val_loss: 4.0454e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 648/700\n",
            "734/734 - 3s - loss: 3.1810e-04 - val_loss: 4.0409e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 649/700\n",
            "734/734 - 3s - loss: 3.2074e-04 - val_loss: 4.0148e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 650/700\n",
            "734/734 - 3s - loss: 3.2048e-04 - val_loss: 3.9874e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 651/700\n",
            "734/734 - 3s - loss: 3.1880e-04 - val_loss: 3.9730e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 652/700\n",
            "734/734 - 3s - loss: 3.1717e-04 - val_loss: 3.9655e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 653/700\n",
            "734/734 - 3s - loss: 3.1567e-04 - val_loss: 3.9616e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 654/700\n",
            "734/734 - 3s - loss: 3.1435e-04 - val_loss: 3.9594e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 655/700\n",
            "734/734 - 3s - loss: 3.1324e-04 - val_loss: 3.9578e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 656/700\n",
            "734/734 - 3s - loss: 3.1234e-04 - val_loss: 3.9561e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 657/700\n",
            "734/734 - 3s - loss: 3.1162e-04 - val_loss: 3.9541e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 658/700\n",
            "734/734 - 3s - loss: 3.1106e-04 - val_loss: 3.9518e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 659/700\n",
            "734/734 - 3s - loss: 3.1073e-04 - val_loss: 3.9492e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 660/700\n",
            "734/734 - 3s - loss: 3.1080e-04 - val_loss: 3.9469e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 661/700\n",
            "734/734 - 3s - loss: 3.1167e-04 - val_loss: 3.9477e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 662/700\n",
            "734/734 - 3s - loss: 3.1331e-04 - val_loss: 3.9582e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 663/700\n",
            "734/734 - 3s - loss: 3.1434e-04 - val_loss: 3.9777e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 664/700\n",
            "734/734 - 3s - loss: 3.1417e-04 - val_loss: 3.9953e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 665/700\n",
            "734/734 - 3s - loss: 3.1356e-04 - val_loss: 4.0055e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 666/700\n",
            "734/734 - 3s - loss: 3.1292e-04 - val_loss: 4.0088e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 667/700\n",
            "734/734 - 3s - loss: 3.1228e-04 - val_loss: 4.0073e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 668/700\n",
            "734/734 - 3s - loss: 3.1166e-04 - val_loss: 4.0027e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 669/700\n",
            "734/734 - 3s - loss: 3.1109e-04 - val_loss: 3.9962e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 670/700\n",
            "734/734 - 3s - loss: 3.1055e-04 - val_loss: 3.9888e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 671/700\n",
            "734/734 - 3s - loss: 3.1004e-04 - val_loss: 3.9811e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 672/700\n",
            "734/734 - 3s - loss: 3.0954e-04 - val_loss: 3.9732e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 673/700\n",
            "734/734 - 3s - loss: 3.0906e-04 - val_loss: 3.9655e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 674/700\n",
            "734/734 - 3s - loss: 3.0860e-04 - val_loss: 3.9580e-04 - 3s/epoch - 5ms/step\n",
            "Epoch 675/700\n",
            "734/734 - 3s - loss: 3.0817e-04 - val_loss: 3.9510e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 676/700\n",
            "734/734 - 3s - loss: 3.0781e-04 - val_loss: 3.9448e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 677/700\n",
            "734/734 - 3s - loss: 3.0766e-04 - val_loss: 3.9399e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 678/700\n",
            "734/734 - 3s - loss: 3.0803e-04 - val_loss: 3.9377e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 679/700\n",
            "734/734 - 3s - loss: 3.0966e-04 - val_loss: 3.9378e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 680/700\n",
            "734/734 - 3s - loss: 3.1268e-04 - val_loss: 3.9273e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 681/700\n",
            "734/734 - 3s - loss: 3.1443e-04 - val_loss: 3.8965e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 682/700\n",
            "734/734 - 3s - loss: 3.1338e-04 - val_loss: 3.8745e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 683/700\n",
            "734/734 - 3s - loss: 3.1170e-04 - val_loss: 3.8643e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 684/700\n",
            "734/734 - 3s - loss: 3.1019e-04 - val_loss: 3.8592e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 685/700\n",
            "734/734 - 3s - loss: 3.0880e-04 - val_loss: 3.8565e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 686/700\n",
            "734/734 - 3s - loss: 3.0759e-04 - val_loss: 3.8546e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 687/700\n",
            "734/734 - 3s - loss: 3.0659e-04 - val_loss: 3.8524e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 688/700\n",
            "734/734 - 3s - loss: 3.0578e-04 - val_loss: 3.8499e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 689/700\n",
            "734/734 - 4s - loss: 3.0514e-04 - val_loss: 3.8470e-04 - 4s/epoch - 5ms/step\n",
            "Epoch 690/700\n",
            "734/734 - 3s - loss: 3.0468e-04 - val_loss: 3.8437e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 691/700\n",
            "734/734 - 3s - loss: 3.0450e-04 - val_loss: 3.8403e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 692/700\n",
            "734/734 - 3s - loss: 3.0490e-04 - val_loss: 3.8382e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 693/700\n",
            "734/734 - 3s - loss: 3.0630e-04 - val_loss: 3.8416e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 694/700\n",
            "734/734 - 3s - loss: 3.0802e-04 - val_loss: 3.8563e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 695/700\n",
            "734/734 - 3s - loss: 3.0847e-04 - val_loss: 3.8755e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 696/700\n",
            "734/734 - 3s - loss: 3.0792e-04 - val_loss: 3.8884e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 697/700\n",
            "734/734 - 3s - loss: 3.0722e-04 - val_loss: 3.8936e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 698/700\n",
            "734/734 - 3s - loss: 3.0655e-04 - val_loss: 3.8930e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 699/700\n",
            "734/734 - 3s - loss: 3.0592e-04 - val_loss: 3.8889e-04 - 3s/epoch - 4ms/step\n",
            "Epoch 700/700\n",
            "734/734 - 3s - loss: 3.0534e-04 - val_loss: 3.8827e-04 - 3s/epoch - 4ms/step\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(42)\n",
        "np.random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "from keras import backend as K\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# fit the model\n",
        "neurons= [12]#12 \n",
        "n_epochs=700#186\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(neurons[0], activation=\"tanh\", input_shape=(timesteps, n_features)))\n",
        "model.add(Dense(steps_ahead)) # output layer\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "# # early stopping to return the best model\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=2, restore_best_weights=True, mode='min')\n",
        "# save the best weights if training is interrupted\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min') \n",
        "\n",
        "# Set the initial and total number of epochs\n",
        "initial_epoch = 1\n",
        "n_epochs = 700\n",
        "loss_tracking = list()\n",
        "\n",
        "# Run the training loop\n",
        "for epoch in range(initial_epoch , n_epochs+1):\n",
        "    print(f'Epoch {epoch}/{n_epochs}')\n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "                    epochs=1, batch_size=2, validation_data=(test_X, test_y), verbose=2,\n",
        "                     shuffle=False)\n",
        "    # to find at which epoch each loss is\n",
        "    validation_loss= model.evaluate(test_X, test_y, verbose=0)\n",
        "    loss_tracking.append(validation_loss)\n",
        "    # Save the model every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "        #model.save(f'model_{epoch}Eps.h5')\n",
        "        model.save(os.path.join(directory, f'model_{epoch}Eps.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyrxlI_zh4_P"
      },
      "outputs": [],
      "source": [
        "# load the trained saved model\n",
        "model_saved = tf.keras.models.load_model('/content/drive/My Drive/my_trained_models/model_20Eps.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "615tFlHjehTK"
      },
      "outputs": [],
      "source": [
        "# Load the best weights\n",
        "model.load_weights(f'.mdl_wts.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUQ9MQO4e0uQ",
        "outputId": "a6da8370-8d71-4c41-df23-d5c2d95bb49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:509 Validation loss: 0.00018703137175180018\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_X, test_y, verbose=0)\n",
        "best_epoch = loss_tracking.index(score) + 1\n",
        "# validation loss and corresponding epoch for the saved model\n",
        "print(f'Epoch:{best_epoch} Validation loss: {score}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfmgjN3OhMYp"
      },
      "outputs": [],
      "source": [
        "# # if training is interrupted \n",
        "# n_epochs = 700 - best_epoch # to continue from which epoch it was stopped\n",
        "# # Run the training loop\n",
        "# for epoch in range(initial_epoch , n_epochs+1):\n",
        "#     print(f'Epoch {epoch}/{n_epochs}')\n",
        "#     # Train the model for one epoch\n",
        "#     history = model_saved.fit(train_X, train_y, callbacks=[early_stopping, mcp_save],\n",
        "#                     epochs=1, batch_size=2, validation_data=(test_X, test_y), verbose=2,\n",
        "#                      shuffle=False)\n",
        "#     # to find at which epoch each loss is\n",
        "#     validation_loss= model_saved.evaluate(test_X, test_y, verbose=0)\n",
        "#     loss_tracking.append(validation_loss)\n",
        "#     # Save the model every 10 epochs\n",
        "#     if epoch % 10 == 0:\n",
        "#         # Save the model  in HDF5 foramt with a filename that includes the epoch number\n",
        "#         model_saved.save(f'model_{epoch}Eps.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lKT1sl6ehRW"
      },
      "outputs": [],
      "source": [
        "# 2.455e-04 all variables 6 times steps\n",
        "# 4.2105e-04 all variables 4 times steps\n",
        "# all variables 9 time steps 1.870e-04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "Om2PkqgiVjri",
        "outputId": "5ce32d4e-1249-48b4-b967-1d7e26ec4822"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCEAAAFoCAYAAABpHeH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxddb3v//d3z0P2zpwmTZoOtLQFCkVKqSCDoEIRRVEBUZAjVzwHvE7n6k88lyt6fk73iLOcIwgKeBR6UKRyQBCqzFBaxpaWEjqnQ5p5zp6+94+9kyZpaEObvddO9uv5eOzHmr5r7c8KfWjz7ncw1loBAAAAAABkm8vpAgAAAAAAQGEghAAAAAAAADlBCAEAAAAAAHKCEAIAAAAAAOQEIQQAAAAAAMgJQggAAAAAAJAT4wohjDHnGWNeN8Y0GGO+NsZ1vzHm7sz154wxs4Zduy5z/nVjzLnDzm81xrxqjHnJGLNmIl4GAAAAAADkL8+hGhhj3JJ+Iem9knZKet4Ys9Ja+9qwZldJarPWzjXGXCrp+5IuMcYcI+lSScdKmi7pEWPM0dbaZOa+d1trmyfwfQAAAAAAQJ4aT0+IpZIarLWbrbUxSXdJunBUmwsl3Z7Zv0fSOcYYkzl/l7V2wFq7RVJD5nkAAAAAAKDAHLInhKRaSTuGHe+UdMpbtbHWJowxHZLKM+efHXVvbWbfSnrYGGMl/dJae/OhCqmoqLCzZs0aR8kAAAAAACBX1q5d22ytrTxUu/GEENnyLmttozGmStJfjTEbrbWPj25kjLla0tWSVF9frzVrmD4CAAAAAIB8YozZNp524xmO0ShpxrDjusy5MdsYYzySiiW1HOxea+3gtknSvXqLYRrW2puttUustUsqKw8ZqgAAAAAAgDw1nhDieUnzjDGzjTE+pSeaXDmqzUpJn8rsf1TSKmutzZy/NLN6xmxJ8yStNsaEjTERSTLGhCW9T9K6I38dAAAAAACQrw45HCMzx8PnJD0kyS3pNmvtemPMtyStsdaulHSrpDuNMQ2SWpUOKpRpt0LSa5ISkq611iaNMdMk3Zueu1IeSb+z1v4lC+8HAAAAAADyhEl3WJgclixZYpkTAgAAAACA/GKMWWutXXKoduMZjgEAAAAAAHDEnFwdAwAAAACArOvs7FRTU5Pi8bjTpUw6Xq9XVVVVikajE/I8QggAAAAAwJTV2dmpvXv3qra2VsFgUJm5CTEO1lr19fWpsTG9QOZEBBEMxwAAAAAATFlNTU2qra1VKBQigHibjDEKhUKqra1VU1PThDyTEAIAAAAAMGXF43EFg0Gny5jUgsHghA1lIYQAAAAAAExp9IA4MhP58yOEAAAAAAAAOUEIkUVbmnv0t9cnZtwMAAAAAKAwrVixQr/5zW8mzXMPhhAii+5Zu0OfuX2NrLVOlwIAAAAAmKQIITAuIZ9HiZRVLJlyuhQAAAAAABxHCJFFYZ9bktQzkHS4EgAAAADAZHTllVfqD3/4gx577DEZY2SM0Q033CBJuu+++7RkyRIFAgFVV1frq1/96ohVLHbu3KmLL75YVVVVCgaDOuqoo3T99dcf8rnZ5Mn6NxSwsD/94+0ZSKgs7HO4GgAAAADAZHP99ddr+/btam9v10033SRJqqur04oVK/Txj39cn/3sZ/Wd73xHb775pq677jqlUin94Ac/kCRdccUV6uvr080336ySkhJt3rxZGzduPOhzs40QIouGQohYwuFKAAAAAACT0VFHHaWysjKlUiktW7ZMkmSt1Ve+8hVdccUVQwGCJPn9fl177bW67rrrVF5ertWrV+v3v/+9PvCBD0iSzjrrrIM+NxcIIbJof08IhmMAAAAAQL745p/X67VdnY589zHTo/rGB449omds2rRJ27dv18UXX6xEYv8/ep999tnq7+/XunXrdOaZZ2rx4sW67rrr1NLSorPPPlv19fVHWv4RY06ILNo/JwQ9IQAAAAAAE6O5uVmSdP7558vr9Q59Zs+eLUnasWOHJOnuu+/WkiVL9KUvfUkzZ87U4sWL9eijjzpWt0RPiKwK+dI/3l6GYwAAAABA3jjSnghOKysrkyTdfPPNOvHEEw+4PhhG1NbW6je/+Y1SqZRWr16tG264QR/84Ae1fft2lZeX57TmQYQQWVSUGY7RzXAMAAAAAMBh8vl86u/vHzqeP3++amtrtXXrVn3mM5855P0ul0vLli3TN77xDZ166qnatm2bysvLD3huLhBCZFHInx6OQU8IAAAAAMDhWrBgge677z796U9/Ul1dnaZPn64bb7xRl19+uTo7O7V8+XL5fD5t3rxZf/rTn3TPPfcoHo/r3HPP1RVXXKGjjz5aAwMDuvHGG1VdXa2FCxe+5XOnT5+e1XchhMiiIiamBAAAAAAcoWuuuUYvvviiPv3pT6utrU3f+MY3dMMNNygajeo73/mObrvtNrndbs2ZM0cXXHCBfD6f3G63Fi1apJ/85CfasWOHQqGQli1bpocffljBYPCgz80mQogs8ntcchkmpgQAAAAAHL6Kigrde++9B5xfvny5li9fPuY9Ho9Ht9xyy2E9N5tYHSOLjDEK+z3qYTgGAAAAAACEENkW9nnoCQEAAAAAgAghsi7kd6snxpwQAAAAAAAQQmRZkZ+eEAAAAAAASIQQWRfyudXL6hgAAAAAABBCZFuR36NuekIAAAAAgGOstU6XMKlN5M+PECLLQj6PelkdAwAAAAAc4fV61dfX53QZk1pfX5+8Xu+EPIsQIsvCTEwJAAAAAI6pqqpSY2Ojent76RHxNllr1dvbq8bGRlVVVU3IMz0T8hS8JZboBAAAAADnRKNRSdKuXbsUj8cdrmby8Xq9mjZt2tDP8UgRQmRZyO9RbyypVMrK5TJOlwMAAAAABScajU7YL9E4MgzHyLIiv1uS1BtnSAYAAAAAoLARQmRZyJfubNLLkAwAAAAAQIEjhMiyIn86hGCZTgAAAABAoSOEyLKQLzMcgxUyAAAAAAAFjhAiy8L0hAAAAAAAQBIhRNYNhhC9MUIIAAAAAEBhI4TIsnBmOEbPAMMxAAAAAACFjRAiywZ7QvQwHAMAAAAAUOAIIbIsnFmis4eJKQEAAAAABY4QIstC/sHhGPSEAAAAAAAUNkKILPO6XfJ5XOphYkoAAAAAQIEjhMiBsM9NTwgAAAAAQMEjhMiBsN+jXlbHAAAAAAAUOEKIHAj7POqmJwQAAAAAoMARQuRAUYAQAgAAAAAAQogciAQ86uonhAAAAAAAFDZCiBwo8tMTAgAAAAAAQogciAS86uqPO10GAAAAAACOIoTIgWjAo06GYwAAAAAAChwhRA5EAh7FEikNJFimEwAAAABQuAghcqDI75EkddMbAgAAAABQwAghciAS8EoSK2QAAAAAAAoaIUQORALpnhCEEAAAAACAQkYIkQNFgyHEACtkAAAAAAAKFyFEDkQZjgEAAAAAACFELjAcAwAAAACAcYYQxpjzjDGvG2MajDFfG+O63xhzd+b6c8aYWcOuXZc5/7ox5txR97mNMS8aY+4/0hfJZ4MTU3b3MxwDAAAAAFC4DhlCGGPckn4habmkYyR93BhzzKhmV0lqs9bOlfQjSd/P3HuMpEslHSvpPEk3ZZ436AuSNhzpS+S7wSU66QkBAAAAAChk4+kJsVRSg7V2s7U2JukuSReOanOhpNsz+/dIOscYYzLn77LWDlhrt0hqyDxPxpg6Se+X9Ksjf4385vO45Pe41DVACAEAAAAAKFzjCSFqJe0Ydrwzc27MNtbahKQOSeWHuPfHkr4qKXWwLzfGXG2MWWOMWbNv375xlJufIgGvuhiOAQAAAAAoYI5MTGmMuUBSk7V27aHaWmtvttYusdYuqayszEF12REJeBiOAQAAAAAoaOMJIRolzRh2XJc5N2YbY4xHUrGkloPce5qkDxpjtio9vONsY8xvD6P+SYMQAgAAAABQ6MYTQjwvaZ4xZrYxxqf0RJMrR7VZKelTmf2PSlplrbWZ85dmVs+YLWmepNXW2uustXXW2lmZ562y1n5yAt4nb6VDCIZjAAAAAAAKl+dQDay1CWPM5yQ9JMkt6TZr7XpjzLckrbHWrpR0q6Q7jTENklqVDhaUabdC0muSEpKutdYms/QueS3i92pf14DTZQAAAAAA4JhDhhCSZK19QNIDo879n2H7/ZI+9hb3flvStw/y7L9L+vt46pjMihiOAQAAAAAocI5MTFmImBMCAAAAAFDoCCFyJBLwqnsgoWTKOl0KAAAAAACOIITIkYg/PfKlJ0ZvCAAAAABAYSKEyJFIIB1CMCQDAAAAAFCoCCFyJBLwShLLdAIAAAAAChYhRI4UZXpCdNMTAgAAAABQoAghcoThGAAAAACAQkcIkSPRTAjRyXAMAAAAAECBIoTIkf1zQtATAgAAAABQmAghcqQos0Rn9wAhBAAAAACgMBFC5EjI55bbZVgdAwAAAABQsAghcsQYoyK/h+EYAAAAAICCRQiRQ0V+D0t0AgAAAAAKFiFEDkUCHnUSQgAAAAAAChQhRA5FA17mhAAAAAAAFCxCiByKBJgTAgAAAABQuAghcqgo4GGJTgAAAABAwSKEyKF0TwiGYwAAAAAAChMhRA5FAl519SdkrXW6FAAAAAAAco4QIoeK/B4lUlYDiZTTpQAAAAAAkHOEEDkUDXgkSZ0MyQAAAAAAFCBCiByKBLySxAoZAAAAAICCRAiRQ5FMTwhCCAAAAABAISKEyKEifzqE6CaEAAAAAAAUIEKIHNo/HIM5IQAAAAAAhYcQIocYjgEAAAAAKGSEEDk0FEIMEEIAAAAAAAoPIUQODc4JwXAMAAAAAEAhIoTIIY/bpZDPzXAMAAAAAEBBIoTIsUjAQ08IAAAAAEBBIoTIsSK/R93MCQEAAAAAKECEEDkWCXgZjgEAAAAAKEiEEDkWCXjUSQgBAAAAAChAhBA5xpwQAAAAAIBCRQiRYxG/V930hAAAAAAAFCBCiBxL94QghAAAAAAAFB5CiByLBLzqiycVT6acLgUAAAAAgJwihMixooBHktTDMp0AAAAAgAJDCJFjkUwI0dlHCAEAAAAAKCyEEDlWHPRKkjpZIQMAAAAAUGAIIXJsMITo6COEAAAAAAAUFkKIHCOEAAAAAAAUKkKIHCOEAAAAAAAUKkKIHCOEAAAAAAAUKkKIHAv53PK4DCEEAAAAAKDgEELkmDFGxUEvIQQAAAAAoOAQQjiAEAIAAAAAUIgIIRwQDXrV0UsIAQAAAAAoLIQQDqAnBAAAAACgEBFCOIAQAgAAAABQiAghHEAIAQAAAAAoRIQQDigOetXZH1cqZZ0uBQAAAACAnCGEcEBJyCtrpa6BhNOlAAAAAACQM4QQDogGvZKkToZkAAAAAAAKCCGEA4ozIQTzQgAAAAAACsm4QghjzHnGmNeNMQ3GmK+Ncd1vjLk7c/05Y8ysYdeuy5x/3RhzbuZcwBiz2hjzsjFmvTHmmxP1QpMBIQQAAAAAoBAdMoQwxrgl/ULScknHSPq4MeaYUc2uktRmrZ0r6UeSvp+59xhJl0o6VtJ5km7KPG9A0tnW2hMkLZZ0njFm2cS8Uv4jhAAAAAAAFKLx9IRYKqnBWrvZWhuTdJekC0e1uVDS7Zn9eySdY4wxmfN3WWsHrLVbJDVIWmrTujPtvZlPwSwVQQgBAAAAAChE4wkhaiXtGHa8M3NuzDbW2oSkDknlB7vXGOM2xrwkqUnSX621zx3OC0xGhBAAAAAAgELk2MSU1tqktXaxpDpJS40xx43VzhhztTFmjTFmzb59+3JbZJaEfG55XIYQAgAAAABQUMYTQjRKmjHsuC5zbsw2xhiPpGJJLeO511rbLulvSs8ZcQBr7c3W2iXW2iWVlZXjKDf/GWNUHPQSQgAAAAAACsp4QojnJc0zxsw2xviUnmhy5ag2KyV9KrP/UUmrrLU2c/7SzOoZsyXNk7TaGFNpjCmRJGNMUNJ7JW088teZPAghAAAAAACFxnOoBtbahDHmc5IekuSWdJu1dr0x5luS1lhrV0q6VdKdxpgGSa1KBxXKtFsh6TVJCUnXWmuTxpgaSbdnVspwSVphrb0/Gy+Yr6JBrzoJIQAAAAAABeSQIYQkWWsfkPTAqHP/Z9h+v6SPvcW935b07VHnXpF04tstdiopDnrV1htzugwAAAAAAHLGsYkpC11JyKv2XnpCAAAAAAAKByGEQ0pDPnpCAAAAAAAKCiGEQ0pDPnX1JxRPppwuBQAAAACAnCCEcEhZ2CtJDMkAAAAAABQMQgiHlIZ9ksSQDAAAAABAwSCEcEhZKB1CtPYQQgAAAAAACgMhhENKMiFEGyEEAAAAAKBAEEI4pGxoOAZzQgAAAAAACgMhhENKQumJKZkTAgAAAABQKAghHBLwuhXyuZkTAgAAAABQMAghHFQa8jEnBAAAAACgYBBCOKgs7GM4BgAAAACgYBBCOKg07FMrE1MCAAAAAAoEIYSDSkNehmMAAAAAAAoGIYSDmBMCAAAAAFBICCEcVBb2qWsgoXgy5XQpAAAAAABkHSGEg0pDXklickoAAAAAQEEghHBQadgnSWrrYXJKAAAAAMDURwjhoLJQOoRoZV4IAAAAAEABIIRw0GBPiHaGYwAAAAAACgAhhINKB3tCEEIAAAAAAAoAIYSDSgYnpmQ4BgAAAACgABBCOCjgdSvsc6uFEAIAAAAAUAAIIRxWEfGrpZsQAgAAAAAw9RFCOKyiyK99XQNOlwEAAAAAQNYRQjisssiv5m5CCAAAAADA1EcI4bCKiE/7CCEAAAAAAAWAEMJhlUUBtffGFU+mnC4FAAAAAICsIoRwWEXEJ0lMTgkAAAAAmPIIIRxWWeSXJCanBAAAAABMeYQQDquIpEMIJqcEAAAAAEx1hBAOoycEAAAAAKBQEEI4rDLTE4IVMgAAAAAAUx0hhMMCXreK/B56QgAAAAAApjxCiDxQGfEzJwQAAAAAYMojhMgDFUU+ekIAAAAAAKY8Qog8QE8IAAAAAEAhIITIAxVFfnpCAAAAAACmPEKIPFBZ5Fdnf0IDiaTTpQAAAAAAkDWEEHmgIrNMZ0t3zOFKAAAAAADIHkKIPFBZlA4hGJIBAAAAAJjKCCHyQGWmJ0QTIQQAAAAAYAojhMgDNcUBSdKejj6HKwEAAAAAIHsIIfJARZFfXrfRro5+p0sBAAAAACBrCCHygMtlNC0a0O52ekIAAAAAAKYuQog8UVMc0G56QgAAAAAApjBCiDxRUxwkhAAAAAAATGmEEHmipjigPR39stY6XQoAAAAAAFlBCJEnaooDiiVTaumJOV0KAAAAAABZQQiRJ6qLg5KkPQzJAAAAAABMUYQQeWJ6SUCStIsVMgAAAAAAUxQhRJ6oyfSEYHJKAAAAAMBURQiRJ8rDPnndhhACAAAAADBlEULkCZfLqLo4oN0dDMcAAAAAAExNhBB5pCYapCcEAAAAAGDKGlcIYYw5zxjzujGmwRjztTGu+40xd2euP2eMmTXs2nWZ868bY87NnJthjPmbMeY1Y8x6Y8wXJuqFJrOaEnpCAAAAAACmrkOGEMYYt6RfSFou6RhJHzfGHDOq2VWS2qy1cyX9SNL3M/ceI+lSScdKOk/STZnnJST9s7X2GEnLJF07xjMLTk1xUHs6+pVKWadLAQAAAABgwo2nJ8RSSQ3W2s3W2pikuyRdOKrNhZJuz+zfI+kcY4zJnL/LWjtgrd0iqUHSUmvtbmvtC5Jkre2StEFS7ZG/zuRWXxZSPGm1p5MhGQAAAACAqcczjja1knYMO94p6ZS3amOtTRhjOiSVZ84/O+reEWFDZujGiZKeext1T0kzy0OSpK0tPZpeEnS4mvzVM5BQY3uf9nT0a09nv5o609vWnpi6+hPqGUioZyCp7oGE+uNJDe9X4nO7FPK7FfK5FQ14VRnxq7LIr6qoX/VlYc2pDKu+LKSA1+3Y+wEAAADAVDWeECJrjDFFkv4g6YvW2s63aHO1pKslqb6+PofV5d5gCLGtpVenHuVwMXmgqbNf63d1qqGpW5ube7SluVtbmnu0t3PggLYlIa/Kwz4VBbyK+D2qjPgV9nsU9LrlMkaSZGUVS6TUE0uqL5ZUR19cL25vV1NXv/rjqaFnGSPNKg/r+LpiHV9XosUzirWotkQ+D/O4AgAAAMCRGE8I0ShpxrDjusy5sdrsNMZ4JBVLajnYvcYYr9IBxH9aa//4Vl9urb1Z0s2StGTJkik9WUJNcVA+t0tbW3qcLiXn2ntjWr2lVa82dmhdY4fW7erUvq79YUNZ2KfZFWGdPq9SsyvCmlEWUnU0oOpoQFVR/xH1XLDWqmsgoW3Nvdrc3K3N+3q0YXenntvcqvte2iVJCvncWjanXKfNrdBZ8yt1VGXREb8zAAAAABSa8YQQz0uaZ4yZrXSAcKmky0a1WSnpU5KekfRRSaustdYYs1LS74wxP5Q0XdI8Sasz80XcKmmDtfaHE/Mqk5/bZTSjLKhtzb1Ol5J17b0xPbelVc9ubtGzm1u1cU+nrE3/DOZVFemMeZU6dnpUx9UWa/60iIpD3qzVYoxRNODVorpiLaorHnFtb2e/XtzepqcaWvRUQ7NWbWzSv94vHT2tSOcdV6P3L6rR/OpI1moDAAAAgKnkkCFEZo6Hz0l6SJJb0m3W2vXGmG9JWmOtXal0oHCnMaZBUqvSQYUy7VZIek3pFTGutdYmjTHvknS5pFeNMS9lvurr1toHJvoFJ5tZ5eEp2xNie0uvHn5tjx5+ba/WbG1Vykp+j0tLZpXqy+85WqfMKdfxdcV5NR/DtGhA5x1Xo/OOq5Ek7Wzr1SOv7dUD6/boZ6ve0E8ffUOLaot18ZI6ffCE2qyGJQAAAAAw2RlrJ88IhyVLltg1a9Y4XUZWfevPr+mu57dr/TfPlcnMZTCZdfTGtfLlRt2zdqde3tkhSVpQHdH7jpmmd82r1AkziuX35E/o8Hbs6xrQ/a/s0oo1O7Vhd6f8Hpc+cMJ0/cNps3Ts9OJDPwAAAAAApghjzFpr7ZJDtXN0YkocaGZ5SL2xpPZ1D6gqEnC6nMP20o523frkFj20bo9iyZQWVEf0L+cv1LnHVqs+MwHnZFcZ8esfTputfzhtttY1duiu57frjy+kA5dlc8p01bvm6D0Lq6ZEmAQAAAAAE4EQIs8MXyFjsoUQqZTVqo1NuvmJzVq9pVWRgEeXnVKvj55Up2OnR6f0L+PH1Rbr/69dpK+8b4HuXrNdtz+9TZ+5Y42OqYnqi++Zp/ceM21Kvz8AAAAAjAchRJ6ZVR6WJG1t7tHJs8ocrmb8nm5o1nce3KB1jZ2qLQnqf79/oS5dWq8if2H9ESsOeXX1GUfp06fN1sqXd+mnj76hq+9cSxgBAAAAACKEyDu1pUG5XUbbWibHChkb93Tqew9u1N9f36fakqB+8LETdOHi6fK6XU6X5iiP26WL3lGnD54wXfe9tEs/W5UOI46dHtXXz1+o0+ZWOF0iAAAAAOQcIUSe8bpdqisN5v0KGf3xpH766Bv65eObFfa59fXzF+iKd87Kq5Ut8oHH7dJHTqrThYvTYcSPHtmkT/zqOb1nYZW+fv5CzakscrpEAAAAAMgZQog8dFRlkd7Y2+10GW/p+a2t+v/ueUWbm3v0sZPq9C/vX6iSkM/psvLaYBjx/uNr9OuntuoXf2vQ+370uC5/50x94Zx5/PwAAAAAFITC7jOfpxbWRPTmvm4NJJJOlzJCIpnS//3LRn3sP55RLJnSnVct1b997AR+gX4bAl63/umso/S3/3WWLj55hm5/eqvO/Le/685ntymZmjzL5QIAAADA4SCEyEMLqqNKpKwamvKnN8Tezn5d9qvndNPf39THl87QQ188Q6fPq3S6rEmrMuLXdz68SA984XQdUxPV9X9ap4v+/Wmta+xwujQAAAAAyBpCiDy0sCYqSdqwu8vhStKebmjW+T95Qq/u7NCPLjlB373oeIULbNWLbFlQHdXvPnOKfnzJYjW29eqDP39SN6xcr87+uNOlAQAAAMCEI4TIQ7MrwvJ7XNqwu9PpUrTi+R264rbVKgv7tPJzp+nDJ9Y5XdKUY4zRh06s1aP/fJY+ccpM3f7MVr3nxsf04Ku7nS4NAAAAACYUIUQecruM5ldHtHGPcyGEtVY3Pvy6vvqHV/TOo8r1x2tO1bxpEcfqKQTFQa/+9UPH6U/XnKbKiF//9J8v6B/vXKumrn6nSwMAAACACUEIkacWVke1YXeXrM39ZIWxREpfXvGyfraqQZeePEO3XXmyIgFvzusoVCfMKNF9156mr543X6teb9J7f/i47lm705E/CwAAAAAwkQgh8tTCmohae2Jq6hrI6fcOJJK65j9f0L0vNuor587Xdy9aJK+bPya55nG7dM1Zc/XA50/XvKoi/a//ellX/vp5Nbb3OV0aAAAAABw2frvMUwuGJqfM3ZCM/nhSn71zrR7ZsFf/euGxuvbdc2WMydn340Bzq4q04rPv1A0fOEbPb23V+374mO58ZqtSLOcJAAAAYBIihMhTC2uiMkZ6ZWdulmzsiyX1mTvW6LFN+/S9ixbp8nfOysn34tBcLqMrT5uth754hk6sL9X1963XpTc/q8378mcJVwAAAAAYD0KIPFUc9Gr+tIie29KS9e+KJVK6+s41erKhWf/20RN06dL6rH8n3r4ZZSHdedVS/d+PHK8Nezq1/CdP6JePvakkvSIAAAAATBKEEHls2Zxyrd3WplgilbXvSKWs/vm/XtYTbzTr+xcdr4+exBKc+cwYo4tPnqFHvnymTp9Xqe8+uFEX/fvT2rS3y+nSAAAAAOCQCCHy2LI5ZeqPp/RqY3tWnm+t1Tf/vF5/fnmXvrZ8gS4+eUZWvgcTb1o0oFuuOEk/uXSxtrf06IKfPqmfr3pD8WT2AisAAAAAOFKEEHls6exySdKzm1uz8vyfrWrQ7c9s02dOn63PnjEnK9+B7DHG6MLFtfrrl8/Ue4+dph88vEkX/vwprd+Vm3lEAAAAAODtIoTIY2Vhn+ZPi+jZzRM/L8Rvn92mH/51ky56R62uW76QVTAmsYoiv35x2Tv0H598h5q6BnThz5/SDx9+XV017ZQAACAASURBVAOJpNOlAQAAAMAIhBB57pQ5ZVq7rW1Cu9k/8OpuXX/fOp29oErf/8jxcrkIIKaC846r0V+/dIY+eMJ0/XRVgz7wsyf18o7sDOUBAAAAgMNBCJHnTj2qQr2x5IT1hniqoVlfvOslnVRfql9c9g553fwRmEpKwz798JLFuu3KJersS+jDNz2l7z64Qf1xekUAAAAAcB6/gea5s+ZXKuL36L6Xdh3xs17d2aGr71ij2RVh3fqpkxX0uSegQuSjsxdM08NfPkOXnDxDv3xss87/6RNaszU7c4sAAAAAwHgRQuS5gNet846r1l/W7Tmif83evK9bV/56tUpCPt1x1VIVh7wTWCXyUTTg1XcvOl6/veoUDcRT+tgvn9E3/7xevbGE06UBAAAAKFCEEJPAh06sVfdAQo9uaDqs+3e19+mK21ZLku68aqmmRQMTWR7y3LvmVejhL52hK5bN1K+f2qrzfvyEnn6z2emyAAAAABQgQohJYNmcclVF/Lr3xca3fe/ujj59/JZn1dEb12/+YanmVBZloULku7Dfo29eeJzuvnqZXEa67Jbn9LU/vKL23pjTpQEAAAAoIIQQk4DbZfSxJXV6dONevbarc9z37eno12W3PKeW7pjuuGqpFtUVZ7FKTAanzCnXg184Q1efMUf/tXanzrnxMf3xhZ2y1jpdGgAAAIACQAgxSVx9xlEqDnr1vb9sHFf7vZ39uuyWZ7Wva0C3f3qpTqwvzXKFmCyCPre+fv5C3f8/36X68pC+vOJlXXbLc3pzX7fTpQEAAACY4gghJonioFefe/dcPb5pnx7btO+gbTfs7tRFNz2tvZ39uv3TJ+ukmQQQONDCmqj+8I+n6tsfPk7rd3Vo+Y+f0A//uonlPAEAAABkDSHEJHL5O2dqTkVYn//9i9qw+8BhGdZarVizQx/596eVTFnddfU7ddLMMgcqxWThchl94pSZevSfz9LyRdX66aNv6LwfP66/v354k6ACAAAAwMGYyTQWfMmSJXbNmjVOl+GoHa29+th/PKN4MqXrzl+oC46vkSQ9+Uazbn1yi57Z3KKls8r0s8tOZBUMvG1PvtGs6+9bpy3NPXrPwir97/cfo1kVYafLAgAAAJDnjDFrrbVLDtmOEGLy2byvW//02xf0+t6uEecrI359/px5+sTSerlcxqHqMNnFEin9+qkt+umjbyietLrq9Nn63LvnKuz3OF0aAAAAgDxFCDHFWWv1VEOLVm9pkd/r1vxpEZ01v1IeNyNsMDGaOvv1vb9s1B9faNS0qF/XLV+oCxdPlzEEXAAAAABGIoQAMCHWbmvTDSvX69XGDi2ZWap/ef9CVlsBAAAAMMJ4Qwj+2RzAQZ00s1T3XXuavv+RRdra0qMP3/S0rv3dC9rW0uN0aQAAAAAmGXpCABi37oGEbn58s255fLMSqZQ+uWymPn/2PJWGfU6XBgAAAMBBDMcAkDV7O/v1o79u0oo1OxT2e3Ttu+fqylNnKeB1O10aAAAAAAcQQgDIuk17u/S9Bzdq1cYmTS8O6PPnzNNHTqqTlwlSAQAAgILCnBAAsu7oaRHdduXJ+t1nTlFVNKCv/fFVnXPjY/rjCzuVTE2egBMAAABAbhBCADhipx5VoXuvOVW3fmqJivwefXnFy3rfjx7T/a/sUoowAgAAAEAGIQSACWGM0TkLp+n+//ku/fsn3iG3y+hzv3tR5//0CT28fg9hBAAAAADmhACQHcmU1f2v7NKPH3lDW5p7tKA6omvePVfvX1Qjt8s4XR4AAACACcTElADyQiKZ0v2v7NbP/9aghqZuza4I65/OPEofOrFWPg+dsQAAAICpgBACQF5Jpawefm2PfraqQet3daq2JKjPnjlHFy+ZwdKeAAAAwCRHCAEgL1lr9fdN+/SLVQ1as61NFUU+Xb5slj65rF7lRX6nywMAAABwGAghAOQ1a62e29Kqmx/frFUbm+T3uPSRk+p01btm66jKIqfLAwAAAPA2jDeE8OSiGAAYzRijZXPKtWxOuRqauvSrJ7bonrU79bvntus9C6v0P06fo1Nml8kYJrEEAAAApgp6QgDIG/u6BnTns9v022e3qbUnpkW1xfofp8/W+Ytq5HUziSUAAACQrxiOAWDS6o8n9YcXdurWJ7Zoc3OPqiJ+XXZKvS5bWq+qaMDp8gAAAACMQggBYNJLpaz+9nqT7nhmmx7btE8el9G5x1XrimUztZShGgAAAEDeYE4IAJOey2V0zsJpOmfhNG1t7tFvn92mFWt26L9f2a0F1RF9ctlMffjEWoX9/E8ZAAAAMBnQEwLApNIXS+q+lxp1xzPb9NruTkX8Hn3kpDpdunSGFlRHnS4PAAAAKEgMxwAwpVlr9cL2Nt3xzDY9+OoexZIpnTCjRJeePEMfOGG6iugdAQAAAOQMIQSAgtHWE9O9Lzbqrue3a9PeboV8bl1wfI0uOble76gvYe4IAAAAIMsIIQAUHGutXtrRrruf36GVL+9SbyypeVVFuuTkGfrQibWqKPI7XSIAAAAwJRFCACho3QMJ/fcru3TX8zv04vZ2uV1GZ8yr0IffUaf3LpymoM/tdIkAAADAlDGhIYQx5jxJP5HklvQra+33Rl33S7pD0kmSWiRdYq3dmrl2naSrJCUlfd5a+1Dm/G2SLpDUZK09bjwvRQgB4HBs2tule19s1H0vNmpXR7+K/B6dd1y1PnxirZbNKZfbxXANAAAA4EhMWAhhjHFL2iTpvZJ2Snpe0setta8Na3ONpOOttf9ojLlU0oettZcYY46R9HtJSyVNl/SIpKOttUljzBmSuiXdQQgBIBdSKatnt7ToTy826sFX96hrIKHqaEAXLp6uD51YqwXVEeaPAAAAAA7DRIYQ75R0g7X23MzxdZJkrf3usDYPZdo8Y4zxSNojqVLS14a3Hd4uczxL0v2EEAByrT+e1CMb9ureFxr12KZ9SqSs5lSG9f5FNVp+XI0W1hBIAAAAAOM13hBiPGvY1UraMex4p6RT3qqNtTZhjOmQVJ45/+yoe2vH8Z0AkFUBr1sXHD9dFxw/XS3dA3pg3R49+Opu/eJvDfrZqgbNKg/p/EU1On9RjY6dHiWQAAAAACbAeEIIRxljrpZ0tSTV19c7XA2Aqai8yK/Ll83U5ctmqqV7QA+t36sH1+3WLx/frJv+/qbqy0Javqha5x5brcV1JXIxhwQAAABwWMYTQjRKmjHsuC5zbqw2OzPDMYqVnqByPPcelLX2Zkk3S+nhGG/nXgB4u8qL/LrslHpddkq9Wnti+utre/TAq3t06xNb9MvHNquiyKez5lfpnAVVete8CkUCXqdLBgAAACaN8YQQz0uaZ4yZrXSAcKmky0a1WSnpU5KekfRRSaustdYYs1LS74wxP1R6Ysp5klZPVPEAkE1lYZ8uOblel5xcr47euP6+qUmPbmjSw+v36J61O+V1Gy2bU66zF1TpzKMrNbsizLANAAAA4CAOGUJk5nj4nKSHlF6i8zZr7XpjzLckrbHWrpR0q6Q7jTENklqVDiqUabdC0muSEpKutdYmJckY83tJZ0mqMMbslPQNa+2tE/6GADABikNeXbi4VhcurlUimdKabW1atbFJj27Yq2/+Ob1YUG1JUKfNLddpcyt02twKVRT5Ha4aAAAAyC+HXB0jn7A6BoB8tK2lR0+80awn32jW0282q7M/IUlaWBPV6fMqdMrsMp00s1QlIZ/DlQIAAADZMWFLdOYTQggA+S6ZslrX2KEnG9KhxNptbYolU5Kk+dMiWjKrVEtnl2nJrDLVlgQdrhYAAACYGIQQAJAH+uNJvbSjXWu2tmr11ja9sK1N3QPpnhLTiwNaXF+i4+tKdHxdsRbVFjPRJQAAACal8YYQeb9EJwBMZgGvW8vmlGvZnHJJ6Z4SG3Z3as3WVj2/rU2v7GzXA6/ukSQZI82pCA+FEguqo1pQHVFpmGEcAAAAmBroCQEADmvtiemVne16ZWdH5tOupq6BoevTon7Nr45qYXVE8zOfuVVF8nvcDlYNAAAA7EdPCACYJMrCPp01v0pnza8aOre3s18b93Tp9T2d2rinSxt3d+nXb7YMzS/hdhnNLA9pTkWR5lSGNacirNkVYc2pLFJFkY+lQgEAAJCXCCEAIA9NiwY0LRrQmUdXDp1LJFPa2tKjDbu79PqeLjU0dWtzc7cef2OfYonUULtIwDMUStSXhzWjNKj6spBmlIU0LRqQ20VAAQAAAGcQQgDAJOFxuzS3KqK5VRF94IT955Mpq13tfXpzX7e2NPdo874ebWnu0eotrbrv5V0aPurO53aptjSoGWWhEeFEfVlIM0pDKg4xMSYAAACyhxACACY5t8ukQ4WykM6aP/LaQCKpXe392tHaq+2tvdrR1qudrX3a3tqrV3a2q703PqJ9xO9RbWlQdaUh1ZUGh33Sx8VBL0M9AAAAcNgIIQBgCvN73JqdGZoxls7+uHa09mY+fdrZ1qvG9vT2mTeb1RNLjmhf5PeotuTAcGIwuCgNEVIAAADgrRFCAEABiwa8OnZ6sY6dXnzANWutOvri2tnWl/n0jthfvaVVXQOJEfeEfO6hcGJ/WLG/V0VZmEkzAQAAChkhBABgTMYYlYR8Kgn5dFztgSGFpExIsT+caBwWVqzZ2qrO/pEhRcDrGhFK1JaERvSqYGUPAACAqY0QAgBw2IqDXhUHx+5JIaWHezSO6knR2Nanne29emnHgXNS+D2uMeakSPeqmFEaVEWRXy5W9wAAAJi0CCEAAFkTDXgVrfFqYU10zOtd/XE1tvcdEFTsbOvTusYOtfbERrT3eVyqKxmcgyJ4QK+KqgghBQAAQD4jhAAAOCYS8GpBtVcLqscOKXoGEkMTZe4f7pE+fnhXp1pGhxRul6aXBPZPmFkSVF1ZOqyYWRZSZcTPcA8AAAAHEUIAAPJW2O/R0dMiOnpaZMzrvbGEdrX3acewcGIwqHhkQ5OauwdGtA/53KovC2lWeVgzKzLb8vS2OhqgFwUAAECWEUIAACatkM+juVURza0aO6ToiyXV2N6nHW292t7Sq20tvdrW0qM3mrq0amOTYsnUUFufx6WZZSHNLA9rVnlIMysy27KwppcE5HG7cvVaAAAAUxYhBABgygr63JpbVaS5VUUHXEumrHZ39GlbS6+2tvSkt83p7ZMN+9Qf3x9QeFxGM8pCQ70mhm/rSkPyeQgoAAAAxoMQAgBQkNwuk5k7IqTT5laMuGatVVPXwFAoMRRStPRozdY2dQ/sX3rUZaTa0uCocCKs2RUhzSgLye9x5/rVAAAA8hYhBAAAoxhjNC0a0LRoQKfMKR9xzVqrlp6Ytg0FE+khHltbevXnl3eroy8+7DnS9OKgZmXmn5hVHtaszDCPGWUhBbwEFAAAoLAQQgAA8DYYY1RR5FdFkV8nzSw74Hp7b0xbM0M7trb0ZLa9+u9Xd6u9d+yAYmZ5WLMzPSlmV4QJKAAAwJRFCAEAwAQqCfm0OOTT4hklB1wbDCi2tfRoS2aox5bmHj346m61jQooaqIBzarYP7QjvQ2rnoACAABMYoQQAADkyMECio7eeLrnREuPtjb3Du3/Zd3YAcXMYUM70tt0TwoCCgAAkM8IIQAAyAPFIa9OCJXohHEEFNtaerSlpUcPrd+j1p7YiLY1xYHM3BPDJ8lM96AI+ggoAACAswghAADIcwcNKPriI4Z3DM5F8dD6vQcEFNXRwP5JMof1ophZFiagAAAAOUEIAQDAJFYc9Or4uhIdX/fWAcXwiTK3tfTqr6/tVcsYAcXgxJjD56GYVU5AAQAAJg4hBAAAU9TBAorO/ri2Dc49kVnBY2tLjx7ZsFfN3SMDimlR/wFLjKYnzQwp5OOvEgAAYPz4mwMAAAUoGvBqUV2xFtUVH3Ctsz+u7ZmVO9JDPdLzUDy68cCAoiriP2CCzMFJMsN+/poBAABG4m8HAABghGjAq+Nqi3Vc7YEBRVd/PD33xPAeFM09WrVxn5q7d45oWxXxD02SOThB5szy9H4RAQUAAAWJvwEAAIBxi4wzoNg2rCfFWAFFacirGWUhzSgNqa4sqBmlocxxULWlQfk9zEMBAMBURAgBAAAmxMECiu6BxNDkmNtbe7WjtU8723q1fleHHn5tj+JJO9TWGGlaJKAZmXCiLhNOzChLBxXV0YDcLpPLVwMAABOEEAIAAGRdkd/zlgFFMmW1t7NfO9v6tKO1Vzva0iHFjrZePbu5RbtfapTdn1HI6zaaXpIJKDLhxNC2JKiKIr9chBQAAOQlQggAAOAotysdKkwvCWrp7LIDrscSKe1q7xsRTqTDir4xV/Pwuo1qioOaXhLQ9JKgajPPTu+nz7GqBwAAzuD/gQEAQF7zeVzplTcqwmNe740lhnpR7Oro1672Pu1q71NjW5+efbNFezr7lbIj7ykJeTW9OD3/RDqkCAwLKoKqpDcFAABZQQgBAAAmtZDPo6OnRXT0tMiY1xPJlPZ2DewPJzLbXe392tHaq2ffbFHXQGLEPV63UXVxQDXRoKYVB1Qd9WtaNKCa4qCqi9P7VZGAfB5XLl4RAIApgxACAABMaR63S7WZHg5vpbM/Piyk6B/qSbGno18v72jXQ539iiVSB9xXUeTTtGhA1dFAJqw4cD8a9MgYelUAACARQgAAACga8Cpa7dWC6uiY1621au+Na09nv/Z09mtvR2bb2a89Hf3a1dGvF3e0q7UndsC9Qa9b1cUBVUb86U+RX1XR9HboXMSv8rCfVT8AAFMeIQQAAMAhGGNUGvapNOzTwpqxgwpJGkgk1dQ5kA4rOtIhxe5MYLGva0AbdnXq8a6BA4Z/SJLLSGVh/4iwYnhIMfw4GqB3BQBgciKEAAAAmCB+j1szykKaURY6aLu+WFLN3QNq6hrQvq4B7evObIcdv9nUrX1dA4olDxwG4nO7VBr2qizsV3nYp7LMpzzsU1lRZhv2D50rDnqZaBMAkBcIIQAAAHIs6BtfWGGtVUdffEQ4sa9rQM3dMbX2DKi1J6aWnph2tPWqtTs2Zg8LKb0MamnIuz+sKNofXpSGfCoJeVUc9Kok5FNJ0KvSkE+RgIfgAgAw4QghAAAA8pQxJh0MhHya9xarfww3kEiqrSeulkxA0doTU0t3bOi4pTt9bsOuTrX0xNTRFz/IdysdTAS9Kh4KJ9JBRTqwyHyC+0OMaNCrSMAjv8c9kT8GAMAUQggBAAAwRfg9blUXpyfCHI9EMqWOvrja++Jq742roy+m9t642nrj6uiNDZ1Pb2Pa0tyj9t6YOvvH7nGxvw6XIgGvokFPehvwKBpIBxTRoFcRv2f/fuZ6ZNR1emEAwNRECAEAAFCgPG5XemhGkf9t3ZdMWXX27Q8n0kFFTF39CXX2xdPb/rg6+xND53a192WO4+qPHzjPxWgRv0dFAY/Cfo/CPnd6O2y/yO9RyOdR2O9W0eA1v1thn2d/28y1oNfNRJ4AkCcIIQAAAPC2uF37VwuRwm/7/lgipa7+/WHF2OFF+rg3llD3QFI9Awm19vSqJ5ZQT+Z4IHHoMENKDy0J+0aGFEGvWwGfWyGvW0GfWwGvW0GvW0GfK7P1jDgevB7yeRT0uYa1dyvgcdNzAwDGiRACAAAAOeXzHF4PjNHiyZR6B5LqjiXUO5BQ90AmoIgl1DOQ+cTSgUX3QGKobc9AQv3xpDr64trb0a/eeEJ9sZT640n1xhJK2bdfi9/jUsjnHgos/F63/B5X+uN1y+d2ye/NHHsy17zD9jPthvY97vR19+h27qHn+Dwued0ueVyGnh4AJg1CCAAAAExKXrdLxSGXikPeCXumtVbxpFVfPKm+WHLEtn+Mc4P7/cP2e+NJxRIpDSRSGogn1dkXT+8nkhqIp/bvJ1KKjbM3x6H43C553UbeTDAxdOx2ZT7D9j0u+UZcc8nnGXXsNvIMu3cw8Bj+LLfLyOs2crvSQYjHZeQZfuzOnHOl26aP09fcbiPv4HmXoScJUEAIIQAAAIAMY4x8nvQv3cXBiQs33oq1VrHkYGCxP5wYsZ8JMwb3Y8NCjHgipXjKKp7M7CdTiiUzx5lPLDHyuLcvqcTQsVUskRp2PV3PRIUj4+UyGhVWpMOMdMgxGHBkAoxR+163kcuk990mHWi4M8fpfY1xLrNvjNwujXFu1PUDzg37rmHXXWb4/Rqj7cj7jUkPFxq8z2XSfwb3n0tvpXSNg8fGSEb7j13GyLgko2HHw9oOfzbgNEIIAAAAwCHGmMxQC7c0vkVNcsJaq2TKDoUS8WRKiUy4Mfw4mbJKpPbvx1NWycxxIpX+JFPpcCOZOU4kUyP2021sps3Yx6O/a3+bdGCTSFmlMjUnh+2nrMY4N7xd5rq1SmW29jCG40wmg2HEiK1GBhwulxkKNIwZHX6MDDMGd4e2MqOOB6+boX2NcW3k8YHP0UHavtU9+79v5D2SNOI/c+Y/uh15mDlnDzxnD3yGHeMPzv52doxzB947/Ny915yWkyDUCYQQAAAAAEYwJtMjwS0F5Xa6nJwaDGDSwYSUHAwvRoUV6XPDrg8LN6w98PyI+zLPTlmbmYMkvR08tpkwZPA4Za006tja9K+2qdTwc+lfeIcfp1KZdsOePXRtjOPBZ6eGPcsOq9dqjF+uR/1iPfqX6kz5Y17TqGdZe+DzR//ibkfdfLDnH3ivPSDIkMYOTYaujWoz/Ozwc2O1GytMGR3YDL958IxnCg9RIoQAAAAAgIyhAMbpQoApyuV0AQAAAAAAoDAQQgAAAAAAgJwghAAAAAAAADlBCAEAAAAAAHKCEAIAAAAAAOQEIQQAAAAAAMiJcYUQxpjzjDGvG2MajDFfG+O63xhzd+b6c/+vvXOPu7Iq8/53yUlExAMiKCAonu1goaMdjHRG82weRhzPaCVmvWrmpM2rjmXlTOUhT6WVh0wjLNPU0LSsKRVFM1FAAUFOipxBUHhgzR+/az33tddzb6CZ3ucFWb/P5/k8e+/7un/3ta71W2tda93r3juEMMAdu9g+nxBCOHhtOQsKCgoKCgoKCgoKCgoKCt5bWOMiRAihA3ADcAiwO3BiCGH3zOxMYH6McRBwNXCVnbs7MBTYA/gUcGMIocNachYUFBQUFBQUFBQUFBQUFLyHsDY7IfYBJsYYJ8cYlwP3AEdlNkcBt9vrkcCBIYRgn98TY3w3xvgaMNH41oazoKCgoKCgoKCgoKCgoKDgPYS1WYTYDpjm3k+3z2ptYowtwEJgq9WcuzacBQUFBQUFBQUFBQUFBQUF7yGs819MGUL4bAjh2RDCs2+99db/b3cKCgoKCgoKCgoKCgoKCgr+h1ibRYgZQD/3vq99VmsTQugI9ADmrubcteEEIMb4gxjj4Bjj4K233not3C0oKCgoKCgoKCgoKCgoKFgXsTaLEM8AO4UQBoYQOqMvmrw/s7kfOM1eHwc8HmOM9vlQ+/WMgcBOwOi15CwoKCgoKCgoKCgoKCgoKHgPoeOaDGKMLSGEc4FRQAfgRzHGl0IIVwDPxhjvB34I3BlCmAjMQ4sKmN0I4GWgBfh8jHElQB3nmnwZM2bMnBDCVKAnMGcN5muy+XtwtNd1NjRfN7Tyttd11hWO9rrOhuZrKe+6e50NzdcNrbztdZ11haO9rrOh+bqhlbe9rrOucLTXddYVjva6zobm6/pQ3u3XcJ4QY1zv/tDix//K5u/B0V7X2dB83dDKuz75uqGVd33ytZR33b3Ohubrhlbe9cnXDa2865OvG1p51ydfS3nX3etsaL6uT+Vd0986/8WUBQUFBQUFBQUFBQUFBQUF7w2URYiCgoKCgoKCgoKCgoKCgoJ2wfq6CPGDv4PN34Ojva6zofm6oZW3va6zrnC013U2NF9Ledfd62xovm5o5W2v66wrHO11nQ3N1w2tvO11nXWFo72us65wtNd1NjRf16fyrhbBnukoKCgoKCgoKCgoKCgoKCgo+H+K9XUnREFBQUFBQUFBQUFBQUFBwXqGNf5E57qEEMJ/AkcAy4FJwBkxxgUhhAHAOGACsC3QCZjmbez8i4EvAluazT4xxmftmOfoYX+bexvHcSaw0rj2Az4DvGUml8QYHzLbTwHXop8hvTXG+K2sPFOAxcbVEmMcHEL4EXA4MDvGuKfZbQn8DBgATAHeBA7KbC53fnRCP4naCYjAD2KM12Y8s4AAbJXZJJ45wCC71jJgZIzxshDCQOAeO+954+qMtJRsbgM+ASy0og5DP+M6I8Z4eMYxBjjFYvCss8k5egFzs1j58vQFJgMr3HEfE4ArgROAPa3Mw1B9J47pwCJgF3f8YMfRxcq62Ph2AC4F7jCOnaxMU8zPdHzzzI/RwEftGi8CZwB9XEwW27VWueM3Z/F4BDjU6vCWGOM1NTp5DDg5s3keeD9qQxOAS4Cn3HmbWBnfBN6H9Hs4sDUw385J+nsbtaXXUHvphn6u5wHULmbHGPesa3fAOcY7H+hP27a7mfG96TguMv9mAC/Y9Q/KOHo7jtlIMwfa68ctZt0tjkutXF2AN4BzgV9ZebDPDgZ+CvxTxrEUOB34JPBt1F7edBzLrLxz7fPZwAft/12oD9ncrjMd6If6iekWl9QX9bQ4zESa6p1xrAR+a2Vc6Wx8TLa3z6cDOwIbAxNcXC+xmM0wH7qbvefoav7OQm1tI/MpaeRopN3pSL8zgX1p1MjGVpYFSC9ds/odbvXxBjDW6vtGu96OxjkH9Tt9Uf/Uw+KxEm0L3JFGvU6h6ue6WmxSH5/0+hzSVTSOTWjU6xHAhcA2qJ8bgH522ut1pvGl/nQysJtxvA0ssWulPmyklW+h+fI28JLxb2Ecc4DtqPS6AvUTc+z148CptNXrn+y6niPXa7LxMeltZZ+G6n2+1WWKyZfNl9eBd6jGGB8TrKy9zddlSP+J40zjWG4+dTV7z5H0+ibqQwMayxOH12tnpMtpGYfXa7B4pTpOMVllXFVS5wAAIABJREFU5eiA2t8c8zfFdZZ9vgT4K+onetJYvx2tHKuMczpqG48Cn7O62d5i9QjVeNnJztnY+KPFxY+pPa0Mr9rrzkjXz5vPHZGOtgBORH1mZ9Q2fmn+bmb1MN7qdJXFtRfSrOc4w/yajvSxu/F5jn4Wy7esvDOsvL9E498h5tvrqA/rb5y+LADXo3FomNVXlywmc9FY/WXgbNQfdLTzP2rX6GZlmW/vV5rNEtQOt7T6TLnMdKuHZ4BPW930tnPmIM0syDiWmv3Hzbdk42MyCLWT2UgTy+xaKa6fsTK/bnXc1V57jk2RPt9Cmp9u10tx/ZjFb6qVd1Pj9HHd1GK4hPr6PdZiMgPV75lId+OR5l6iqu93UG52GvAkaguLgX+g+km+p6lyt8kWy3E0ajX1w8/adSfTqNWtY4xzQggdMj+SVt9A+dLn7P2zVt6VVj8Lrbyj0fjxlPm+O6rrTczmv1D/t8zK1cvqdjMrSwvwCtLjE6jPSPrGbPaNMW5qvnqOpNULgGHOxsekv/mc+FpzYrM7Hen+NfPxdJT7+ZhgZeljXDebXeJIuc075tdNwA0ZR9Jq6gNGo/4pceRaHY104zmSVmdb7E83v31MVpiPLWYzDOWYKa4L0fg5H+UvSYu+fgMaJ1Ya9yfM967my1jU7rvauQ1zAODPtM1dd7Frew6fC7yBm2cA99I2dx1pfnQAdkVjQz7v/LBdZ6XxvkOVC8xHecoU83Uj1MZ9LvAc6ksWGEcfu6bPXXcxjnepxvE8F5jm/EgceS6QbHxMUi4wGbWlmeZLionPBRZj895sHg3wVIzxbFaH/81Pa7T3H5pwdLTXVwFX2esBwNg12OyOJi7vBw5ADX0fx+05drMK/j0w2Nkkji7AQCS2fwcurPG1gx3fAXW2LwC7ZzZTgJ7ZZ/sDH0q+2Gf/AXzFXn8FTUBym8uTH0hsH7LX3VHnunvGcyVwW43N5SjhDsCmdrwTGnD2BUYAQ+3zm4HzamxuA45zvl2AJnK/tvc5x/Aam5yjLla+PPOB67LjrTGx97cDZ9nrlLx6jjHAw9nxBo6sft9AHXheP1dlx33dbIc6iq4uFqenmNjxRcAXs+Ot8UCLKGNRJ9ERdeKDMj+uRglNbvNjO9ZMXzfbtcaiQe1hO36D1a/X32uuvnyb+YwdH0uTdkel8wnUt927nB+J4zArwyTz6a4ajs1cub6IFgQ+hPTzMNL1AcDTZnMtGlTGAkNcefoBo1DSd0QNx75oMjAK1fMBnoO22kvlfZWqD7kGJTcd3PGxVAPBJ63euhjHkTUcJ2KTucymNSaZbu9ByYmPq+/PvouSozyujwCH2OuLULLgNfIIcD7SyKEWm1wjzwCfsNffAm7J/HgWJXOTUFJytXEMQBOVhn4M9XPXofbWHSXuf6BRr76fOwQlRLtT6fXPwEmuH5yCEi6v10Oo+tM90KC/O416vd5dZ7DZfAAl6ZNQu77N+TrZ6tHr9d/QQi4o8XvbrnOAlaWPle1m45gG/D7T63TggBoOr1dv42NyOer78/EjxeRrwDdceepikjS7vdVdr4zjIDQhSBwH5hwuHn2AO9FCrufwev0+cFONH16vJ2E/I5bF5Gnj6wN8AfVdrXGlUa/no4XcvH5foFq8G24x6mSxnkTz8fJcNBHYF03y/lxjcybqW/YF9qJaXN7ejbnjkYb3QhPrd1HSm8buA9HYuC/VonUAfm7+eo5Dze5p4G7nh+fYzD4LwPdQO+yE2vkv0KRuKJpwfBe4NC+Li+GdSHub1sRkqNXhncASV95J5vttVOOhz1WOQMnyvsCDqI3luczLSINnoBsIG5nNgBqOr6FxNLdpjYnTawDuQwtYPq5pvHgaJfCfqYnrK6hPCkhrt2VxfQXlSD9DC/g/yeL6EaTbnY3jm3Ys+fGkHT/e/LjCjl+A2uubTXKzkSgve9Hej0Bj5s9ozN2eBF6z87xWe1Lldk+jsaJBqy5H9H54rd7trvN7NPlNcXra2SRfn0RjsO9bv4u0egFq11Pt8zOAnzmbXxvHX4Drc606Xz1HnVbzmNxGfU6cYnIbcDGWlzSJSate7f2lGccZwENUuU2vnCPLBe618z1HrtVTa/x4BdjNXp9jvucxmQU85GxG+7hiWrXjXoupfjdCfcELzmYO0tMQqpyidg5A89x1YQ2Hz11nUmmyWe46xTgG0Hzema7jc6yUC3Sw48nXASgPynPXxcaRypLnrnOpcg5fHp+7vl7D4XMBb+M5Lqeas0ypiYnPBTo4v1tjsrZ/69XjGDHGR2KMLfb2KbTytbY2RwH3xBj/GmN8HAlqjybXGRdjnFBzKHG8G2N8DZiIEqk67ANMjDFOjjEuR8n/UWtRxj8A82que7u9vh11irmN55gVY3zOXi9GK1PbZTzXo7vVuU3iiDHGJfa2E9WuigNQZ598OaTGphUhhL5o8nirvQ81HCd4m78BvjxLUEOrRQihB5ro/dDKtzxqh8xRwO12fGu0aOSPN8OBwKQY41Ta1s/R2fEcHYGuIYSOaJFgFo0xWQYc5Y7PzM7fDXVES03rTwDHZH68DHSqsZmKJq0e/rx/R3d90ud32P+vo0WZh6nRX9ZmnnfHa9tdnc6ztjuSaqdA4ngwxjgRtbu5diznWOTeph0E81ByfIfp+nFg8xBCH5TAvUNbXI0m2xElEznHU1QLP++gAbApXHm7W1neRYnuXLQYWtfuhwPfMltijPfXcHwa3Z34YGbTBtb2PooSSKjvz05CCwQ5R7TygxKIGY7jDjs+E9XZ9qg/yTl2RosEoMRgiPcD3Q0YYX7MAQ5O/Ri6C9bQj8UYZ6Fk+2jrw1rQ5MLrdQTWzyHtLQG2c3pNO4JSP7gU+FOm197Oj7dR8rxdptfHUP8H2jUzCegVY7zTytMfLYj1tetMREmL1+tKqt1SB6XyJr3a5/PlalyM2vLG9nnSawu6M5NzeL16m9aYJCdqxo+l6M7pSlSnE4H+dTGh0uzUGONzMcbZGcdZKMFJHI/VcCS8gTRyd1Y3Xq9Ho8lDzuH1ugolzg0xobqjDdLbzCyuXq8jUdsBV79UCeQ+aAJzLNVYCM3Hy6Ps+hHpfmdrn96mA0rGY4zx+RjjFFdO7BpboWT/+RjjL81+Gzd2d3QcD1nfFdHkuG/G8ZDpZHOL0dY1HF6vHc3/xPGgHR+Jxr+uqD4aymJ3if8T6RXnq4/JL1DdX+Su18l4GpDlKkdjbYRqEb53lsukHcDDgStijKuMY0oNx8FoMrBNZtMaE+dKd3S39r4srmm82NLi8rMajogmIRFpb6aPqx1/ys7vgSYOPq4rgeUxxleM4yEqLSaO5THGn6P6fQ719YfZsbrc7CG0qHgr2gV2ux2/yPzwuVtqJ2Ra7UOV2/VG42eDVl2O+KDj8FodjXKew6wuptuhq60saSfXh3E5ZNKqlaur1c9hdnia/b8TONBseqI7260cuVadr56jQavOpjUmHllO3BuNn6AFs81DCH3qYoLTqx3/RMYxHE1eU27TuYYj+bAZqsNtaaybXKujazh839oD1Ukek0XARyyu/VBfmeK6MaZVe/8olRYXo0XyrdC4tLGV5VHUlnM0mwM0y13bcMQ1z/fWZs6Yzzs7ZBzvulxgH9Qvbptx5LlrdBx1uWve/yT43JUaDp8L1J2/OqRczecC+/yNHA1YrxYhMgxDokoYGEJ4PoTwRAjh4zU221E1EJAItqYRdRweOcd01BjPDSH8NYTwoxDCFquxzRcsIvBICGFMCOGzzYvKNpZwgxKzbZrYtfHDtsfshVYCa3kyG8/z4xDCi2hl8lGUeC1wjW06sF0I4S/JJsaYOK4MIfwVbW39KkoEQZ1LzrEXajTJBs8RQri6Sax8eVqAATWxPNf8uB01mh9bHd8aQujmOAZaTAZmx2vjila/767xI8XVH/d+fA1NwF5Hiw8L0Q6MBTHGlhjjDLQFfUg6HmN8JIvp4cD+IYStQgiboI63X+bHfwHda2xAWywHufLk/qd2kTScjk9HSY3X334hhBdCCA+HEOo66P9puxuGVqbrOKajOzrN2v8dIYRpaGC71I53zDg6o8WSk6gmMak8r6GFlhYa0coRQjgKJaoLaYv90BbiK0IIEzLdpC17CdsC9wQ9hrWZ+3wgqudbQwgvW7n2ruHYGQ14d2Q2eUw+jhaX3kQr29A2rivQnZxXcw6UlFxncf02GsA8x3koWdseLWRd7OMRQngBte9z7bPjUYLqOV5Cg9x0tLjSz3HsgCZnlwHb5u3N+rBtkGaa6bU30t536/RqHP3QolNCrte+aDvqt1cz1uyKkq7UF6a+fxjwsF1nD6CX1c/UEMKbNOp1kPmSOLxeLzWONHltptdWjtXotTUmxn2+7+tqYnIusDfqi5KmW2OC+pmTQghPJz1mHDsjHe6FtL13zpHrNcb4apO6yfXq/cj1mvTo43qe2T2fbHxcUXt/1nRyPJUeff2+hPKo7YB/RnfUZgN/tNh2Bx6z8vjx8gC0cDUJTbwXUj3OlGyuQ0nzLSGEkSGEdP2N3Ji7kKqfBGmgdwihg9nch7Tzg6T5EEIndFfun5twzAD+BY23dRy/RO1uV7ObjdrJKDv/FpT0vw+4IS8LGu/+kNqw8/UA4DHLIYajicwKs0nlfQk9mnAkGsvHhRCuDiF0NZvT0EJVajebA38IIVxjfdBstONqN7RT56EQwlgr1y41HDui3OOxzKZNXNHixWNo8lkX1+VW9rdzDtQ2R4UQplvdHJ7F9Sz0mOPmaGfkf9TEtXcIIU0Gj0cLCN6PjiGEwUhjJ6BJe5qsbIF2O3RFGgY9AjGfxseGFkQtfi9Ei2F7OY4+1nd4rV5JldttTON404LayDXeD59POK2+32x6oslgwnS0wPt/0GQz5ZApL5mOFqN2RXdxE8c7AJaHpsdPP4XqPnEci/K0LakWrq7JOci0mpWnj+VsQ4CrQtuc2MfkSpQPfBvVa0NM0I2GL4QQnkUa/l7GsSOq1z5oIenWZnFFWl0CfKlJ3SStfr3Gj1yr/Wpichbq+2YAn0c7KlJcDwP6hRAeM50cR6XFVL9zLOYLUd96nL1/BO1+G2K+7GD1A24OgHKwutx1o5wjywVa5xlowboud43G8QCwU6jPXZdS7Q4d5DhSLrAp8GG7zolUuZrPBeYbxwmonSWkXKCb4zic+tw15hw1uUCy8XFtzQXQuPRYTUzqcgFY8zy6AevcIkQI4bc2KOR/RzmbiWgV8CshhLFole51dIflAuDREMLszOZENOgkbAlckPhrOH6KrWYln4zjm+6c/miA2BF1ELOA7/wNxf1YjPFDKLn+fAhh/zWdYCvDdatXN+V+hBA2RVuqzstW2Vp5amw8z0y0xaovWu3atYlPH0w2IYQ9UcK3K0qoVyHhNsOB6DscxmSfJ469UV2NXEOsPoZWUf1xX5a5qBHeFGPcCw2gX3Hnd0T6eCc7XhfXzigJ+nlNLFL9+OOeYz5arR6IBpxuaPADwBrzQejO3bZAtxDCyVk8QMnYI8Bv0Ba3lZkf49CAkNvchHaETKRGr6vRV4OZ/V+GtgZ/AA2I963hvDq0oDuie2HtLoRwhX3ejO8DqCx3NeH4JJrk3UU16c0xGXXcd6EBEnR3aFeUuF3Y7PpBizqXGEeO59BE/AMoyd+I5v3CTUgjF5rNv9nns1DfMhmtqndH/dKIGo6OaKvfxeg5vWTTJq5WzrtrOBJ2RItXCZ5jIuoP90AD61XZucPt8z9RPdIBjRr5V+BbNph1p0raEoahrZtHoWR4uX2+CLWHoSjZ7BZ0J8fr9V7UJvJdPlD1c/8KnBJjfB+ZXl0/+Efqd8Ykm+uA0608uV7vMptD0HZp3+ceQ6Xpey1WKbbHWFlHosXKTVFSdq3j8Ho93zguoJr0NujVc9h12+i1JiaXWfxSX3dtFpPUj/0S9WPfqYnJGyhh/Cekx59nHB1Rf/4Augs5ollcMb2upm5a9VrDkev1hzVxHY50dTjVFvgU1/5mG1Ay3h1YXlO/w9CE9iqUWC5AY+FuaCI4zZVnU2gdLydYnFc3pu6GJhv/gm4CpDt+q9yYuzkaS/LzV5rNzmgMP4lK8zeiRYCdmnDsAjwXY3yiCceeaGwahyZcfXGT1xjjGWg3ySvA8VlZzrU4tI7fztcJwAdt7D4et2DmyrsZWujaA2n+DaSnL5vNb4HdXR7yFNLRFqhu+9rfp5CWnkD95y3oe7tyjvTdTKdmNnVxPRHt2mlWN9sAo5rUzUpgUYyxL3pkcnQW1/Ot3FORlr5do5HrUR80GvWZEzI/hqK7pIPRxGKF5V2voMWTIRbz+0IIh6OcqbYvNOxPlbv9GXg8xvh+Kq12BebU5HYe+6Lvjmr1I8snbkRt6OXV8FwDvB5jTGPOQqox57Oor1oK9GjC8RaK72xUJ6BFif3Q4zA3W3k6OF8BCCFsS6NWvY2PyQ2o7prlxCm/ewYtgvaticlKVM+Xo0nolzKOLqi+nkF1//7VxPWLaNt8s5huY/7W1Y3X6lPosYqc53w0hlyIdoqlHOtNtHvsE6iPfcmutcJz2Lg+FNXHbSi3f9XNAV5Dj9C9SzXu+TnAAJSD5Vhcw+FzgbPc8fdRLch5+HnbqygnyXOBvczmAeAfs/nKMajfSTdWTgROqMkF7jWO0cAxjiPlAt9BY/EhaMdWWhD2ucBhNRx5LnBYTUx8LvAjNAb6mLTJBYxrFm3zeX9zrS3i3/Dsxrrwh1aBnwQ2WY3NeLTddBP32cXAxe79PPSllc04fm+BH7wajlHAfu79AKpnhPZDA07tuTXXu5zqGZxWHns/Aehjr/vY+wabjGsAavijgAvWwNNgU8djry9FSeUcqmef8jJeSuNz8N9EHfxSlCwsRUm057gddZxTnM1PMj+GYM8q+VjVlSePpTtnb7QFLL3/OFp4mmDn9kaD3QR/vElcjwIeWU1cZ/jjGcc5wDz3/lTUoNPK7/Go4xrljt+4hnh8w3hr4+FtsnKk//l5k+zz76MOMsVoAurYa/VndfgnlOQk7qbtrglHa9ut40DtfwEwZDUcvzcf+rtyzgNOzOuM6osXk87fhzryKWgwaUGLk3snDmezAmmmxep8fE19T0GLX8mPN6jpQ+xYw/c4oMWjT7ryTEILZa0cZvMM1g85mzwmT6Cksm+TuHZEA/qRTfqgdDdtMJqYLaZRIwvt8xTXRU3qZgq627EzWhir08gotIAzGt29yPuxpehRDdBdmLfRgLc6vbbp56j0+g/peI0v86i+sK+Ow+s12TyYcbxof5vVcTjNHkbVb/+Zer3uYLG/YA16/V3ioF6vyaYuJj2pvsCsLiaj0E6VujEmLXgOtngsBf5v4qDSdNL9JHRnMPcj6XVAXd3g9NpEI7leF+VxNZsU104Wl7q6mWIaeaZJ/aay7AyMrhsvzZczqPr1UegOeLKZY37WjqlUzxFPwX03kvn0E/d+BXrcjZzDXs9H2+w3quNAyeditNuoGUfSyP5UzxC/CnzP1c0cf9xxXIb6r1XGswo9tupjkmxW1th4P1JMhjg/vo8t7GbtxtukmI5Hk/NUnoU5h9lMNo6QbGp8eR31FRs3iWtPK8+Amrh+GbWD5Ed/NOlujasdT3FtPV6nEfvsIGBEE41MQJOUpTTmXSk3m4Im9rPRInKqi1F2vIv9r83dXL0sQDey0vEVwB8zrd6C7g43cGRa/aazWYrafbKZY7Gp5XB6/bmVZYqd/475mmL6TSuvz1Xn2+spSIMR9RGeI9kkrXqbupjkOXEekwlosWxZDcd4K+c1VF9c2spBpecJaEF2Vc7htJq+PLVN3VBp9caauD5Io1ZvsHN9TJJNiussNLHO/UgxuYdKi3n9pvbbqmf7/HKqOcA088XPAZ61mLXJBXKOLBfw873fYt9r4XOBrP16jmbzzt86m5QLbFLHkecCrj8aSds+rb+zuRyNs3W5QG/HkWzyXKB3k5jk332Rx6Q1F8jHTVeWwXXH0t86txNidQj6tYmLUKK81H2+ddCzW4QQTkcrNMd6G+B+YGgIoUvQrzN0pfrG2ZxjB7Qa6bd91XHsRPVsHlSJGdiKZghhoN05H2rnp+t1CyF0T69RIxtLPe5H28Sw/7+qiU2fzI9uwLgYo99qnvOsyG0STwhha5TAjg0hdEV3tsahxPU4M/8cutOOsxnvfLkEDWzXWfkfjzGelHEsQ4nfAGdzsvMjmO0rNbG6HzjNPvsM8Ct/PIvJx4CFIYS0snkg+t6E+4HTYoxvoAb5B3+8Jq5pR4y/o5zHdZE/nnHsBHQIIWxiZUt+pJi8jp49fsgdH5fF42hsJTOE0B+tnv60xo9Hc5sm5ak9zz4/1f7/GxowDqHSX0fzhxDCPuiuf353e7XtzmKxtm33CLSNcQEadOs4DrAYT0aLRePNZhFwahCOQ8naLLOZZOf2Rp1pLzQJnokG4Q+hxGGRxWMsmvw8H2PsR/WLFi0hhN52jT4uJkOo2vZiF499zNfRVhdJ46kvus8+3wklwJ3RQNjKYXEYBIwOIezsbHxMdkB3DsfHGKfX1Q26G7eKxmc/Wzms/HtYXA+geqQjaWQmurO8EG17TVvkvUYOtnjMQ3q6y3EMDSH0df3qEegO1A/tWte6sqyket70V1R9WDO9rkB910+b6PXSjKNOrz80jjvr9Ir6sWRzkeM4Dd05+Ed0p3JcjPG7qY5DCDu58WZPdMd9HNqa26BXlMTdA7xhHM30+iT68qgraa7XZONjcojFZC7qv2ZmMdne1c9AbIzxMUE7E3YwnYywuvp64kDfm5A0PR8lSH/N4tqqV/SFZG3qhka9tqkb2uo1aaA1rkiHKZF/EJib4mpx7+V08nmUSOf1O9jK8hp6DOlmGwsPRcni79AC8U5ofEyP1j2MND4O7dp4NSpr82PqQDtnvNXfOPNlMzveFelzV/N3XytPSwhhc7MZQDUufx0tln2uCcdZVN+Ev6KGY0II4RiqL2k83ni72vtBIYRBaBx7HG0Bfi0ryxjUT4y2MX8pWijyMRmDHpW5Fy3+Lo0xDnJxTTlGismJVP3Nb9CYOT7o0YSFaFw/gSqXOdTKeB/aybIRGnMn5Ryob8bGiiOpxgof133Q7o5HsO9oyesGLTTMQ49i5HEdh3YmdLY4HonG/BTXHdGz9+daXD+NNJNr5BQ7bzs0Tt6c+dHLNLII9TOHWx2cQ5Wb/cXKcj76roMvoXb7stXl79CjeOkZ+QsyjpNdvSxAd+MHGMfzwJJMqxfHGPvmHE6rx8YYvc0VVqenhBC+gRZE9nTHh6LJ5CkhhEGu/U4FbjCbm9Ad+VNQu34c5ap3oIn3UPQ4zhYxxt4Wi9HA2zHGjp4jxrgFplX73Nv4mJxmMclz4hSTPhaThWhyeG0Nx9NWl+ejXz0b4zmQns80jl8AY2rimrQ6IotZa91gWo0xnpPXDcqXklbnop2f92dxPQo9tjA6xngxGosfcHE9OYTQy3Qy3mwPr6nfQ+z1PDSZvx1aNZ/mAKORlpfROAfYBI27Phc4Ei1qNXA4jay089I8YyvUbnwuMClU87btHcfpVLlASDYol94P9Z0pFziSapd9N9QfvZzlAmn3KWiif6BdJ+UCi9CYP944DgOeyXKBGcDHbW6TOJ6hMRdotcliknKBZVZvY7OY5LnAWCtP3Ty6bsdwK4KtVqwXCHoMowvVl9I9FWM8O4RwLBLvCrSlaTHVF6e1/kRICOGraKtJ+hm1+cBfYowHZxzdUaffHXWkf4kxHuw4hqGB7Ty0BeaDxjcF+FysnnU8FK1adgB+FGO80pVlB7SVBbQa+9MY45UhhLvRpKUnatCXoc5lBFr5mopE+JHMZojzYxEaVF+keg7rEtSJJZ4FaPDPbU40ni5om9QMOz4ixniF+X0P2gI5GT0bu5H9JZvHUccS0KB2tl3rwqif3/QczwMnxxjfDSEMcTaeYyJq4KuyWG1l5dnBYjHV7NPxO7O6uQ596V5n8/2M5LfFZK6Vu4M7fl3GcR5qyDvEGBdaXW7lOKaZ/UB3PPfjVdRptFj5z0LPiaWYvGvlXOGOP5zFdCDaYroCJQKPZX5MRZOEHpnNa+hueEe0av1V1Lmn81LnuRXS1it2ra3RYPAKlf56USXxS82fHlbOQPUNx6PN3re7pLn0jN0s40ttd3urp86O4wg753Wz64YGVM/RHel/ocVgJdXPir1rfnahuhuxFdUW8SX2WfqpvrSNegxVe0scb6JV8WdDCEuoftItcXSl+oKxl82PfY0jrfZ3oVpU2BLdjd3S/H/H/Ohnx+da3HbPOOZbvHqhSVKy8TGZY9cZibZBDqHqO0ajOwQ90RcXfcH1QZ5jGWoXb1N98d/mVBrZxXyfZj7MN16vkZVIE+8g7W+R+bE/mhzNRncxfo0WWaZSfa/DDLRocCa689zX4psWv6ahyXzS65tU/dyWVkezzH4LK0Mnq7c0CXkBbW9Mel1C9cx0dzRxnmlxSHrthhaDUn+a/E0/I7fAjs8zH3tYLHpQ/UTsTKSzxLEd1c/MpS+s3BEls8up7lgtoNLrveZfzjGHSq+znI2PSWo7MbtOiskxqD2mBCeNMT4mi8yf7VG/MZnqJ41fQIvBPZE+3kV1mHOkxPN5dLfLj1Ge4w70JX9/rOFoodJrR9Qm8pgstfJ1svJONPsU19QvvIUWp0+ibf2mhawW7Cdn7bOxaAdKsFgstM/SeNnB4rwx1RdNdqNxTO1D1f66orbR0z5bbOUcYb6cgLSUFlc2suM9rRyz0HP1M5Ce+1tdzXEc51g8ptg1eljZPccOqH2uQrpJX5r8C/RowOF27jSLZ1/zyZdlHjA8xjg+hLAULdZ0yGIyDyW/myIdpO/emGfX7W+8M1H/049qzEl1uA1qVzHzdQrS5irzb57FpDPVT+YljnS3u4fZJxsfk2X2+S1o+38HqrybrG1CAAACaklEQVRiG/ToxzZoIvUE1dZ+z7GxvW5Bj7rMsNcprh8zH6aar5tQ/exeimvKBzoYV9JB8uMku84bwDUxxmsAQgjXopx2spWxC9Vz5yejSdRFFpO9qX6i8xmq3O0uNLmZTKNWZ6OJ309QW55Ko1ZnozurZ2V+JK3OsTr7heWWQ9D2/JVIiw02qJ1eb9wD7P8s9NjA8BjjohDCQcaxlCrHbUF9y3B00+FW1D+1WByHo1/Y2dRi5jnmoV8UmRxCWOJsfEz6o7a0nCwntpikXHS6+Xp2jHFJFpPl9reZaeBsq/PEcSjS+Wy71tkxxhcyjqTVS2KMvzE/hziOVq3GGL9ncc01krS6BLWNYVZ2H5NodZRylGEWgxTXrVF/NxstuCQt+vpN5VyONHykuZP6x7SDAyt3wxwAtaNDqXKBNO6uzDg2pspd08R7mnFA45xxkcXvNTunC9KXn3d2Nv4ZFqcZaHzph8aBt1D/8zb2CyAoV9qOKheYjMayFuNYbOXoaee3oLafbipNRu2hhSoXGEH1E5+eYylVLjDd2fiYbEv1PSf+OikmX6HKBV7E5r3ZPHoVcFmM8QFWg/VqEaKgoKCgoKCgoKCgoKCgoGD9xXr1OEZBQUFBQUFBQUFBQUFBQcH6i7IIUVBQUFBQUFBQUFBQUFBQ0C4oixAFBQUFBQUFBQUFBQUFBQXtgrIIUVBQUFBQUFBQUFBQUFBQ0C4oixAFBQUFBQUFBQUFBQUFBQXtgrIIUVBQUFBQUFBQUFBQUFBQ0C4oixAFBQUFBQUFBQUFBQUFBQXtgrIIUVBQUFBQUFBQUFBQUFBQ0C74b8duKbn57l7lAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(5))\n",
        "#plt.plot(history.history['loss'], label='train')\n",
        "plt.plot( loss_tracking, label='test')\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHohbk8uYRIh"
      },
      "source": [
        "**MinMax Scaler equation**\n",
        "$$x' = \\frac{(x - min)}{(max - min)} \\times (new\\ max\\ value - new\\ min\\  value) + new\\ min\\ value$$<br/>\n",
        "\n",
        "\n",
        "$$x = \\frac{(max - min)\\times (new\\ min\\ value + x') + (new\\ max\\ value - new\\ min\\ value)\\times min}{new\\ max\\ value - new\\ min\\ value}$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$x$ is the inverse scaled value\n",
        "$x'$ is the scaled value\n",
        "$min$ is the minimum value of the original data\n",
        "$max$ is the maximum value of the original data.<br/>\n",
        "$new\\ max\\ value$ and $new\\ min\\ value$ is the new range that we want to scale the data to. For example: $(1,0)\\ or\\ (1,-1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ3IIvIhvHaz",
        "outputId": "c24b5278-e7ac-46d6-e42b-c5bae7b8ce21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# make a prediction \n",
        "# select the number of obersvtions for prediction\n",
        "n_obs = len(test)\n",
        "yhat = model.predict(test_X[-n_obs:], verbose=1)\n",
        "\n",
        "\n",
        "# invert scaling \n",
        "scaled_y = pd.DataFrame(test_y)\n",
        "scaled_yhat = pd.DataFrame(yhat.ravel()) ## ravel () converting into 1D array\n",
        "#obtain the min and max from the training set\n",
        "unscaled_train = pd.DataFrame(series_supervised[:len(train)])\n",
        "#new feature range\n",
        "new_max_value = 1 \n",
        "new_min_value= 0\n",
        "feature_range = new_max_value - new_min_value\n",
        "\n",
        "def transform_column(column):\n",
        "    min_value = min(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    max_value = max(unscaled_train.iloc[:, -steps_ahead + column.name])\n",
        "    return ((max_value - min_value) * (new_min_value + column) + (feature_range  * min_value)) / feature_range \n",
        "    \n",
        "# invert scaling for actual\n",
        "inv_scale_y = scaled_y.apply(transform_column, axis=0)\n",
        "inv_scale_y = inv_scale_y.values.ravel() \n",
        "# invert scaling for forecast\n",
        "inv_scale_yhat = scaled_yhat.apply(transform_column, axis=0)\n",
        "inv_scale_yhat = inv_scale_yhat.values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqftbPYxvEE5"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for actual \n",
        "df = pd.DataFrame(series.iloc[-len(test)-steps_ahead:,-1])\n",
        "n_vars = df.shape[1]\n",
        "columns = df.columns\n",
        "cols, names = list(), list()\n",
        "for i in range(0, steps_ahead):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "        names += [('%s(t)' % (columns[j])) for j in range(n_vars)]\n",
        "    else:\n",
        "        names += [('%s(t+%d)' % (columns[j], i)) for j in range(n_vars)]\n",
        "# put it all together\n",
        "agg = pd.concat(cols, axis=1)\n",
        "agg.columns = names\n",
        "agg.dropna(inplace=True)\n",
        "agg = agg.iloc[:-1,0]\n",
        "#drop all the variables that we don't want to predict\n",
        "#agg.drop(columns=vars_to_drop, inplace=True)\n",
        "agg = agg.to_numpy()\n",
        "inv_y = np.add(inv_scale_y,agg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWAqc4iTkxvn"
      },
      "source": [
        "* To invert the differencing of time series for multistep prediction:<br/>\n",
        "The equation is given by $$\n",
        "\\hat x_{t+h|t}=x_t+(\\widehat{\\Delta x_{t+1}}+\\dots+\\widehat{\\Delta x_{t+h}}).\n",
        "$$ <br/>\n",
        "where: <br/>\n",
        "$\\hat x_{t+h|t}$ is the predicted value of the time series x at time $t$+h, given the value of the time series at time $t$.<br/>\n",
        "$x_t$ is the value of the time series $x$ at time t.<br/>\n",
        "${\\Delta x_{t+1}}$ is the difference between the value of the time series $x$ at time $t+1$ and the value of the time series at time t.<br/>\n",
        "${\\Delta x_{t+2}}$ is the difference between the value of the time series $x$ at time $t+2$ and the value of the time series at time $t+1$.<br/>\n",
        "${\\Delta x_{t+h}}$ is the difference between the value of the time series $x$ at time $t+h$ and the value of the time series at time $t+h-1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSJErK0WDkX4"
      },
      "outputs": [],
      "source": [
        "# Invert the Differencing for forecast\n",
        "# to invert the diffrenced predicted values,the the predicted differenced value is added\n",
        "# to previous predicted diffenced values and last available observation in test set(Xt) as explained above\n",
        "originalSeries_supervised = series_to_supervised(series, series.columns, n_in=timesteps, n_out=steps_ahead, dropnan=True)\n",
        "\n",
        "current_timestep = 1\n",
        "# actual value of oil rate at current time step\n",
        "# steps_ahead = 4\n",
        "#drop all the variables that we don't want to predict\n",
        "vars_y = originalSeries_supervised.columns[-steps_ahead*len(series.columns):]\n",
        "vars_to_drop = [col for col in vars_y if col.startswith(vars_name_to_drop[0])]\n",
        "originalSeries_supervised.drop(columns=vars_to_drop, inplace=True)\n",
        "originalSeries_xt = originalSeries_supervised.iloc[-len(test):,-steps_ahead-2]\n",
        "\n",
        "\n",
        "# A predicted value at any given step ahead is a result of the previous cumulative differnced predicted values and current time step\n",
        "col = []\n",
        "#inv_yhat_cum = np.cumsum(inv_scale_yhat, axis=1)\n",
        "inv_yhat_cum = inv_scale_yhat\n",
        "\n",
        "for i in range(n_obs):\n",
        "    #.ravel() flattens the series into a one-dimensional array\n",
        "    inverted_diff_yhat = originalSeries_xt[-n_obs:].ravel()[i] + inv_yhat_cum[i]\n",
        "    col.append(inverted_diff_yhat)\n",
        "#col = pd.DataFrame.from_records(col) # creates a DataFrame from a list of records\n",
        "col = pd.DataFrame(col)\n",
        "#col.columns = pd.RangeIndex(start=1, stop=steps_ahead+1, step=1)\n",
        "inv_yhat = col.values.ravel() # convert df to NumpyArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si8_sP7AeBNV"
      },
      "outputs": [],
      "source": [
        "inv_yhat = np.add(inv_scale_yhat,agg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alOk-YutHixs",
        "outputId": "da7b899f-ddf7-430f-9def-5cb6f1c964a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1902.73060461, 2717.82716026,  672.44365125,   61.70304199,\n",
              "       3062.1313925 , 1036.43499067, 2522.33984681,  885.22794384,\n",
              "       3063.89253947, 3337.49930057])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06AqinKpyr8U",
        "outputId": "d714c97d-be38-48f7-d33e-e5f1c8a9c62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2164.42402892, 3171.03431554,  857.81251182,  362.32646375,\n",
              "       3367.9969873 , 1618.67533782, 3242.31682661, 1717.44726869,\n",
              "       3491.30704541, 3167.62691447])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUnbXmPJligj",
        "outputId": "f3be5b4e-4418-4713-fc65-a1d5ae5a5291"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3607.93342036, 2350.85371642, 3257.16322179, 1183.83887901,\n",
              "        126.939745  , 3499.08097167, 1843.84037688, 3750.63127973,\n",
              "       1881.272464  , 3321.59024853])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnEwrbE7dBzK",
        "outputId": "4c98fccd-662d-4804-eee1-7b7aecbcda59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3590.59357661, 2211.30977111, 3251.55189367, 1095.77833214,\n",
              "        381.24345593, 3312.50870605, 1757.93412688, 3445.83049848,\n",
              "       1839.522464  , 3686.42227978])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdEkT5sNTIcw",
        "outputId": "34d0d25f-d9f1-44e4-d0e1-f6801687cb59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3594.66193598, 2206.2423883 , 3173.63001867, 1143.65919151,\n",
              "        407.15947156, 3368.39737792, 1757.37943938, 3290.52971723,\n",
              "       1995.08789369, 3455.65079541])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJvNG5uGK-CL",
        "outputId": "3f2b8f8e-cf9d-4b5f-8f40-d9098bd95db1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3626.33967036, 2268.59590392, 3209.46400304, 1201.12501182,\n",
              "        361.57548718, 3662.83683105, 1867.23881438, 3091.02581098,\n",
              "       2142.52344056, 3604.08829541])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ksoIwntDr-m",
        "outputId": "8574d814-18b3-4a2e-8c87-038da8de7b5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3434.46857661, 3391.58027892, 1893.50794836, 2708.45704307,\n",
              "        663.33622937,   53.39640136, 3052.82279875, 1027.26409223,\n",
              "       2513.01269837,  876.16739697])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cp8I88cA6f_",
        "outputId": "5926c5a5-0758-4344-b082-01a893b0a5db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3616.66779536, 2901.4142633 , 2707.84290929, 2021.48536339,\n",
              "        415.11064343, 2041.42862792, 2893.83940032, 1935.12932661,\n",
              "       2185.30762025, 2642.25040478])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU8EPrjW9-WB",
        "outputId": "77946584-1d51-49e0-c189-753a6b043f1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3574.35529536, 2202.53340392, 3130.52064367,  958.16505089,\n",
              "          4.90165906, 2767.44425292, 1848.91557219, 3947.85198286,\n",
              "       1786.16992494, 3531.10392041])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm_8nWqG1pv1",
        "outputId": "be20d3f0-c336-4dd2-a218-3f1c7aa15bc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3636.01545161, 2339.25898986, 3426.80189367, 1147.14063682,\n",
              "        288.00908093, 3820.93644042, 2009.1470175 , 3904.13713911,\n",
              "       1911.25879212, 3662.91837353])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvxvb4BhFVeh",
        "outputId": "9f0a8759-a30c-4801-9a2f-fbc4b05241c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3381.95099848, 1601.08223205, 3568.13392492, -203.34080849,\n",
              "       -564.89033313, 5612.03995605, 2615.65483   , 3544.03557661,\n",
              "       1119.57129212, 3880.51602978])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] # 1 time steps # on stream choke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CotdhM7B70z",
        "outputId": "6a99acda-ab09-4fd0-b335-e8c6048f31f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3362.01447504, 3014.15742736, 1575.44740148, 2900.26856651,\n",
              "        196.33037   ,  969.9657373 , 4537.10893157, 1709.12542036,\n",
              "       2967.28906556, 1227.26407666])"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10] # 4 time steps # on stream choke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0iYlicucxa",
        "outputId": "0c11e428-80fe-425a-bbd8-28da6cbd8a0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3357.58478754, 3198.6486383 , 1894.60365148, 2831.45606651,\n",
              "        624.30595593,  780.4735498 , 3790.01518157, 1856.40471723,\n",
              "       3131.147464  , 1301.48477978])"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat[:10]# 4 time steps # on stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA3lZJw-LHgv",
        "outputId": "d0beb942-f44b-4b55-ae68-782911742ce8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.31858047240881304"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r2_score(inv_y,inv_yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UT3jqDxPF9e",
        "outputId": "12fb85bb-2d64-427c-dbdc-17c7bbe9bc2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28.446741757485977"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wMAPE(inv_y[:10],inv_yhat[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xw8O7CoPQAG",
        "outputId": "3cdff192-b9ed-42ef-f99f-c96cbd884cab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((369,), (369,))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_y.shape, inv_yhat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqXWUX41YtDY",
        "outputId": "e3cdcede-ed29-465a-ac7f-70fda875f54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE: 449.03130\n",
            "Test RMSPE: 19544194831094544.00000\n",
            "Test MAE: 213.63827\n",
            "Test MAPE: 1353133045674894.00000\n",
            "Test r2: 0.60894\n",
            "Test wMAPE: 9.53361 \n",
            "Test wMAPE: 14.70437 \n"
          ]
        }
      ],
      "source": [
        "# Performance evaluation\n",
        "\n",
        "rmse_test = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.5f' % rmse_test)\n",
        "#report performance using RMSPE\n",
        "RMSPE_test = RMSPE(inv_y, inv_yhat)\n",
        "print('Test RMSPE: %.5f' % RMSPE_test)\n",
        "MAE_test = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test MAE: %.5f' % MAE_test)\n",
        "MAPE_test = MAPE(inv_y, inv_yhat)\n",
        "print('Test MAPE: %.5f' % MAPE_test)\n",
        "r2 = r2_score(inv_y, inv_yhat)\n",
        "print('Test r2: %.5f' % r2)\n",
        "wMAPE_test = wMAPE(inv_y, inv_yhat)\n",
        "print('Test wMAPE: %.5f ' % wMAPE_test)\n",
        "SMAPE_test = SMAPE(inv_y, inv_yhat)\n",
        "print('Test wMAPE: %.5f ' % SMAPE_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "51SnY7n5e0nx",
        "outputId": "1f038602-a51a-4b26-8c5f-0bfb86cabda4"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-bef913473e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresult_RMSPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMSPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult_MAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ],
      "source": [
        "# Performance evaluation\n",
        "rmse_test, RMSPE_test, MAE_test, MAPE_test, r2_test, wMAPE_test, SMAPE_test  = [], [], [], [], [], [], []\n",
        "# calculate the score for each day\n",
        "\n",
        "for i in range(test_y.shape[1]):\n",
        "    result_rmse = sqrt(mean_squared_error(inv_y[:,i], inv_yhat[:,i]))\n",
        "    result_RMSPE = RMSPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAE = mean_absolute_error(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_MAPE = MAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_r2 = r2_score(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_wMAPE = wMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "    result_SMAPE = SMAPE(inv_y[:,i], inv_yhat[:,i])\n",
        "\n",
        "    rmse_test.append(result_rmse)\n",
        "    RMSPE_test.append(result_RMSPE)\n",
        "    MAE_test.append(result_MAE)\n",
        "    MAPE_test.append(result_MAPE)\n",
        "    r2_test.append(result_r2)\n",
        "    wMAPE_test.append(result_wMAPE)\n",
        "    SMAPE_test.append(result_SMAPE)\n",
        "    \n",
        "## calculate overall score\n",
        "print(\"The Average scores for the vector output {} steps ahead:\\n\".format(steps_ahead))\n",
        "print('Test RMSE: %.5f' % np.mean(rmse_test))\n",
        "#print('Test RMSPE: %.5f' % np.mean(RMSPE_test)) because of that the denominator (actual) has some zero values\n",
        "print('Test MAE: %.5f' % np.mean(MAE_test))\n",
        "#print('Test MAPE: %.5f' % np.mean(MAPE_test)) because of that the denominator (actual) has some zero values\n",
        "print('Test r2: %.5f' % np.mean(r2_test))\n",
        "print('Test wMAPE: %.5f ' % np.mean(wMAPE_test))\n",
        "print('Test SMAPE: %.5f ' % np.mean(SMAPE_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef--j4gGOE6F"
      },
      "outputs": [],
      "source": [
        "Test RMSE: 555.56135\n",
        "Test MAE: 277.11301\n",
        "Test r2: 0.39641\n",
        "Test wMAPE: 12.32902 \n",
        "Test SMAPE: 17.45901"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4KkEyXsJvDW"
      },
      "outputs": [],
      "source": [
        "# plot the scores for each time step of the multi-step forecast\n",
        "scores = pd.DataFrame({\"rmse_test\":rmse_test, \"MAE_test\":MAE_test, \"R-squared_test\":r2_test, \"wMAPE_test\":wMAPE_test, \"SMAPE_test\":SMAPE_test})\n",
        "\n",
        "# Reset the index, keeping the old index as a column\n",
        "scores = scores.reset_index(drop=False)\n",
        "\n",
        "# Set the 'index' column as the new index\n",
        "scores.index = scores['index'] + 1\n",
        "\n",
        "# Drop the old 'index' column\n",
        "scores = scores.drop(columns='index')\n",
        "\n",
        "data = scores.columns\n",
        "\n",
        "# Creating figure with two rows and one column\n",
        "fig, axs = plt.subplots(nrows=len(data), figsize=(17, 15))\n",
        "\n",
        "axs = axs.ravel()\n",
        "\n",
        "for id, column in enumerate(data):\n",
        "    # Set the x-axis limits\n",
        "    #axs[id].set_xlim(xmin=1, xmax= steps_ahead)\n",
        "    #print the name of the test on plot\n",
        "    axs[id].plot(scores[column])\n",
        "    # Add a title to the x-axis\n",
        "    axs[id].set_xlabel('Steps ahead',fontsize=10, labelpad=0.1)\n",
        "    axs[id].grid(True)\n",
        "    # Remove the horizontal grid lines\n",
        "    axs[id].grid(which='both', axis='y')\n",
        "    axs[id].xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "    axs[id].legend([column], loc='upper left', fontsize=15, handlelength=0, handletextpad=0, frameon=False)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-CDANaINC-c"
      },
      "outputs": [],
      "source": [
        "inv_yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHKnDMnFNdmw"
      },
      "outputs": [],
      "source": [
        "inv_yhat[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1S1CN4BEWUe"
      },
      "outputs": [],
      "source": [
        "plt.plot(inv_yhat[-1], label = \"predicted\")\n",
        "plt.plot(inv_y[-1], label = \"actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2CGD3H6NZoj"
      },
      "outputs": [],
      "source": [
        "plt.plot(inv_yhat.flatten(), label = \"predicted\")\n",
        "plt.plot(inv_y.flatten(), label = \"actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GHomhZ5E3jc"
      },
      "outputs": [],
      "source": [
        "plt.plot(inv_yhat.flatten(), label = \"predicted\")\n",
        "plt.plot(inv_y.flatten(), label = \"actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doFyZoCCZ-ht"
      },
      "outputs": [],
      "source": [
        "# plot the last forecasted values on test set\n",
        "fig, ax = plt.subplots(1, 1, figsize=(18,6)) \n",
        "# Set the major locator for the x-axis\n",
        "x = list(range(1, len(inv_yhat[-1])+1))\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "ax.plot(x, inv_yhat[-1], label = \"predicted\")\n",
        "ax.plot(x, inv_y[-1], label = \"actual\")\n",
        "ax.set_ylabel('Oil Rate', fontsize=15)\n",
        "ax.set_xlabel('Steps Ahead (Days)',fontsize=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZcZ-O1kL3Q5"
      },
      "outputs": [],
      "source": [
        "#comparing predictions and actual values\n",
        "act_pred = pd.DataFrame({\"actual\":inv_y.flatten(), \"prediction\":inv_yhat.flatten()})\n",
        "act_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7APsQRBRvRbx"
      },
      "outputs": [],
      "source": [
        "series_to_supervised(series, series.columns, n_in=2, n_out=steps_ahead, dropnan=True).iloc[-len(test):-len(test)+5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kx12S2F506y"
      },
      "outputs": [],
      "source": [
        "r2_score(act_pred.iloc[:5,0],act_pred.iloc[:5,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS4cX0QOuinK"
      },
      "outputs": [],
      "source": [
        "wMAPE(act_pred.iloc[:5,0],act_pred.iloc[:5,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4g3tcrW5lIB"
      },
      "outputs": [],
      "source": [
        "MAPE(act_pred.iloc[:5,0],act_pred.iloc[:5,1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1fRyNGg_0mKKrWR0X5NTRjquhMWU9-Gqx",
      "authorship_tag": "ABX9TyMGghsy2VngBXwVVZROrsuv",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}